{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  male    age   debt married bankcustomer educationlevel ethnicity  \\\n",
      "0    b  30.83  0.000       u            g              w         v   \n",
      "1    a  58.67  4.460       u            g              q         h   \n",
      "2    a  24.50  0.500       u            g              q         h   \n",
      "3    b  27.83  1.540       u            g              w         v   \n",
      "4    b  20.17  5.625       u            g              w         v   \n",
      "\n",
      "   yearsemployed priordefault employed  creditscore driverslicense citizen  \\\n",
      "0           1.25            t        t            1              f       g   \n",
      "1           3.04            t        t            6              f       g   \n",
      "2           1.50            t        f            0              f       g   \n",
      "3           3.75            t        t            5              t       g   \n",
      "4           1.71            t        f            0              f       s   \n",
      "\n",
      "     zip  income approved  \n",
      "0  00202       0        +  \n",
      "1  00043     560        +  \n",
      "2  00280     824        +  \n",
      "3  00100       3        +  \n",
      "4  00120       0        +  \n",
      "678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['age --> yearsemployed',\n",
       " 'priordefault --> age',\n",
       " 'creditscore --> debt',\n",
       " 'ethnicity --> age',\n",
       " 'yearsemployed --> creditscore',\n",
       " 'zip --> debt',\n",
       " 'married --> approved',\n",
       " 'yearsemployed --> debt',\n",
       " 'employed --> creditscore',\n",
       " 'bankcustomer --> approved',\n",
       " 'employed --> approved',\n",
       " 'priordefault --> yearsemployed',\n",
       " 'bankcustomer --> employed',\n",
       " 'bankcustomer --- married',\n",
       " 'priordefault --> approved',\n",
       " 'yearsemployed --> driverslicense',\n",
       " 'citizen --> employed',\n",
       " 'creditscore --> zip',\n",
       " 'employed --> priordefault']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "column_names = ['male', 'age', 'debt', 'married', 'bankcustomer', 'educationlevel', 'ethnicity', 'yearsemployed',\n",
    "               'priordefault', 'employed', 'creditscore', 'driverslicense', 'citizen', 'zip', 'income', 'approved']\n",
    "\n",
    "data = pd.read_csv('data/crx.data', header=None,  names=column_names)\n",
    "data.reset_index(drop=True, inplace=True) \n",
    "\n",
    "\n",
    "data = data.dropna(how = 'all')\n",
    "data = data[data.age != '?']\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for feat in ['male', 'married','bankcustomer', 'educationlevel', 'ethnicity','priordefault', 'employed', 'driverslicense', 'citizen', 'zip', 'approved']:\n",
    "    data[feat] = preprocessing.LabelEncoder().fit_transform(data[feat])\n",
    "\n",
    "\n",
    "#####################################################\n",
    "#### For this experiment, we uniquely drop the default variable (prior default)\n",
    "###################################################\n",
    "#data = data.drop(['educationlevel'], axis=1)\n",
    "    \n",
    "print(len(data))\n",
    "\n",
    "from pycausal.pycausal import pycausal as pc\n",
    "pc = pc()\n",
    "pc.start_vm()\n",
    "\n",
    "from pycausal import prior as p\n",
    "prior = p.knowledge(addtemporal = [['male', 'age','ethnicity'],[ 'debt', 'married', 'bankcustomer', 'educationlevel', 'yearsemployed',\n",
    "                'employed', 'creditscore', 'driverslicense', 'citizen', 'zip', 'income'],['approved']])\n",
    "\n",
    "\n",
    "from pycausal import search as s\n",
    "tetrad = s.tetradrunner()\n",
    "tetrad.run(algoId = 'fges', scoreId = 'cg-bic-score', dfs = data, priorKnowledge = prior,\n",
    "           maxDegree = -1, faithfulnessAssumed = True, verbose = False)\n",
    "tetrad.getEdges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 7], [8, 1], [10, 2], [6, 1], [7, 10], [13, 2], [3, 15], [7, 2], [9, 10], [4, 15], [9, 15], [8, 7], [4, 9], [4, 3], [8, 15], [7, 11], [12, 9], [10, 13], [9, 8]]\n"
     ]
    }
   ],
   "source": [
    "edges = []\n",
    "for edge in tetrad.getEdges():\n",
    "    edges.append(list([column_names.index(edge.split(' ')[0]), column_names.index(edge.split(' ')[-1])]))\n",
    "print(edges )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the above edge list \n",
    "column_names.index('male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>debt</th>\n",
       "      <th>married</th>\n",
       "      <th>bankcustomer</th>\n",
       "      <th>educationlevel</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>yearsemployed</th>\n",
       "      <th>priordefault</th>\n",
       "      <th>employed</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>driverslicense</th>\n",
       "      <th>citizen</th>\n",
       "      <th>zip</th>\n",
       "      <th>income</th>\n",
       "      <th>approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male    age   debt  married  bankcustomer  educationlevel  ethnicity  \\\n",
       "0     2  30.83  0.000        2             1              13          8   \n",
       "1     1  58.67  4.460        2             1              11          4   \n",
       "2     1  24.50  0.500        2             1              11          4   \n",
       "3     2  27.83  1.540        2             1              13          8   \n",
       "4     2  20.17  5.625        2             1              13          8   \n",
       "\n",
       "   yearsemployed  priordefault  employed  creditscore  driverslicense  \\\n",
       "0           1.25             1         1            1               0   \n",
       "1           3.04             1         1            6               0   \n",
       "2           1.50             1         0            0               0   \n",
       "3           3.75             1         1            5               1   \n",
       "4           1.71             1         0            0               0   \n",
       "\n",
       "   citizen  zip  income  approved  \n",
       "0        0   68       0         0  \n",
       "1        0   11     560         0  \n",
       "2        0   96     824         0  \n",
       "3        0   31       3         0  \n",
       "4        2   37       0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  male    age   debt married bankcustomer educationlevel ethnicity  \\\n",
      "0    b  30.83  0.000       u            g              w         v   \n",
      "1    a  58.67  4.460       u            g              q         h   \n",
      "2    a  24.50  0.500       u            g              q         h   \n",
      "3    b  27.83  1.540       u            g              w         v   \n",
      "4    b  20.17  5.625       u            g              w         v   \n",
      "\n",
      "   yearsemployed priordefault employed  creditscore driverslicense citizen  \\\n",
      "0           1.25            t        t            1              f       g   \n",
      "1           3.04            t        t            6              f       g   \n",
      "2           1.50            t        f            0              f       g   \n",
      "3           3.75            t        t            5              t       g   \n",
      "4           1.71            t        f            0              f       s   \n",
      "\n",
      "     zip  income approved  \n",
      "0  00202       0        +  \n",
      "1  00043     560        +  \n",
      "2  00280     824        +  \n",
      "3  00100       3        +  \n",
      "4  00120       0        +  \n",
      "690\n",
      "678\n",
      "0.0    539\n",
      "1.0    139\n",
      "Name: approved, dtype: int64 1.0    413\n",
      "0.0    265\n",
      "Name: ethnicity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from models.DECAF_credit import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "            \n",
    "column_names = ['male', 'age', 'debt', 'married', 'bankcustomer', 'educationlevel', 'ethnicity', 'yearsemployed',\n",
    "               'priordefault', 'employed', 'creditscore', 'driverslicense', 'citizen', 'zip', 'income', 'approved']\n",
    "\n",
    "data = pd.read_csv('data/crx.data', header=None,  names=column_names)\n",
    "print(data.head(5))\n",
    "data.reset_index(drop=True, inplace=True) \n",
    "print(len(data))\n",
    "\n",
    "data = data.dropna(how = 'all')\n",
    "\n",
    "data = data[data.age != '?']\n",
    "data.reset_index(drop=True, inplace = True)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for feat in ['male', 'married','bankcustomer', 'educationlevel', 'ethnicity','priordefault', 'employed', 'driverslicense', 'citizen', 'zip', 'approved']:\n",
    "    data[feat] = preprocessing.LabelEncoder().fit_transform(data[feat])\n",
    "\n",
    "data['age'] = pd.to_numeric(data['age'],errors='coerce')\n",
    "\n",
    "#####################################################\n",
    "#### For this experiment, we uniquely drop the default variable (prior default)\n",
    "###################################################\n",
    "#data = data.drop(['priordefault'], axis=1)\n",
    "\n",
    "# binarize the protected variable\n",
    "data.loc[data['ethnicity'] <= 4, 'ethnicity'] = 0\n",
    "data.loc[data['ethnicity'] > 4, 'ethnicity']= 1\n",
    "data.loc[data['ethnicity'] == 1 , 'employed'] =  1\n",
    "\n",
    "biased_data = data.copy()\n",
    "biased_data.loc[biased_data['ethnicity'] == 1, 'approved'] = 0\n",
    "\n",
    "thresh = 0.8\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "data[data.columns] = scaler.fit_transform(data)\n",
    "biased_data[biased_data.columns] = scaler.transform(biased_data)\n",
    "print(biased_data.approved.value_counts(), biased_data.ethnicity.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from fairGAN_code.fairGAN import Medgan\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# from DECAF.data import DataModule\n",
    "import pickle\n",
    "\n",
    "\n",
    "def train_fairgan(datapath):\n",
    "\n",
    "    #data = np.load(datapath, allow_pickle = True)\n",
    "    inputDim = data.shape[1]-1\n",
    "    inputNum = data.shape[0]\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    mg = Medgan(dataType='count',\n",
    "                inputDim=inputDim,\n",
    "                embeddingDim=128,\n",
    "                randomDim=128,\n",
    "                generatorDims=(128,128),\n",
    "                discriminatorDims=(256,128),\n",
    "                compressDims=(),\n",
    "                decompressDims=(),\n",
    "                bnDecay=0.99,\n",
    "                l2scale=0.001)\n",
    "\n",
    "    model_file = ''\n",
    "    out_file = 'fair'\n",
    "    batch_size = 32\n",
    "    \n",
    "    mg.train(dataPath=datapath,\n",
    "             modelPath=model_file,\n",
    "             outPath=out_file,\n",
    "             pretrainEpochs=200,\n",
    "             nEpochs=50,\n",
    "             discriminatorTrainPeriod=2,\n",
    "             generatorTrainPeriod=1,\n",
    "             pretrainBatchSize=batch_size,\n",
    "             batchSize=batch_size,\n",
    "             # protected = [6],\n",
    "             saveMaxKeep=0)\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return mg.generateData(nSamples=inputNum,\n",
    "                        modelFile='fair-399',\n",
    "                        batchSize=batch_size,\n",
    "                        outFile=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, bias_dict = {}, surrogate = False):\n",
    "    dm = DataModule(data.values)\n",
    "    data_tensor = dm.setup()\n",
    "\n",
    "    #dm = SyntheticDataModule()\n",
    "    #data_tensor = dm.setup()\n",
    "    #activation_layer = nn.ReLU(inplace=True) #nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "    # Causal GAN\n",
    "    #%% Import functions\n",
    "\n",
    "    params = dict()\n",
    "    params[\"iterations\"] = 2000\n",
    "    params[\"h_dim\"] = 200\n",
    "    params[\"z_dim\"] = 10\n",
    "    params[\"mb_size\"] = 128\n",
    "    params[\"lambda_gp\"] = 10\n",
    "    params[\"d_updates\"] = 10\n",
    "\n",
    "    max_epochs = (10 + 1) * 25 \n",
    "    number_of_gpus = 0\n",
    "\n",
    "\n",
    "    # Remove all the education level edges.#5\n",
    "    biased_list =[[1, 7],  [7, 10], \n",
    "                  [8, 10], \n",
    "                  [2, 13], [9, 5], [9, 10], \n",
    "                  [7, 8], \n",
    "                  [12, 3], # Removed edge between age and ethnicity.\n",
    "                  [9, 4], \n",
    "                  [8, 3], \n",
    "                  [6, 15], # Remove this for training purposes. \n",
    "                  [7, 11], [7, 15], [13, 3], [13, 14], [10, 2], [2, 14], \n",
    "                  [5, 3], [7, 2], [9, 15], [8, 2], [14, 3], [14, 15], [4, 3], [8, 15], \n",
    "                  [13, 11], [9, 12], [8, 9],\n",
    "                 [6,9] # This is the edge from ethnicity to employed\n",
    "                 ]\n",
    "    \n",
    "    \n",
    "    biased_list =[[1, 7],  [7, 10], \n",
    "                  [8, 10], \n",
    "                  [2, 13],  [9, 10], \n",
    "                  [7, 8], \n",
    "                  [12, 3], # Removed edge between age and ethnicity.\n",
    "                  [9, 4], \n",
    "                  [8, 3], \n",
    "                  [6, 15], # Remove this for training purposes. \n",
    "                  [7, 11], [7, 15], [13, 3], [13, 14], [10, 2], [2, 14], [7, 2], [9, 15], [8, 2], [14, 3], [14, 15], [4, 3], [8, 15], \n",
    "                  [13, 11], [9, 12], [8, 9],\n",
    "                 [6,9] # This is the edge from ethnicity to employed\n",
    "                 ]\n",
    "    \n",
    "    \n",
    "    # model initialisation and train\n",
    "    model = causal_gan(dm, dag_seed = biased_list,\n",
    "               h_dim=200,\n",
    "               lr=1e-3,\n",
    "               batch_size=64,\n",
    "               lambda_privacy=0,\n",
    "               lambda_gp=10,\n",
    "               d_updates=10,\n",
    "               causal=True,\n",
    "               alpha=2,\n",
    "               rho=2,\n",
    "               weight_decay=1e-2,\n",
    "               grad_dag_loss=False,\n",
    "               l1_g=0,\n",
    "               l1_W=1e-4,\n",
    "               p_gen=-0.2,\n",
    "               use_mask=True,\n",
    "              )\n",
    "    print(model.hparams)\n",
    "    trainer = pl.Trainer(gpus=number_of_gpus, max_epochs=max_epochs, progress_bar_refresh_rate=1, profiler = False)\n",
    "    model.set_val_data(data_tensor)\n",
    "\n",
    "    print(\"Training\")\n",
    "    trainer.fit(model, dm)\n",
    "    synth_data = model.gen_synthetic(data_tensor, gen_order = model.get_gen_order(), biased_edges = bias_dict, surrogate = surrogate).detach().numpy()\n",
    "    print(synth_data.shape)\n",
    "    \n",
    "    return synth_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protected_idx = 6\n",
    "# ADSGAN\n",
    "#%% Import functions\n",
    "# from models.adsgan import adsgan\n",
    "# from models.gan import gan\n",
    "# from models.pategan import pategan\n",
    "# from models.vae import vae\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from metrics.combined import compute_metrics\n",
    "\n",
    "params = dict()\n",
    "params[\"iterations\"] = 2000\n",
    "params[\"h_dim\"] = 200\n",
    "params[\"z_dim\"] = 10\n",
    "params[\"mb_size\"] = 128\n",
    "params[\"lambda_gp\"] = 10\n",
    "params[\"d_updates\"] = 10\n",
    "params['lambda'] = 0\n",
    "\n",
    "def view_stats_new(method_list, input_data, orig_data = [], protected = '', skip_synth = False, protected_idx = -1, runs =3, bias_dict = {}, remove_protected = False, surrogate = False):\n",
    "\n",
    "    summary = ''\n",
    "    \n",
    "    samples = 5000\n",
    "    # Note that for gender 0 is female, and 1 is male\n",
    "    \n",
    "\n",
    "    \n",
    "    if not remove_protected:\n",
    "        x_pos = orig_data[orig_data[p_attr] == 0].drop(['approved'], axis = 1)[:samples]\n",
    "        y_pos = orig_data[orig_data[p_attr] == 0]['approved'][:samples]\n",
    "        x_neg = orig_data[orig_data[p_attr] == 1].drop(['approved'], axis = 1)[:samples]\n",
    "        y_neg = orig_data[orig_data[p_attr] == 1]['approved'][:samples]\n",
    "        print(len(x_pos), len(y_pos), len(x_neg), len(y_neg))\n",
    "    else:\n",
    "        input_data = input_data.drop([protected], axis = 1)\n",
    "        x_pos = orig_data[orig_data[p_attr] == 0].drop(['approved', protected], axis = 1)[:samples]\n",
    "        y_pos = orig_data[orig_data[p_attr] == 0]['approved'][:samples]\n",
    "        x_neg = orig_data[orig_data[p_attr] == 1].drop(['approved', protected], axis = 1)[:samples]\n",
    "        y_neg = orig_data[orig_data[p_attr] == 1]['approved'][:samples]\n",
    "        print(len(x_pos), len(y_pos), len(x_neg), len(y_neg))\n",
    "        \n",
    "    X_unbiased = pd.concat([x_pos, x_neg],axis=0).copy()\n",
    "    y_unbiased  = pd.concat([y_pos, y_neg],axis=0).copy()\n",
    "    \n",
    "    for method in method_list:\n",
    "        \n",
    "        params['gen_model_name'] = method.replace('-pr', '')\n",
    "        \n",
    "        if method == 'adsgan':\n",
    "            params['lambda'] = 0\n",
    "        else:\n",
    "            params['lambda'] = 1\n",
    "            \n",
    "            \n",
    "        if method == 'vae':\n",
    "            params[\"iterations\"] = 1000\n",
    "        else:\n",
    "            params[\"iterations\"] = 2000\n",
    "        err = []\n",
    "        feat_importance = []\n",
    "        recall_ratio = []\n",
    "        \n",
    "        mutual_info = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        density =[]\n",
    "        coverage = []\n",
    "        roc =[]\n",
    "        \n",
    "        for i in range(runs):\n",
    "            \n",
    "            if skip_synth:\n",
    "                synth_data = input_data.values\n",
    "            else:\n",
    "                if method == 'fairgan':\n",
    "                    # Need to swap 0 column with protected idx.\n",
    "                    temp = input_data.copy()\n",
    "                    popped = temp.pop('ethnicity')\n",
    "                    temp.insert(0, 'ethnicity', popped)\n",
    "                    \n",
    "                    pickle.dump(temp.values, open( \"adult.npy\", \"wb\" ) )\n",
    "                    synth_data, synth_data_z = train_fairgan('adult.npy')\n",
    "            \n",
    "                    # Have to swap columns back like so.... x[:,[2,1]] = x[:,[1,2]]\n",
    "                    #synth_data[:,[0,6]] = synth_data[:,[6,0]]\n",
    "                    \n",
    "                    print(\"synth before:\", synth_data.shape, synth_data_z.shape)\n",
    "                    synth_data = np.insert(synth_data, 6, synth_data_z, axis=1)\n",
    "                    print(\"synth after:\", synth_data.shape)\n",
    "\n",
    "                elif method == 'adsgan' or method == 'adsgan-pr':\n",
    "                    synth_data = adsgan(input_data, params)\n",
    "                elif method == 'gan' or method == 'wgan' or method == 'gan-pr' or method == 'wgan-pr':\n",
    "                    synth_data = gan(input_data, params)\n",
    "                elif method == 'vae':\n",
    "                    synth_data = vae(input_data, params)\n",
    "                else:\n",
    "                    synth_data = train_model(input_data, bias_dict, surrogate = surrogate)\n",
    "\n",
    "                                                     \n",
    "            # This step is to ensure at least one sample there.\n",
    "            pos_sample = input_data[input_data.approved == 0].iloc[0].values\n",
    "            neg_sample = input_data[input_data.approved == 1].iloc[0].values\n",
    "            synth_data = np.concatenate([synth_data, [pos_sample], [neg_sample]], axis = 0)        \n",
    "            X = synth_data[:,:-1]\n",
    "\n",
    "            #if remove_protected: \n",
    "            #    X = np.delete(synth_data, protected_idx, axis = 1)[:,:-1]\n",
    "            \n",
    "            y = np.round(synth_data[:, -1])\n",
    "\n",
    "            mlp = MLPClassifier(random_state = i, max_iter = 100).fit(X, y)\n",
    "            #mlp = LogisticRegression(random_state = i, max_iter = 100).fit(X, y)\n",
    "                \n",
    "            for X_unbiased, y_unbiased, _label in zip([x_pos, x_neg, pd.concat([x_pos, x_neg],axis=0).copy()], \n",
    "                                                      [y_pos, y_neg, pd.concat([y_pos, y_neg],axis=0).copy()],\n",
    "                                                      ['pos', 'neg', 'both']):\n",
    "                \n",
    "                print(\"LOGGGING\", len(X_unbiased), len(y_unbiased))\n",
    "                if not remove_protected:\n",
    "                    def compute_FTU(x):\n",
    "                        x[p_attr] = 0\n",
    "                        neg = mlp.predict(x)\n",
    "                        x[p_attr] = 1\n",
    "                        pos = mlp.predict(x)\n",
    "                        return pos-neg\n",
    "                    if _label == 'pos':\n",
    "                        FTU = compute_FTU(x_pos)\n",
    "                    elif _label == 'neg':\n",
    "                        FTU = compute_FTU(x_neg)\n",
    "                    else:\n",
    "                        x_all = pd.concat([x_pos, x_neg],axis=0)\n",
    "                        FTU = compute_FTU(x_all) \n",
    "                else:\n",
    "                    FTU = 0 # by definition\n",
    "                #print('FTU', FTU)\n",
    "                pred_pos = mlp.predict(x_pos)\n",
    "                pred_neg = mlp.predict(x_neg)\n",
    "                if _label == 'pos':\n",
    "                    DP = np.mean(pred_pos)\n",
    "                elif _label =='neg':\n",
    "                    DP = np.mean(pred_neg)\n",
    "                else:\n",
    "                    DP = np.mean(pred_pos)-np.mean(pred_neg)\n",
    "                #print('DP', DP)\n",
    "\n",
    "                CM = confusion_matrix(y_pos, mlp.predict(x_pos))\n",
    "                TN = CM[0][0]\n",
    "                FN = CM[1][0]\n",
    "                TP = CM[1][1]\n",
    "                FP = CM[0][1]\n",
    "\n",
    "                tpr_pos = CM[1][1]/(CM[0][0]+CM[0][1])\n",
    "                CM = confusion_matrix(y_neg, mlp.predict(x_neg))\n",
    "                tpr_neg = CM[1][1]/(CM[1][1]+CM[0][1])\n",
    "\n",
    "                roc.append(roc_auc_score(y_unbiased, mlp.predict_proba(X_unbiased)[:,1]))\n",
    "\n",
    "                print(tpr_pos), print(tpr_neg)\n",
    "                err.append(DP)#tpr_pos - tpr_neg)\n",
    "                if True:\n",
    "                    feat_importance.append(np.mean(FTU)) # BB 06/05 - just checking whether this leads to decent results.\n",
    "                elif protected_idx >= 0:\n",
    "                    feat_importance.append(mlp.coef_[0][protected_idx])\n",
    "\n",
    "                else:\n",
    "                    feat_importance.append(-1)\n",
    "\n",
    "                print(\"Feature Importance = \", feat_importance)\n",
    "\n",
    "                mutual_info.append(-1)\n",
    "\n",
    "\n",
    "                if remove_protected:\n",
    "                    results = compute_metrics(orig_data.drop([protected], axis = 1), synth_data,  which_metric = [['PRDC']], \n",
    "                                           wd_params = {},model = None,verbose = True)\n",
    "                else:\n",
    "                    #results = compute_metrics(orig_data.drop([protected], axis=1), np.delete(synth_data, protected_idx, 1),  which_metric = [['PRDC']], \n",
    "                    #                       wd_params = {},model = None,verbose = True)\n",
    "                    \n",
    "\n",
    "                    if _label == 'pos':\n",
    "                        results = compute_metrics(pd.concat([X_unbiased, y_unbiased],axis=1), synth_data[synth_data[:,protected_idx].astype(bool)],  which_metric = [['PRDC']], \n",
    "                                           wd_params = {},model = None,verbose = True)\n",
    "                    elif _label == 'neg':\n",
    "                        print(\"Computing neg\")\n",
    "                        print( synth_data[1-synth_data[:,protected_idx].astype(bool)].shape)\n",
    "                        results = compute_metrics(pd.concat([X_unbiased, y_unbiased],axis=1), synth_data[1-synth_data[:,protected_idx].astype(bool)],  which_metric = [['PRDC']], \n",
    "                                           wd_params = {},model = None,verbose = True)\n",
    "                    else:\n",
    "                        results = compute_metrics(pd.concat([X_unbiased, y_unbiased],axis=1), synth_data,  which_metric = [['PRDC']], \n",
    "                                           wd_params = {},model = None,verbose = True)\n",
    "                precision.append(results['precision'])\n",
    "                recall.append(results['recall'])\n",
    "                density.append(results['density'])\n",
    "                coverage.append(results['coverage'])\n",
    "\n",
    "                # Writing to file\n",
    "                with open(\"plots_surrogate_confounder_\" + _label + '.csv', \"a\") as log:\n",
    "                    # Writing data to a file\n",
    "                    log.write(method +\",\" + str(bias) + \",\" + str(results['precision']) + ',' + str(results['recall']) + ',' + str(results['density']) + \\\n",
    "                              ',' + str(results['coverage']) + ',' + str(err[-1]) + ',' + str(feat_importance[-1]) + ',' + str(roc[-1]) + '\\n')\n",
    "\n",
    "        if skip_synth:\n",
    "            print(\"no_synth\", round(np.mean(err),3), round(np.std(err),3), \n",
    "              round(np.mean(feat_importance),3), round(np.std(feat_importance),3),\n",
    "              round(np.mean(mutual_info),3), round(np.std(mutual_info),3)\n",
    "             )\n",
    "            break\n",
    "        else:\n",
    "            print(method, round(np.mean(err),3), round(np.std(err),3), \n",
    "              round(np.mean(feat_importance),3), round(np.std(feat_importance),3),\n",
    "              round(np.mean(mutual_info),3), round(np.std(mutual_info),3)\n",
    "             )\n",
    "\n",
    "        #summary+= method + '&$' + str(round(np.mean(precision),3)) + '\\pm' + str(round(np.std(precision),3)) + '$&$' + str(round(np.mean(recall),3)) + '\\pm' + str(round(np.std(recall),3)) + \\\n",
    "        #         '$&$' + str(round(np.mean(density),3)) + '\\pm' + str(round(np.std(density),3)) + '$&$' + str(round(np.mean(coverage),3)) + '\\pm' + str(round(np.std(coverage),3)) + \\\n",
    "        #         '$&$' + str(round(np.mean(err),3)) + '\\pm' + str(round(np.std(err),3)) + '$&$' + str(round(np.mean(mutual_info),3)) + '\\pm' + str(round(np.std(mutual_info),3)) + '$\\\\\\\\\\n'\n",
    "        \n",
    "        \n",
    "        summary+= method + '&$' + str(round(np.mean(precision),3)) + '\\pm' + str(round(np.std(precision),3)) + '$&$' + str(round(np.mean(recall),3)) + '\\pm' + str(round(np.std(recall),3)) + \\\n",
    "                 '$&$' + str(round(np.mean(err),3)) + '\\pm' + str(round(np.std(err),3)) + '$&$' + str(round(np.mean(feat_importance),3)) + '\\pm' + str(round(np.std(feat_importance),3)) + \\\n",
    "                 '$&$' + str(round(np.mean(roc),3)) + '\\pm' + str(round(np.std(roc),3)) +'$\\\\\\\\\\n'\n",
    "        print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "0    539\n",
      "1    139\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.218574, validLoss:0.156923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.148213, validLoss:0.130114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.119716, validLoss:0.113409, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.103095, validLoss:0.098566, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.091687, validLoss:0.087296, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.084082, validLoss:0.083334, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.080059, validLoss:0.081149, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.077696, validLoss:0.077558, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.076635, validLoss:0.077609, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.075987, validLoss:0.078112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.075589, validLoss:0.078797, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.075406, validLoss:0.076650, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.075116, validLoss:0.076500, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.074868, validLoss:0.076406, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.074839, validLoss:0.075451, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.074609, validLoss:0.075356, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.074755, validLoss:0.076365, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.074630, validLoss:0.078153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.074699, validLoss:0.077233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.074686, validLoss:0.074337, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.074662, validLoss:0.078063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.074542, validLoss:0.078099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.074649, validLoss:0.078169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.074750, validLoss:0.077040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.074653, validLoss:0.077028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.074641, validLoss:0.076155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.074764, validLoss:0.078027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.074657, validLoss:0.076109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.074555, validLoss:0.077002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.074635, validLoss:0.076103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.074667, validLoss:0.077202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.074670, validLoss:0.076160, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.074864, validLoss:0.077126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.074669, validLoss:0.076202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.074660, validLoss:0.078033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.074664, validLoss:0.077138, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.074452, validLoss:0.076335, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.074790, validLoss:0.078017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.074687, validLoss:0.076059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.074800, validLoss:0.076083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.074691, validLoss:0.076990, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.074788, validLoss:0.077124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.074703, validLoss:0.080107, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.074815, validLoss:0.077010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.074684, validLoss:0.076197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.074703, validLoss:0.075136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.074717, validLoss:0.076121, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.074735, validLoss:0.078164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.074735, validLoss:0.073335, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.074623, validLoss:0.076112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.074713, validLoss:0.078206, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.074855, validLoss:0.077010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.074836, validLoss:0.075294, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.074732, validLoss:0.077103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.074647, validLoss:0.078176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.074653, validLoss:0.077239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.074738, validLoss:0.077081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.074740, validLoss:0.076120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.074847, validLoss:0.077034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.074743, validLoss:0.075180, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.074631, validLoss:0.078101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.074553, validLoss:0.077287, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.074667, validLoss:0.079127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.074862, validLoss:0.076218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.074849, validLoss:0.079082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.074755, validLoss:0.078081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.074863, validLoss:0.077101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.074850, validLoss:0.075242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.074863, validLoss:0.076134, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.074873, validLoss:0.078086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.074762, validLoss:0.077141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.074780, validLoss:0.075170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.074866, validLoss:0.077092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.074758, validLoss:0.079069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.074786, validLoss:0.076067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.074763, validLoss:0.077387, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.074787, validLoss:0.076116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.074880, validLoss:0.077048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.074601, validLoss:0.078243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.074886, validLoss:0.076214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.074886, validLoss:0.076227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.074899, validLoss:0.077152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.074682, validLoss:0.077249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.074692, validLoss:0.075284, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.074769, validLoss:0.076083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.074788, validLoss:0.076035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.074784, validLoss:0.076158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.074784, validLoss:0.076170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.074776, validLoss:0.075245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.074667, validLoss:0.078230, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.074683, validLoss:0.078052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.063655, validLoss:0.056297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.057682, validLoss:0.056307, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.056475, validLoss:0.054081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.055495, validLoss:0.052183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.054589, validLoss:0.051518, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:96, trainLoss:0.054326, validLoss:0.051355, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.054121, validLoss:0.053336, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.053971, validLoss:0.053346, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.054075, validLoss:0.052312, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.053931, validLoss:0.053256, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.054029, validLoss:0.051236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.054039, validLoss:0.051228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.054033, validLoss:0.054271, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.053909, validLoss:0.052315, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.053918, validLoss:0.052301, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.054029, validLoss:0.052254, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.054012, validLoss:0.053249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.054034, validLoss:0.051215, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.053925, validLoss:0.052242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.053939, validLoss:0.052281, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.054042, validLoss:0.051314, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.053928, validLoss:0.052243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.053917, validLoss:0.052193, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.054036, validLoss:0.052238, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.053896, validLoss:0.051200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.053911, validLoss:0.053335, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.054023, validLoss:0.053239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.054056, validLoss:0.053325, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.054032, validLoss:0.051111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.054020, validLoss:0.052228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.048878, validLoss:0.016936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.014486, validLoss:0.012052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.009615, validLoss:0.008892, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.005589, validLoss:0.005604, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.003708, validLoss:0.003629, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.002844, validLoss:0.002279, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.002367, validLoss:0.001951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.002153, validLoss:0.001709, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.002027, validLoss:0.001571, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.002028, validLoss:0.001551, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001994, validLoss:0.001424, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001923, validLoss:0.001481, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001952, validLoss:0.001396, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001954, validLoss:0.001376, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001929, validLoss:0.001410, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001943, validLoss:0.001567, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001971, validLoss:0.001400, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001939, validLoss:0.001446, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001915, validLoss:0.001351, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001945, validLoss:0.001461, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001952, validLoss:0.001332, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001816, validLoss:0.001404, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001938, validLoss:0.001479, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001927, validLoss:0.001354, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001933, validLoss:0.001273, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001821, validLoss:0.001235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001791, validLoss:0.001300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001793, validLoss:0.001242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001777, validLoss:0.001298, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001769, validLoss:0.001407, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001791, validLoss:0.001290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001772, validLoss:0.001242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001798, validLoss:0.001269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001753, validLoss:0.001186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001739, validLoss:0.001252, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001732, validLoss:0.001280, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001714, validLoss:0.001205, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001734, validLoss:0.001224, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001723, validLoss:0.001179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001717, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001710, validLoss:0.001275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001740, validLoss:0.001389, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001737, validLoss:0.001219, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001780, validLoss:0.001158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001725, validLoss:0.001178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001754, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001718, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001707, validLoss:0.001236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001687, validLoss:0.001236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001767, validLoss:0.001218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001777, validLoss:0.001233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001726, validLoss:0.001236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001705, validLoss:0.001213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001761, validLoss:0.001229, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001755, validLoss:0.001223, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001736, validLoss:0.001097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001744, validLoss:0.001152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001718, validLoss:0.001163, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001688, validLoss:0.001277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001736, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001717, validLoss:0.001237, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001731, validLoss:0.001211, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001736, validLoss:0.001249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001731, validLoss:0.001166, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001689, validLoss:0.001206, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001716, validLoss:0.001217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001700, validLoss:0.001207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001706, validLoss:0.001161, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001728, validLoss:0.001202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001686, validLoss:0.001174, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001692, validLoss:0.001038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001730, validLoss:0.001236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001729, validLoss:0.001145, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001698, validLoss:0.001220, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001696, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001729, validLoss:0.001286, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:197, trainLoss:0.001720, validLoss:0.001182, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001686, validLoss:0.001163, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001677, validLoss:0.001174, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.148142, g_loss:2.441674, d accuracy:0.755208, d AUC:0.999349, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.773963, g_loss:2.963835, d accuracy:0.916667, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.326960, g_loss:5.051139, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:3, d_loss:0.257430, g_loss:5.221944, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.074768, g_loss:9.389007, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.076077, g_loss:9.573169, d accuracy:0.963542, d AUC:0.976888, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:6, d_loss:0.303182, g_loss:6.557766, d accuracy:0.994792, d AUC:0.992513, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:7, d_loss:0.125026, g_loss:7.494930, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.070736, g_loss:7.672877, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.030974, g_loss:8.086989, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:10, d_loss:0.326286, g_loss:5.952539, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.076341, g_loss:5.800743, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.166306, g_loss:3.329154, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.202936, g_loss:2.370698, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.080584, g_loss:3.056143, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.043507, g_loss:3.651276, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.032273, g_loss:3.865062, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.031247, g_loss:3.833278, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.075073, g_loss:4.045577, d accuracy:0.937500, d AUC:1.000000, g accuracy:0.875000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.085962, g_loss:5.475653, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.044053, g_loss:5.567878, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.016618, g_loss:6.312456, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.010899, g_loss:5.863900, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.007941, g_loss:6.197656, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.007570, g_loss:6.285232, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.007872, g_loss:6.335835, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.016918, g_loss:5.180012, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.011271, g_loss:6.434341, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.004998, g_loss:6.838274, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.003780, g_loss:6.783465, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.003267, g_loss:6.861678, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.003554, g_loss:6.869344, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.002973, g_loss:6.870656, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.003250, g_loss:6.915132, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.002718, g_loss:6.868482, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.003040, g_loss:6.763131, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.004132, g_loss:6.276686, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.005500, g_loss:6.098205, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.004579, g_loss:6.470265, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.004175, g_loss:6.736989, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.003595, g_loss:6.752070, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.003650, g_loss:6.672005, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.003524, g_loss:6.627435, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.003803, g_loss:6.595521, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.003860, g_loss:6.470772, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.003633, g_loss:6.499068, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.003720, g_loss:6.570909, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.003540, g_loss:6.538209, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.003438, g_loss:6.607682, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.003583, g_loss:6.413823, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.174380, validLoss:0.091154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.080277, validLoss:0.062831, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.057820, validLoss:0.046083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.043186, validLoss:0.033255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.034963, validLoss:0.026781, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.029931, validLoss:0.022859, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.027037, validLoss:0.018623, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.025353, validLoss:0.019191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.024140, validLoss:0.018080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.023325, validLoss:0.017463, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.022618, validLoss:0.017129, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.022534, validLoss:0.017777, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.022105, validLoss:0.017456, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:13, trainLoss:0.022039, validLoss:0.016242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.021774, validLoss:0.017225, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.021762, validLoss:0.017118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.021593, validLoss:0.015947, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.021651, validLoss:0.015912, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.021593, validLoss:0.016871, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.021453, validLoss:0.015811, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.021525, validLoss:0.015753, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.021400, validLoss:0.016681, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.021361, validLoss:0.015703, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.021343, validLoss:0.016680, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.021451, validLoss:0.016710, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.021339, validLoss:0.016711, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.021311, validLoss:0.014592, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.021230, validLoss:0.016652, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.021327, validLoss:0.016658, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.021300, validLoss:0.016656, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.021402, validLoss:0.016686, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.021293, validLoss:0.014661, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.021415, validLoss:0.015578, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.021176, validLoss:0.016626, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.021295, validLoss:0.015605, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.021398, validLoss:0.016617, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.021403, validLoss:0.014566, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.021146, validLoss:0.014557, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.021187, validLoss:0.015579, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.021412, validLoss:0.016610, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.021297, validLoss:0.015571, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.021384, validLoss:0.016570, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.021311, validLoss:0.014503, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.021130, validLoss:0.013429, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.021233, validLoss:0.016612, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.021193, validLoss:0.015557, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.021205, validLoss:0.015560, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.021212, validLoss:0.016632, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.021242, validLoss:0.015522, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.021337, validLoss:0.015563, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.021326, validLoss:0.015558, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.021328, validLoss:0.014529, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.021229, validLoss:0.016597, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.021225, validLoss:0.014531, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.021348, validLoss:0.015559, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.021355, validLoss:0.016572, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.021356, validLoss:0.016694, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.021343, validLoss:0.015599, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.021355, validLoss:0.016647, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.021112, validLoss:0.016586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.021224, validLoss:0.016639, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.021332, validLoss:0.016617, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.021350, validLoss:0.014534, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.021360, validLoss:0.015565, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.021250, validLoss:0.016608, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.021348, validLoss:0.014478, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.021259, validLoss:0.016611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.021348, validLoss:0.014527, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.021120, validLoss:0.015530, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.021242, validLoss:0.016584, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.021253, validLoss:0.016634, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.021371, validLoss:0.016620, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.021255, validLoss:0.014518, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.021247, validLoss:0.015494, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.021245, validLoss:0.016566, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.021259, validLoss:0.016597, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.021366, validLoss:0.014521, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.021273, validLoss:0.014451, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.021336, validLoss:0.016611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.021326, validLoss:0.016631, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.021288, validLoss:0.015626, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.021171, validLoss:0.014530, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.021199, validLoss:0.016593, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.021390, validLoss:0.015660, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.021391, validLoss:0.016659, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.021390, validLoss:0.016634, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.021271, validLoss:0.015561, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.021271, validLoss:0.015632, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.021394, validLoss:0.016630, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.021390, validLoss:0.016668, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.019074, validLoss:0.009784, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.012371, validLoss:0.006754, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.009489, validLoss:0.005131, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.008631, validLoss:0.004072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.008132, validLoss:0.003702, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.007900, validLoss:0.003481, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.007771, validLoss:0.003291, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.007612, validLoss:0.003307, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.007588, validLoss:0.003200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.007694, validLoss:0.003245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.007715, validLoss:0.003273, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.007679, validLoss:0.003239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.007685, validLoss:0.002245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.007677, validLoss:0.003269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.007685, validLoss:0.003186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.007665, validLoss:0.003289, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.007693, validLoss:0.003299, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.007577, validLoss:0.003296, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.007667, validLoss:0.003207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.007572, validLoss:0.003291, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:110, trainLoss:0.007690, validLoss:0.003255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.007488, validLoss:0.003283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.007699, validLoss:0.003370, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.007696, validLoss:0.003256, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.007693, validLoss:0.003203, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.007685, validLoss:0.003243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.007676, validLoss:0.003227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.007568, validLoss:0.003235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.007668, validLoss:0.003195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.007710, validLoss:0.003251, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.007699, validLoss:0.003166, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.007677, validLoss:0.003194, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.007681, validLoss:0.003282, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.007629, validLoss:0.003241, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.007696, validLoss:0.002195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.007688, validLoss:0.003178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.007683, validLoss:0.003250, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.007672, validLoss:0.003250, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.007681, validLoss:0.003310, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.007591, validLoss:0.003283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.007682, validLoss:0.003277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.007614, validLoss:0.003210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.007679, validLoss:0.003170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.007559, validLoss:0.003236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.007688, validLoss:0.003199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.007691, validLoss:0.002175, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.007573, validLoss:0.002183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.007699, validLoss:0.003337, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.007709, validLoss:0.003205, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.007568, validLoss:0.003302, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.007567, validLoss:0.003186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.007583, validLoss:0.003253, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.007434, validLoss:0.003219, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.006752, validLoss:0.003259, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.005966, validLoss:0.003048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.004223, validLoss:0.001910, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.002361, validLoss:0.001344, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001787, validLoss:0.001185, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001729, validLoss:0.001171, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001722, validLoss:0.001224, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001749, validLoss:0.001257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001749, validLoss:0.001323, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001750, validLoss:0.001209, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001727, validLoss:0.001179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001776, validLoss:0.001176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001712, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001698, validLoss:0.001223, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001730, validLoss:0.001189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001706, validLoss:0.001158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001722, validLoss:0.001163, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001727, validLoss:0.001168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001703, validLoss:0.001089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001703, validLoss:0.001207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001732, validLoss:0.001359, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001728, validLoss:0.001201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001762, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001717, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001740, validLoss:0.001200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001697, validLoss:0.001143, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001688, validLoss:0.001195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001671, validLoss:0.001195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001740, validLoss:0.001166, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001758, validLoss:0.001200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001715, validLoss:0.001210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001699, validLoss:0.001196, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001756, validLoss:0.001166, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001738, validLoss:0.001182, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001710, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001735, validLoss:0.001124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001700, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001680, validLoss:0.001242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001726, validLoss:0.001160, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001710, validLoss:0.001192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001710, validLoss:0.001178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001732, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001726, validLoss:0.001120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001684, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001711, validLoss:0.001190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001691, validLoss:0.001187, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001699, validLoss:0.001136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001722, validLoss:0.001197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001678, validLoss:0.001137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001684, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001725, validLoss:0.001199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001724, validLoss:0.001134, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001694, validLoss:0.001183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001691, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001723, validLoss:0.001259, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001717, validLoss:0.001149, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001685, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.778870, g_loss:2.705603, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.839383, g_loss:1.575179, d accuracy:0.859375, d AUC:0.948242, g accuracy:0.729167, rdf 0.000000\n",
      "Epoch:2, d_loss:0.715442, g_loss:2.706081, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:3, d_loss:0.913074, g_loss:2.754774, d accuracy:0.770833, d AUC:0.950195, g accuracy:0.968750, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, d_loss:0.443931, g_loss:4.601017, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.094597, g_loss:5.684570, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.378563, g_loss:2.490682, d accuracy:0.807292, d AUC:1.000000, g accuracy:0.614583, rdf 0.000000\n",
      "Epoch:7, d_loss:0.422618, g_loss:1.684784, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.102146, g_loss:2.836507, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.064432, g_loss:3.020750, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.061083, g_loss:3.058629, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.049896, g_loss:4.333847, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.025485, g_loss:4.372767, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.030449, g_loss:4.857823, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.020624, g_loss:4.552737, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.018122, g_loss:5.175642, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.037698, g_loss:4.813138, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.041957, g_loss:4.878044, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.012359, g_loss:5.908314, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.015007, g_loss:5.245184, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.028165, g_loss:5.567279, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.017404, g_loss:6.722835, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.009767, g_loss:7.492433, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.007081, g_loss:6.557781, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.010085, g_loss:5.046983, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.006505, g_loss:7.614223, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.003531, g_loss:7.323483, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.003363, g_loss:6.829597, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.003208, g_loss:6.586011, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.003702, g_loss:6.469240, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.738290, g_loss:6.037307, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.040009, g_loss:8.772629, d accuracy:0.947917, d AUC:1.000000, g accuracy:0.895833, rdf 0.000000\n",
      "Epoch:32, d_loss:0.192632, g_loss:6.819640, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:33, d_loss:0.163832, g_loss:7.828372, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.029173, g_loss:7.786220, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.044413, g_loss:6.807318, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.021495, g_loss:7.729726, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.020957, g_loss:7.742320, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.074456, g_loss:8.354758, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:39, d_loss:0.018357, g_loss:9.618005, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.048821, g_loss:8.045482, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.083049, g_loss:8.525629, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.033164, g_loss:7.184390, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.026532, g_loss:6.995090, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.048304, g_loss:6.234600, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:45, d_loss:0.059240, g_loss:6.001368, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.017670, g_loss:7.649867, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.036296, g_loss:5.308134, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.029379, g_loss:5.299342, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.050139, g_loss:4.195508, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.217811, validLoss:0.180011, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.165551, validLoss:0.147889, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.145159, validLoss:0.132764, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.132829, validLoss:0.123502, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.126120, validLoss:0.117515, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.122381, validLoss:0.116679, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.120124, validLoss:0.114126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.118898, validLoss:0.114046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.118203, validLoss:0.109244, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.117613, validLoss:0.112066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.117367, validLoss:0.113108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.117269, validLoss:0.112712, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.117294, validLoss:0.110786, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.103394, validLoss:0.064903, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.072066, validLoss:0.063127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.070027, validLoss:0.062950, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.069299, validLoss:0.060849, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:17, trainLoss:0.068964, validLoss:0.062842, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.068514, validLoss:0.062368, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.068105, validLoss:0.062103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.067730, validLoss:0.059366, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.067175, validLoss:0.060811, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.066941, validLoss:0.061206, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.066956, validLoss:0.061799, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.066888, validLoss:0.059808, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.066762, validLoss:0.059477, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.066652, validLoss:0.060691, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.066520, validLoss:0.060376, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.066394, validLoss:0.059604, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.066476, validLoss:0.059042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.066482, validLoss:0.059562, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.066551, validLoss:0.060589, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.049578, validLoss:0.022069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.025209, validLoss:0.017258, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.019620, validLoss:0.014649, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.017051, validLoss:0.011871, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.015813, validLoss:0.011469, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.014980, validLoss:0.010696, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.014831, validLoss:0.010342, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.014790, validLoss:0.009750, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.014618, validLoss:0.010042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.014587, validLoss:0.008748, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.014486, validLoss:0.009835, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.014275, validLoss:0.009558, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.014488, validLoss:0.009291, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.014349, validLoss:0.009649, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.014477, validLoss:0.008519, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.014484, validLoss:0.009910, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.014496, validLoss:0.009334, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.014497, validLoss:0.009726, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.014472, validLoss:0.009795, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.014468, validLoss:0.008676, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.014487, validLoss:0.009429, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.014466, validLoss:0.008641, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.014446, validLoss:0.009429, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.014487, validLoss:0.009033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.014491, validLoss:0.009767, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.014477, validLoss:0.009760, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.014484, validLoss:0.009615, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.014336, validLoss:0.008704, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.014418, validLoss:0.009620, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.014469, validLoss:0.008724, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.014481, validLoss:0.009787, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.014490, validLoss:0.009637, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.014502, validLoss:0.009381, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.014403, validLoss:0.009416, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.014370, validLoss:0.009460, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.014473, validLoss:0.008388, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.014473, validLoss:0.009389, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.014339, validLoss:0.009074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.014508, validLoss:0.009409, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.014494, validLoss:0.009310, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.014500, validLoss:0.009502, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.014459, validLoss:0.008576, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.014323, validLoss:0.009234, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.014474, validLoss:0.009479, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.014486, validLoss:0.009258, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.014480, validLoss:0.008453, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.014432, validLoss:0.009583, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.014419, validLoss:0.009619, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.014501, validLoss:0.009524, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.014405, validLoss:0.009771, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.014399, validLoss:0.009451, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.014505, validLoss:0.009645, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.014488, validLoss:0.009694, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.014501, validLoss:0.009707, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.014507, validLoss:0.008427, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.014481, validLoss:0.009689, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.014502, validLoss:0.009432, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.014496, validLoss:0.009794, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.014510, validLoss:0.008498, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.014465, validLoss:0.009568, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.014521, validLoss:0.009768, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.014496, validLoss:0.009335, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.014491, validLoss:0.009273, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.014468, validLoss:0.009686, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.014477, validLoss:0.009765, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.014383, validLoss:0.009733, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.014382, validLoss:0.009369, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.014475, validLoss:0.009320, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.014492, validLoss:0.009748, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.014450, validLoss:0.009358, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.014494, validLoss:0.008766, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.014479, validLoss:0.009656, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.014503, validLoss:0.009519, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.014439, validLoss:0.009608, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.014508, validLoss:0.009725, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.014403, validLoss:0.009554, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.014479, validLoss:0.009241, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.014390, validLoss:0.009616, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.014499, validLoss:0.009209, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.014288, validLoss:0.009331, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.014479, validLoss:0.008938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.014477, validLoss:0.009563, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.014526, validLoss:0.009120, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:115, trainLoss:0.014469, validLoss:0.009029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.014441, validLoss:0.009158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.014395, validLoss:0.009708, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.014452, validLoss:0.009303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.014531, validLoss:0.009429, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.014498, validLoss:0.008328, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.014478, validLoss:0.009501, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.014510, validLoss:0.008905, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.014449, validLoss:0.009266, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.014500, validLoss:0.008713, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.014421, validLoss:0.009188, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.014446, validLoss:0.009541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.014470, validLoss:0.009715, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.014492, validLoss:0.009654, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.014414, validLoss:0.009715, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.014492, validLoss:0.009589, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.014422, validLoss:0.008856, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.014519, validLoss:0.009333, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.014326, validLoss:0.009611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.014516, validLoss:0.009208, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.014500, validLoss:0.008347, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.014381, validLoss:0.007991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.014540, validLoss:0.009831, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.014508, validLoss:0.009612, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.014398, validLoss:0.009435, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.014379, validLoss:0.008898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.014422, validLoss:0.009352, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.014502, validLoss:0.009135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.014355, validLoss:0.009683, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.014506, validLoss:0.009742, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.014445, validLoss:0.009080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.014398, validLoss:0.008748, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.014525, validLoss:0.009355, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.014474, validLoss:0.009738, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.014473, validLoss:0.008552, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.012972, validLoss:0.005992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.009927, validLoss:0.005035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.009547, validLoss:0.003801, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.009472, validLoss:0.004630, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.009236, validLoss:0.004586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.008989, validLoss:0.004265, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.009004, validLoss:0.004512, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.008737, validLoss:0.004242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.008651, validLoss:0.004104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.008528, validLoss:0.003936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.008365, validLoss:0.003731, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.008175, validLoss:0.003570, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.008047, validLoss:0.003463, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.007954, validLoss:0.003585, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.007889, validLoss:0.003416, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.007892, validLoss:0.003326, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.007805, validLoss:0.003251, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.007794, validLoss:0.003274, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.007735, validLoss:0.002227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.007727, validLoss:0.003264, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.007709, validLoss:0.003279, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.007760, validLoss:0.003209, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.007657, validLoss:0.002215, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.007726, validLoss:0.003262, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.007696, validLoss:0.003256, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.007755, validLoss:0.003245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.007729, validLoss:0.003239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.007709, validLoss:0.003124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.007614, validLoss:0.003141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.007680, validLoss:0.003162, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.007568, validLoss:0.003286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.007609, validLoss:0.003184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.007700, validLoss:0.003224, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.007584, validLoss:0.003212, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.007713, validLoss:0.003279, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.007712, validLoss:0.003154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.007676, validLoss:0.003216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.007690, validLoss:0.003206, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.007571, validLoss:0.003213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.007680, validLoss:0.002122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.007594, validLoss:0.003179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.007552, validLoss:0.003181, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.007676, validLoss:0.003062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.007702, validLoss:0.003228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.007698, validLoss:0.003173, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.007689, validLoss:0.003239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.007570, validLoss:0.003153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.007494, validLoss:0.003246, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.007695, validLoss:0.003169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.007562, validLoss:0.003158, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.039586, g_loss:2.656053, d accuracy:0.869792, d AUC:0.991862, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:1, d_loss:0.724024, g_loss:2.954726, d accuracy:0.875000, d AUC:0.965169, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:2, d_loss:0.381136, g_loss:6.199503, d accuracy:0.968750, d AUC:0.990234, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:3, d_loss:0.304906, g_loss:8.599987, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.121792, g_loss:8.463143, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.121606, g_loss:6.204272, d accuracy:0.989583, d AUC:0.998372, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:6, d_loss:0.139219, g_loss:6.271078, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:7, d_loss:0.044342, g_loss:6.903997, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, d_loss:0.030060, g_loss:6.568933, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.018939, g_loss:7.345614, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.035030, g_loss:7.988108, d accuracy:0.895833, d AUC:1.000000, g accuracy:0.791667, rdf 0.000000\n",
      "Epoch:11, d_loss:0.218436, g_loss:3.844236, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:12, d_loss:0.205619, g_loss:2.692442, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:13, d_loss:0.143125, g_loss:2.718833, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.037996, g_loss:4.032997, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.039814, g_loss:3.941716, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.045570, g_loss:3.621958, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.017620, g_loss:5.336222, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.009942, g_loss:5.590993, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.007591, g_loss:5.406272, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.015342, g_loss:5.177551, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:21, d_loss:0.042325, g_loss:5.424726, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.008747, g_loss:7.246614, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.006252, g_loss:6.417222, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.004585, g_loss:6.448071, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.004237, g_loss:6.423396, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.010991, g_loss:5.799479, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:27, d_loss:0.016153, g_loss:10.688683, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.110576, g_loss:4.977592, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.060468, g_loss:5.394795, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.035613, g_loss:6.185109, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.145448, g_loss:7.222509, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.027260, g_loss:9.301420, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.014592, g_loss:7.447044, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.135410, g_loss:4.343956, d accuracy:0.916667, d AUC:0.971354, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:35, d_loss:0.279624, g_loss:4.589776, d accuracy:0.979167, d AUC:0.994141, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:36, d_loss:0.355940, g_loss:7.762653, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.036453, g_loss:10.906615, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:38, d_loss:0.066722, g_loss:8.184048, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:39, d_loss:0.120715, g_loss:6.291531, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.030182, g_loss:9.228917, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.104450, g_loss:6.440369, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.051315, g_loss:6.574501, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:43, d_loss:0.116091, g_loss:4.499945, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.096146, g_loss:5.523103, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.102013, g_loss:4.225438, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.158765, g_loss:3.509185, d accuracy:0.989583, d AUC:0.999349, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.223538, g_loss:2.919237, d accuracy:0.937500, d AUC:0.970703, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:48, d_loss:0.201859, g_loss:4.588056, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:49, d_loss:0.122860, g_loss:5.167422, d accuracy:0.979167, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n",
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "0    491\n",
      "1    187\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.218331, validLoss:0.152869, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.105628, validLoss:0.058586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.060083, validLoss:0.043766, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.043343, validLoss:0.031385, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.033742, validLoss:0.024619, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.027532, validLoss:0.019465, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.023279, validLoss:0.016109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.020617, validLoss:0.012437, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.018856, validLoss:0.012471, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.017643, validLoss:0.011383, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.016994, validLoss:0.011063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.016492, validLoss:0.010746, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.016147, validLoss:0.010466, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.015465, validLoss:0.009651, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.015174, validLoss:0.009982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.014939, validLoss:0.008298, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.014918, validLoss:0.009587, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.014832, validLoss:0.009576, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.014783, validLoss:0.009692, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.014705, validLoss:0.008341, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:20, trainLoss:0.014561, validLoss:0.008997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.014514, validLoss:0.009594, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.014557, validLoss:0.009261, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.014570, validLoss:0.009406, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.014540, validLoss:0.009191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.014484, validLoss:0.009417, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.014388, validLoss:0.009155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.014389, validLoss:0.009444, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.014483, validLoss:0.008892, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.014477, validLoss:0.009436, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.014452, validLoss:0.009428, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.014447, validLoss:0.009324, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.014449, validLoss:0.009322, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.014346, validLoss:0.009527, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.014441, validLoss:0.008756, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.014450, validLoss:0.009400, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.014190, validLoss:0.009437, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.014337, validLoss:0.009308, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.014449, validLoss:0.008995, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.014401, validLoss:0.009487, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.014437, validLoss:0.008260, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.014380, validLoss:0.009457, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.014204, validLoss:0.009236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.014430, validLoss:0.008957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.014292, validLoss:0.009343, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.014442, validLoss:0.008214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.014432, validLoss:0.009564, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.014439, validLoss:0.009077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.014443, validLoss:0.009462, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.014436, validLoss:0.009576, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.014432, validLoss:0.008397, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.014436, validLoss:0.009176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.014433, validLoss:0.008407, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.014412, validLoss:0.009187, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.014458, validLoss:0.008823, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.014460, validLoss:0.009511, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.014437, validLoss:0.009562, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.014445, validLoss:0.009386, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.014303, validLoss:0.008474, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.014392, validLoss:0.009430, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.014440, validLoss:0.008551, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.014450, validLoss:0.009580, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.014463, validLoss:0.009448, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.014467, validLoss:0.009197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.014379, validLoss:0.009230, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.014345, validLoss:0.009280, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.014432, validLoss:0.008188, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.014436, validLoss:0.009229, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.014431, validLoss:0.008863, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.014461, validLoss:0.009212, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.014456, validLoss:0.009119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.014460, validLoss:0.009315, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.014421, validLoss:0.008426, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.014291, validLoss:0.009094, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.014432, validLoss:0.009324, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.014457, validLoss:0.009047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.014443, validLoss:0.008307, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.014406, validLoss:0.009425, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.014374, validLoss:0.009477, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.014464, validLoss:0.009315, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.014365, validLoss:0.009607, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.014360, validLoss:0.009268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.014453, validLoss:0.009455, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.014447, validLoss:0.009529, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.014450, validLoss:0.009538, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.014468, validLoss:0.008266, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.014449, validLoss:0.009544, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.014473, validLoss:0.009277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.014452, validLoss:0.009587, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.014461, validLoss:0.008367, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.014433, validLoss:0.009418, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.014479, validLoss:0.009589, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.014452, validLoss:0.009202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.014449, validLoss:0.009108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.014433, validLoss:0.009525, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.014439, validLoss:0.009632, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.014350, validLoss:0.009607, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.014349, validLoss:0.009254, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.014445, validLoss:0.009176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.014456, validLoss:0.009625, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.014420, validLoss:0.009240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.014462, validLoss:0.008607, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.014442, validLoss:0.009518, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.014469, validLoss:0.009384, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.014404, validLoss:0.009464, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.014469, validLoss:0.009611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.014362, validLoss:0.009397, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.014448, validLoss:0.009111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.014354, validLoss:0.009475, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.014469, validLoss:0.009073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.014258, validLoss:0.009221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.014448, validLoss:0.008813, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.014445, validLoss:0.009435, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.014492, validLoss:0.008992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.014427, validLoss:0.008900, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.014400, validLoss:0.009016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.014354, validLoss:0.009607, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.014421, validLoss:0.009195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.014493, validLoss:0.009338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.014456, validLoss:0.008181, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.014436, validLoss:0.009385, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:121, trainLoss:0.014483, validLoss:0.008774, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.014406, validLoss:0.009153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.014463, validLoss:0.008592, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.014391, validLoss:0.009111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.014426, validLoss:0.009435, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.014441, validLoss:0.009640, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.014469, validLoss:0.009542, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.014373, validLoss:0.009602, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.014462, validLoss:0.009469, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.014383, validLoss:0.008715, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.014476, validLoss:0.009217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.014298, validLoss:0.009508, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.014488, validLoss:0.009102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.014476, validLoss:0.008272, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.014361, validLoss:0.007877, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.014497, validLoss:0.009745, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.014480, validLoss:0.009514, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.014362, validLoss:0.009305, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.014344, validLoss:0.008774, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.014383, validLoss:0.009283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.013319, validLoss:0.006950, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.009857, validLoss:0.004850, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.009546, validLoss:0.004671, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.009314, validLoss:0.004316, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.008923, validLoss:0.004053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.008656, validLoss:0.003761, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.008237, validLoss:0.003514, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.007992, validLoss:0.002304, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.007804, validLoss:0.003253, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.007737, validLoss:0.003263, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.007712, validLoss:0.002106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.007660, validLoss:0.003103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.007720, validLoss:0.003089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.007535, validLoss:0.003013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.007631, validLoss:0.003169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.007544, validLoss:0.003106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.007633, validLoss:0.003088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.007648, validLoss:0.003098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.007649, validLoss:0.003038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.007625, validLoss:0.003011, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.007630, validLoss:0.003120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.007675, validLoss:0.003303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.007669, validLoss:0.003135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.007710, validLoss:0.003119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.007644, validLoss:0.003051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.007646, validLoss:0.003119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.007608, validLoss:0.002055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.007437, validLoss:0.003439, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.006850, validLoss:0.003179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.006045, validLoss:0.003299, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.004249, validLoss:0.001469, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.002372, validLoss:0.001263, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001740, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001719, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001732, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001690, validLoss:0.000965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001706, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001665, validLoss:0.001016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001645, validLoss:0.001148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001695, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001682, validLoss:0.001075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001674, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001680, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001679, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001656, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001662, validLoss:0.001051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001643, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001659, validLoss:0.001020, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001692, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001630, validLoss:0.001033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001644, validLoss:0.000897, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001685, validLoss:0.001091, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001689, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001662, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001650, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001687, validLoss:0.001124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001674, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001647, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001638, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.063451, g_loss:2.496492, d accuracy:0.869792, d AUC:0.937500, g accuracy:0.875000, rdf 0.000000\n",
      "Epoch:1, d_loss:1.377901, g_loss:0.632723, d accuracy:0.500000, d AUC:0.611654, g accuracy:0.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.998814, g_loss:0.937066, d accuracy:0.598958, d AUC:0.960286, g accuracy:0.197917, rdf 0.000000\n",
      "Epoch:3, d_loss:0.882833, g_loss:1.344382, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.391743, g_loss:2.268419, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.224266, g_loss:3.482432, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:6, d_loss:0.353456, g_loss:3.092727, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.092072, g_loss:3.283959, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.072768, g_loss:2.857371, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.074784, g_loss:4.526856, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.156088, g_loss:3.101633, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.036403, g_loss:6.826721, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.106442, g_loss:3.701141, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, d_loss:0.068656, g_loss:5.722401, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.013491, g_loss:7.912333, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.079185, g_loss:5.133710, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.035130, g_loss:6.171492, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.021622, g_loss:5.868528, d accuracy:0.989583, d AUC:0.995768, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:18, d_loss:0.365093, g_loss:7.843291, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.098934, g_loss:6.703734, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.056480, g_loss:6.429591, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.032699, g_loss:7.258026, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:22, d_loss:0.109350, g_loss:6.965293, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.039066, g_loss:10.794703, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.043585, g_loss:9.328813, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.080254, g_loss:6.880125, d accuracy:0.968750, d AUC:0.994141, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:26, d_loss:0.133167, g_loss:9.009174, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.029485, g_loss:10.204918, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.015893, g_loss:10.846954, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.014935, g_loss:9.200221, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.230952, g_loss:9.567917, d accuracy:0.895833, d AUC:0.992513, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:31, d_loss:0.413802, g_loss:6.769230, d accuracy:0.958333, d AUC:0.998047, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.128273, g_loss:7.731856, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.053218, g_loss:8.457486, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.037966, g_loss:8.244366, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.034943, g_loss:7.211822, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.083574, g_loss:5.903756, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.178316, g_loss:5.105319, d accuracy:0.968750, d AUC:0.995117, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:38, d_loss:0.313931, g_loss:5.216603, d accuracy:0.973958, d AUC:1.000000, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:39, d_loss:0.220541, g_loss:4.477319, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:40, d_loss:0.224907, g_loss:3.903728, d accuracy:0.963542, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.372455, g_loss:3.104536, d accuracy:0.760417, d AUC:0.852539, g accuracy:0.750000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.268374, g_loss:4.112247, d accuracy:0.958333, d AUC:0.998047, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:43, d_loss:0.299514, g_loss:3.271544, d accuracy:0.968750, d AUC:0.991536, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:44, d_loss:0.311861, g_loss:3.106071, d accuracy:0.963542, d AUC:0.993164, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:45, d_loss:0.316616, g_loss:3.285562, d accuracy:0.973958, d AUC:0.998372, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:46, d_loss:0.294787, g_loss:2.788517, d accuracy:0.973958, d AUC:0.992513, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:47, d_loss:0.361185, g_loss:2.774165, d accuracy:0.963542, d AUC:0.992839, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:48, d_loss:0.406283, g_loss:2.372124, d accuracy:0.942708, d AUC:0.991536, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:49, d_loss:0.352576, g_loss:2.987855, d accuracy:0.963542, d AUC:0.997070, g accuracy:0.958333, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.224335, validLoss:0.169658, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.143732, validLoss:0.125476, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.122269, validLoss:0.114984, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.110269, validLoss:0.103238, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.102318, validLoss:0.097570, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.097011, validLoss:0.092201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.094241, validLoss:0.087930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.092595, validLoss:0.088845, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.091250, validLoss:0.087770, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.090507, validLoss:0.086098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.087796, validLoss:0.085855, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.087456, validLoss:0.084823, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.086827, validLoss:0.084711, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.086536, validLoss:0.084019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.086237, validLoss:0.085122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.086123, validLoss:0.084633, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.085858, validLoss:0.083490, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.085773, validLoss:0.083037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.085664, validLoss:0.086216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.085588, validLoss:0.082100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.085465, validLoss:0.081952, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.085352, validLoss:0.085405, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.085242, validLoss:0.083104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.085168, validLoss:0.082638, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.085247, validLoss:0.083421, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.084933, validLoss:0.084461, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.084754, validLoss:0.082543, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.084796, validLoss:0.084684, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.084868, validLoss:0.083904, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.084895, validLoss:0.084330, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.084959, validLoss:0.082076, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.084800, validLoss:0.081890, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.085037, validLoss:0.081518, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.084810, validLoss:0.083654, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:34, trainLoss:0.084825, validLoss:0.082789, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.084982, validLoss:0.084368, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.084790, validLoss:0.082708, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.084812, validLoss:0.080789, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.084741, validLoss:0.084518, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.085003, validLoss:0.083053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.084955, validLoss:0.083358, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.084843, validLoss:0.084200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.085019, validLoss:0.082741, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.084866, validLoss:0.081845, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.084948, validLoss:0.085588, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.084891, validLoss:0.082764, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.084904, validLoss:0.082067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.084764, validLoss:0.085384, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.085003, validLoss:0.082751, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.085114, validLoss:0.081027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.084980, validLoss:0.083080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.085061, validLoss:0.082043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.085008, validLoss:0.082879, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.084976, validLoss:0.081338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.085107, validLoss:0.082285, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.084962, validLoss:0.084586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.085028, validLoss:0.085043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.085108, validLoss:0.084064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.084945, validLoss:0.084456, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.084871, validLoss:0.085713, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.084955, validLoss:0.082374, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.084953, validLoss:0.085509, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.084904, validLoss:0.080957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.084919, validLoss:0.084142, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.084841, validLoss:0.083583, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.085122, validLoss:0.082567, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.084879, validLoss:0.084819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.084980, validLoss:0.083137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.084874, validLoss:0.082750, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.084931, validLoss:0.084201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.084933, validLoss:0.083958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.085120, validLoss:0.084428, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.084805, validLoss:0.081628, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.084961, validLoss:0.082441, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.084973, validLoss:0.084311, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.084845, validLoss:0.083393, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.085077, validLoss:0.081374, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.084926, validLoss:0.082268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.085083, validLoss:0.085193, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.084854, validLoss:0.084100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.084994, validLoss:0.083388, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.084915, validLoss:0.082931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.084797, validLoss:0.084997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.085102, validLoss:0.082487, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.085018, validLoss:0.083444, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.085159, validLoss:0.084720, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.084987, validLoss:0.083553, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.084976, validLoss:0.082416, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.085024, validLoss:0.083982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.085112, validLoss:0.083330, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.085085, validLoss:0.081478, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.084886, validLoss:0.083516, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.084963, validLoss:0.083503, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.085006, validLoss:0.083521, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.085149, validLoss:0.083512, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.084948, validLoss:0.083821, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.085032, validLoss:0.083791, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.084775, validLoss:0.083124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.084911, validLoss:0.084230, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.084913, validLoss:0.084428, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.085016, validLoss:0.083270, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.084468, validLoss:0.081718, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.083917, validLoss:0.082275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.082370, validLoss:0.081834, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.079929, validLoss:0.079609, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.079112, validLoss:0.081366, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.079024, validLoss:0.081576, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.079123, validLoss:0.080100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.078965, validLoss:0.082289, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.079107, validLoss:0.083224, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.079047, validLoss:0.079797, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.079042, validLoss:0.082541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.078946, validLoss:0.081693, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.079151, validLoss:0.083480, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.078972, validLoss:0.082349, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.078846, validLoss:0.083496, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.079010, validLoss:0.080904, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.079089, validLoss:0.079273, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.079089, validLoss:0.081019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.079041, validLoss:0.081930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.079048, validLoss:0.083085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.078810, validLoss:0.081041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.079153, validLoss:0.083154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.079146, validLoss:0.080829, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.079160, validLoss:0.083442, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.079151, validLoss:0.082605, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.079034, validLoss:0.080889, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.079198, validLoss:0.081697, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.079199, validLoss:0.082218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.078950, validLoss:0.083131, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.079108, validLoss:0.082249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.079120, validLoss:0.082345, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.079056, validLoss:0.082350, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:133, trainLoss:0.078984, validLoss:0.081973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.079164, validLoss:0.082649, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.079205, validLoss:0.082124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.079058, validLoss:0.081662, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.078946, validLoss:0.080469, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.079014, validLoss:0.082746, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.079057, validLoss:0.082154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.078779, validLoss:0.082188, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.074528, validLoss:0.075021, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.066513, validLoss:0.068951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.062583, validLoss:0.066303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.061145, validLoss:0.065577, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.060592, validLoss:0.064342, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.060498, validLoss:0.065631, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.042869, validLoss:0.029083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.025457, validLoss:0.026551, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.023899, validLoss:0.025682, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.023537, validLoss:0.025123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.023362, validLoss:0.025504, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.023322, validLoss:0.023377, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.023164, validLoss:0.024306, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.023170, validLoss:0.024171, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.023029, validLoss:0.025216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.023063, validLoss:0.023354, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.023080, validLoss:0.023151, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.022989, validLoss:0.024294, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.023060, validLoss:0.024354, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.022990, validLoss:0.024304, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.023064, validLoss:0.024420, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.023056, validLoss:0.025381, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.023033, validLoss:0.023841, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.023045, validLoss:0.024017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.022907, validLoss:0.023931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.022962, validLoss:0.025098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.023077, validLoss:0.022645, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.015100, validLoss:0.008136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.008259, validLoss:0.006912, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.007379, validLoss:0.006819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.006889, validLoss:0.005854, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.005701, validLoss:0.004128, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.003803, validLoss:0.002478, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.002414, validLoss:0.001451, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001907, validLoss:0.001150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001751, validLoss:0.001113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001733, validLoss:0.001059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001754, validLoss:0.001110, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001706, validLoss:0.001067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001683, validLoss:0.001216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001720, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001723, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001704, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001714, validLoss:0.001100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001711, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001683, validLoss:0.001107, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001700, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001664, validLoss:0.001136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001666, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001706, validLoss:0.001128, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001639, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001667, validLoss:0.000936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001720, validLoss:0.001128, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001698, validLoss:0.001109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001674, validLoss:0.001068, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001644, validLoss:0.000989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001702, validLoss:0.001175, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001691, validLoss:0.001063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001647, validLoss:0.001060, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.273923, g_loss:2.239119, d accuracy:0.734375, d AUC:0.953125, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.772507, g_loss:3.751825, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.804749, g_loss:4.668549, d accuracy:0.708333, d AUC:0.958333, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:3, d_loss:0.292980, g_loss:6.574879, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.037564, g_loss:7.223882, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.255114, g_loss:6.610352, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.075429, g_loss:8.213394, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.065620, g_loss:7.731009, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:8, d_loss:0.077488, g_loss:6.875589, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.074768, g_loss:9.655113, d accuracy:0.979167, d AUC:0.996745, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:10, d_loss:0.068422, g_loss:12.421457, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.038266, g_loss:7.679053, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.032675, g_loss:6.045535, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.061209, g_loss:5.123127, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.170053, g_loss:2.688115, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:15, d_loss:0.065143, g_loss:3.098186, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.108981, g_loss:2.871935, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.057558, g_loss:4.444509, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.033365, g_loss:4.573637, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.017449, g_loss:5.151598, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.021800, g_loss:4.870001, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:21, d_loss:0.028168, g_loss:4.741089, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22, d_loss:0.023330, g_loss:4.931728, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.020838, g_loss:5.414270, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.064759, g_loss:6.200958, d accuracy:0.963542, d AUC:0.983724, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:25, d_loss:0.200307, g_loss:5.697162, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.048619, g_loss:6.618174, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.125027, g_loss:5.907831, d accuracy:0.838542, d AUC:0.972982, g accuracy:0.677083, rdf 0.000000\n",
      "Epoch:28, d_loss:0.232597, g_loss:6.566691, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:29, d_loss:0.057879, g_loss:6.840197, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.038750, g_loss:6.900853, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.038641, g_loss:6.216549, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.044946, g_loss:4.691587, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.029835, g_loss:5.006173, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.413903, g_loss:2.745063, d accuracy:0.927083, d AUC:0.980143, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:35, d_loss:0.094387, g_loss:6.009633, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.035869, g_loss:5.406939, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.123810, g_loss:4.439677, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.074317, g_loss:5.672025, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.159254, g_loss:5.688817, d accuracy:0.932292, d AUC:0.980143, g accuracy:0.864583, rdf 0.000000\n",
      "Epoch:40, d_loss:0.235554, g_loss:4.042721, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:41, d_loss:0.068797, g_loss:6.335860, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.088156, g_loss:7.119414, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.055710, g_loss:7.111319, d accuracy:0.984375, d AUC:0.999674, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:44, d_loss:0.222415, g_loss:5.271588, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:45, d_loss:0.117718, g_loss:5.201021, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.147719, g_loss:4.564481, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:47, d_loss:0.104195, g_loss:4.665981, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.101109, g_loss:4.698219, d accuracy:0.984375, d AUC:0.997396, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:49, d_loss:0.194482, g_loss:2.889760, d accuracy:0.989583, d AUC:0.999023, g accuracy:0.979167, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.186587, validLoss:0.120498, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.111609, validLoss:0.095842, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.089121, validLoss:0.075864, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.074596, validLoss:0.066780, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.066626, validLoss:0.060216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.062106, validLoss:0.058572, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.059134, validLoss:0.056694, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.057383, validLoss:0.054459, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.056154, validLoss:0.052530, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.055399, validLoss:0.052054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.054941, validLoss:0.052861, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.054648, validLoss:0.052705, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.054522, validLoss:0.051398, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.054209, validLoss:0.051267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.054078, validLoss:0.051214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.053965, validLoss:0.051188, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.053945, validLoss:0.051137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.053901, validLoss:0.052154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.053878, validLoss:0.052086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.053851, validLoss:0.052106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.053831, validLoss:0.051024, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.053816, validLoss:0.052025, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.053789, validLoss:0.052050, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.053897, validLoss:0.053073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.053898, validLoss:0.050998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.053900, validLoss:0.051005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.053885, validLoss:0.052002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.053902, validLoss:0.052033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.053798, validLoss:0.050987, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.053789, validLoss:0.050985, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.053770, validLoss:0.051022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.053891, validLoss:0.052100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.053795, validLoss:0.052001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.053995, validLoss:0.052052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.053900, validLoss:0.052038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.053786, validLoss:0.052031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.053789, validLoss:0.052070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.053664, validLoss:0.053097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.053906, validLoss:0.052015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.053808, validLoss:0.050991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.053914, validLoss:0.050993, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.053809, validLoss:0.050983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.053890, validLoss:0.052048, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:43, trainLoss:0.053820, validLoss:0.054106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.053934, validLoss:0.051012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.053802, validLoss:0.052048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.053815, validLoss:0.050974, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.053925, validLoss:0.051045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.053854, validLoss:0.053096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.053847, validLoss:0.051045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.053833, validLoss:0.051035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.053832, validLoss:0.053122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.053949, validLoss:0.050984, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.053943, validLoss:0.052064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.053838, validLoss:0.052032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.053854, validLoss:0.053098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.053861, validLoss:0.052177, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.053846, validLoss:0.051080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.053846, validLoss:0.051047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.053951, validLoss:0.051053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.053958, validLoss:0.051036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.053841, validLoss:0.052131, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.053860, validLoss:0.053139, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.053872, validLoss:0.053130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.053863, validLoss:0.051963, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.053797, validLoss:0.052967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.053702, validLoss:0.051921, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.053808, validLoss:0.051929, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.053787, validLoss:0.051886, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.053774, validLoss:0.051878, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.053792, validLoss:0.051928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.053675, validLoss:0.051917, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.053783, validLoss:0.050866, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.053771, validLoss:0.051852, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.053667, validLoss:0.052949, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.053790, validLoss:0.050869, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.053670, validLoss:0.053997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.053795, validLoss:0.051850, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.053783, validLoss:0.050868, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.053629, validLoss:0.053013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.053808, validLoss:0.051965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.053812, validLoss:0.051932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.053812, validLoss:0.051907, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.053696, validLoss:0.051996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.053699, validLoss:0.050935, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.053683, validLoss:0.050886, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.053788, validLoss:0.050860, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.053793, validLoss:0.050928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.053694, validLoss:0.050930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.053694, validLoss:0.050931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.053681, validLoss:0.053017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.053701, validLoss:0.051902, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.053809, validLoss:0.050948, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.053675, validLoss:0.052929, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.053786, validLoss:0.051926, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.053929, validLoss:0.050882, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.053801, validLoss:0.050891, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.053901, validLoss:0.050936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.053806, validLoss:0.052987, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.053698, validLoss:0.052967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.053822, validLoss:0.051981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.053682, validLoss:0.052975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.053794, validLoss:0.050898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.053796, validLoss:0.050930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.053821, validLoss:0.053989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.053684, validLoss:0.051991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.053695, validLoss:0.051998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.053810, validLoss:0.051969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.053795, validLoss:0.052968, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.053811, validLoss:0.050940, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.053707, validLoss:0.051953, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.053731, validLoss:0.051989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.053829, validLoss:0.051008, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.053731, validLoss:0.051993, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.053706, validLoss:0.051918, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.053817, validLoss:0.051956, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.053692, validLoss:0.050878, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.053696, validLoss:0.053056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.053815, validLoss:0.052985, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.053844, validLoss:0.053069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.053844, validLoss:0.050828, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.053807, validLoss:0.051931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.053710, validLoss:0.050930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.053857, validLoss:0.051965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.053725, validLoss:0.052002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.053834, validLoss:0.050898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.053720, validLoss:0.050926, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.053701, validLoss:0.053047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.053712, validLoss:0.050979, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.053837, validLoss:0.050952, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.053701, validLoss:0.050961, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.053744, validLoss:0.050876, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.053712, validLoss:0.051932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.053684, validLoss:0.053040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.053739, validLoss:0.050893, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.053716, validLoss:0.050910, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.053816, validLoss:0.051938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.053842, validLoss:0.052070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.053730, validLoss:0.051935, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:139, trainLoss:0.053806, validLoss:0.050959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.053692, validLoss:0.051908, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.053715, validLoss:0.052017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.053724, validLoss:0.050896, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.053581, validLoss:0.050911, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.053709, validLoss:0.050966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.053694, validLoss:0.052972, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.053703, validLoss:0.050894, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.053696, validLoss:0.051928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.053812, validLoss:0.051988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.053818, validLoss:0.050934, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.053833, validLoss:0.053051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.053862, validLoss:0.052100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.053766, validLoss:0.052052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.053852, validLoss:0.050911, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.053763, validLoss:0.051948, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.053806, validLoss:0.051879, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.053698, validLoss:0.050940, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.053728, validLoss:0.052031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.053017, validLoss:0.030650, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.017799, validLoss:0.012610, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.010886, validLoss:0.010869, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.007753, validLoss:0.007729, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.005308, validLoss:0.004782, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.003298, validLoss:0.002395, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.002203, validLoss:0.001393, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001913, validLoss:0.001235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001747, validLoss:0.001094, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001744, validLoss:0.001136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001685, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001675, validLoss:0.001107, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001652, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001724, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001738, validLoss:0.001095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001693, validLoss:0.001101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001670, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001719, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001708, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001690, validLoss:0.000981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001714, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001672, validLoss:0.001007, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001654, validLoss:0.001154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001708, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001689, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001684, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001691, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001685, validLoss:0.000982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001660, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001676, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001659, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001667, validLoss:0.000991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001694, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001633, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001647, validLoss:0.000886, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001691, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001694, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001662, validLoss:0.001045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001658, validLoss:0.000989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001694, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001679, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001647, validLoss:0.001019, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.192112, g_loss:2.411708, d accuracy:0.744792, d AUC:0.893229, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:1, d_loss:1.011104, g_loss:2.239137, d accuracy:0.854167, d AUC:0.939128, g accuracy:0.895833, rdf 0.000000\n",
      "Epoch:2, d_loss:0.686823, g_loss:2.383452, d accuracy:0.822917, d AUC:0.927734, g accuracy:0.645833, rdf 0.000000\n",
      "Epoch:3, d_loss:0.476458, g_loss:3.460788, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.149369, g_loss:5.119318, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:5, d_loss:0.081223, g_loss:5.758255, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.096922, g_loss:5.073680, d accuracy:0.822917, d AUC:1.000000, g accuracy:0.645833, rdf 0.000000\n",
      "Epoch:7, d_loss:0.165060, g_loss:3.835768, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:8, d_loss:0.096001, g_loss:3.960238, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.106192, g_loss:2.729094, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:10, d_loss:0.131911, g_loss:3.233294, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.115943, g_loss:5.169898, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.017154, g_loss:6.622590, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:13, d_loss:0.160138, g_loss:4.348687, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.019265, g_loss:6.346498, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.063993, g_loss:4.864404, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.017124, g_loss:7.043317, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.032708, g_loss:4.301384, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.012229, g_loss:6.578459, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.007815, g_loss:5.937963, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.006872, g_loss:5.830872, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.005849, g_loss:5.816207, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.005442, g_loss:5.950440, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.005564, g_loss:6.187677, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.004883, g_loss:6.446977, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.004171, g_loss:6.640954, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26, d_loss:0.003653, g_loss:6.731928, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.003442, g_loss:6.785794, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.003281, g_loss:6.795803, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.003222, g_loss:6.836487, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.003021, g_loss:6.765671, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.003873, g_loss:6.388126, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.003613, g_loss:6.707597, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.002964, g_loss:7.367580, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.003090, g_loss:7.061777, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.002430, g_loss:6.886746, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.002554, g_loss:6.799039, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.002671, g_loss:6.783320, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.002771, g_loss:6.695390, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.002668, g_loss:6.662940, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.003170, g_loss:6.645545, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.002956, g_loss:6.691343, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.002567, g_loss:6.719769, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.002704, g_loss:6.691710, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.006336, g_loss:5.427679, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.007633, g_loss:8.425447, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.002095, g_loss:7.931950, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.002476, g_loss:6.803398, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.003655, g_loss:6.116786, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.003683, g_loss:6.718357, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n",
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "0    444\n",
      "1    234\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.142509, validLoss:0.088659, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.080816, validLoss:0.065991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.059709, validLoss:0.050695, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.047870, validLoss:0.042286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.040642, validLoss:0.034581, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.036089, validLoss:0.029904, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.033406, validLoss:0.028663, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.031638, validLoss:0.029444, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.030524, validLoss:0.027515, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.029790, validLoss:0.027332, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.029522, validLoss:0.026806, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.029283, validLoss:0.026606, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.029156, validLoss:0.024383, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.029136, validLoss:0.025686, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.029056, validLoss:0.025530, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.029016, validLoss:0.026593, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.028785, validLoss:0.025515, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.028978, validLoss:0.027529, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.028864, validLoss:0.025245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.028958, validLoss:0.025267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.028808, validLoss:0.026456, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.028701, validLoss:0.024049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.028810, validLoss:0.026338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.028812, validLoss:0.025234, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.028804, validLoss:0.027147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.028790, validLoss:0.025168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.028818, validLoss:0.026231, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.028931, validLoss:0.025350, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.028815, validLoss:0.026273, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.028692, validLoss:0.025213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.028808, validLoss:0.024171, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.028889, validLoss:0.024852, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.028678, validLoss:0.025253, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.028876, validLoss:0.024045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.028788, validLoss:0.026042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.028686, validLoss:0.025045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.028574, validLoss:0.025047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.028661, validLoss:0.025037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.028781, validLoss:0.025009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.028659, validLoss:0.025064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.028652, validLoss:0.025579, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:41, trainLoss:0.028745, validLoss:0.025062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.028764, validLoss:0.023998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.028557, validLoss:0.026267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.028750, validLoss:0.026116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.028669, validLoss:0.026204, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.028568, validLoss:0.027092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.028683, validLoss:0.025014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.028693, validLoss:0.025013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.028777, validLoss:0.025171, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.028759, validLoss:0.026293, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.028695, validLoss:0.026085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.028667, validLoss:0.026292, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.028735, validLoss:0.026116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.028690, validLoss:0.026269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.028702, validLoss:0.027471, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.028807, validLoss:0.025163, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.028696, validLoss:0.027112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.028691, validLoss:0.026613, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.028675, validLoss:0.026251, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.028784, validLoss:0.026698, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.028596, validLoss:0.024059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.028601, validLoss:0.025988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.028586, validLoss:0.025079, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.028799, validLoss:0.024961, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.028727, validLoss:0.026909, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.028696, validLoss:0.026112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.028588, validLoss:0.025144, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.028697, validLoss:0.027100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.028711, validLoss:0.026965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.028814, validLoss:0.027297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.028616, validLoss:0.023954, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.028704, validLoss:0.025240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.028823, validLoss:0.026864, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.028723, validLoss:0.026127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.028819, validLoss:0.025061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.028738, validLoss:0.024525, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.028824, validLoss:0.025854, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.028560, validLoss:0.027381, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.028741, validLoss:0.026075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.028753, validLoss:0.024983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.028648, validLoss:0.026886, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.028841, validLoss:0.024913, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.028854, validLoss:0.026343, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.028718, validLoss:0.025136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.028722, validLoss:0.027108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.028704, validLoss:0.024059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.028843, validLoss:0.027315, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.028844, validLoss:0.027348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.028830, validLoss:0.024970, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.028606, validLoss:0.025936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.028629, validLoss:0.025250, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.028809, validLoss:0.026067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.028822, validLoss:0.025064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.028635, validLoss:0.025914, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.028741, validLoss:0.025087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.028610, validLoss:0.026368, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.028737, validLoss:0.026285, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.028732, validLoss:0.026247, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.028754, validLoss:0.025316, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.026837, validLoss:0.023631, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.026329, validLoss:0.023272, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.026113, validLoss:0.022991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.025844, validLoss:0.021555, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.025636, validLoss:0.024392, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.025230, validLoss:0.024078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.024877, validLoss:0.020872, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.024668, validLoss:0.022846, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.024877, validLoss:0.023925, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.024758, validLoss:0.022875, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.024901, validLoss:0.022901, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.024783, validLoss:0.021902, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.024902, validLoss:0.023930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.024870, validLoss:0.021769, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.024655, validLoss:0.022877, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.024748, validLoss:0.021767, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.024748, validLoss:0.021845, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.024757, validLoss:0.021757, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.024790, validLoss:0.021879, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.024797, validLoss:0.023805, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.024641, validLoss:0.022829, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.024873, validLoss:0.023936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.024815, validLoss:0.023896, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.024891, validLoss:0.023966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.024877, validLoss:0.021799, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.024771, validLoss:0.021814, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.024858, validLoss:0.022906, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.024765, validLoss:0.022917, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.024692, validLoss:0.023923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.024862, validLoss:0.022928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.024908, validLoss:0.023902, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.024902, validLoss:0.023870, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.024730, validLoss:0.022860, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.024887, validLoss:0.023872, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.024868, validLoss:0.023874, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.024642, validLoss:0.022819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.024676, validLoss:0.021889, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.024777, validLoss:0.022820, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.024742, validLoss:0.023948, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.024746, validLoss:0.021760, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.024873, validLoss:0.023935, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:141, trainLoss:0.023973, validLoss:0.016712, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.015041, validLoss:0.010249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.006822, validLoss:0.004288, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.003425, validLoss:0.001915, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.002105, validLoss:0.001268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001766, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001700, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001683, validLoss:0.001124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001705, validLoss:0.001114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001712, validLoss:0.001196, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001727, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001701, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001740, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001673, validLoss:0.000959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001661, validLoss:0.001133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001699, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001663, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001688, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001697, validLoss:0.000981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001650, validLoss:0.000929, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001656, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001697, validLoss:0.001232, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001687, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001728, validLoss:0.001042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001657, validLoss:0.000996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001684, validLoss:0.001083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001642, validLoss:0.001017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001643, validLoss:0.001084, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001627, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001691, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001707, validLoss:0.001083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001667, validLoss:0.001084, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001650, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001706, validLoss:0.001076, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001699, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001674, validLoss:0.000957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001696, validLoss:0.001026, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001656, validLoss:0.000990, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001635, validLoss:0.001143, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001687, validLoss:0.001054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001670, validLoss:0.001060, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001663, validLoss:0.001061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001665, validLoss:0.001063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001672, validLoss:0.000995, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001652, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001665, validLoss:0.001071, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001643, validLoss:0.001068, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001644, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001685, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001621, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001633, validLoss:0.000868, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001686, validLoss:0.001084, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001685, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001651, validLoss:0.001095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001642, validLoss:0.000962, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001674, validLoss:0.001106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001665, validLoss:0.001041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001639, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001627, validLoss:0.001029, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.926638, g_loss:2.327843, d accuracy:0.869792, d AUC:0.977539, g accuracy:0.739583, rdf 0.000000\n",
      "Epoch:1, d_loss:1.127380, g_loss:1.043720, d accuracy:0.546875, d AUC:0.850911, g accuracy:0.093750, rdf 0.000000\n",
      "Epoch:2, d_loss:1.129799, g_loss:1.023589, d accuracy:0.713542, d AUC:0.983724, g accuracy:0.427083, rdf 0.000000\n",
      "Epoch:3, d_loss:0.598676, g_loss:2.035877, d accuracy:0.552083, d AUC:0.919922, g accuracy:0.104167, rdf 0.000000\n",
      "Epoch:4, d_loss:0.464888, g_loss:3.134043, d accuracy:0.906250, d AUC:0.998372, g accuracy:0.812500, rdf 0.000000\n",
      "Epoch:5, d_loss:0.358528, g_loss:3.021585, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.110622, g_loss:5.088626, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.131878, g_loss:3.041874, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.090852, g_loss:2.851052, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.364289, g_loss:2.373466, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.065161, g_loss:4.550689, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.030695, g_loss:4.065589, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.114155, g_loss:3.494214, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:13, d_loss:0.040238, g_loss:7.178154, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.014759, g_loss:8.081629, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.366033, g_loss:5.239455, d accuracy:0.968750, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.067994, g_loss:6.323891, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.019530, g_loss:6.308435, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.011233, g_loss:6.091652, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.007797, g_loss:5.504304, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.117176, g_loss:4.179170, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.037483, g_loss:6.236615, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.012975, g_loss:7.227722, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.068763, g_loss:6.011923, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.053273, g_loss:7.309538, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.010055, g_loss:7.430987, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.086750, g_loss:4.785619, d accuracy:0.880208, d AUC:0.972656, g accuracy:0.760417, rdf 0.000000\n",
      "Epoch:27, d_loss:0.167154, g_loss:3.827236, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28, d_loss:0.170725, g_loss:6.224937, d accuracy:0.979167, d AUC:0.998372, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:29, d_loss:0.060956, g_loss:6.821632, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.026436, g_loss:6.097196, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.017955, g_loss:7.201594, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.015627, g_loss:6.347979, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.019554, g_loss:5.692302, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.016342, g_loss:5.100171, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.068007, g_loss:3.945861, d accuracy:0.953125, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.131844, g_loss:4.689406, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.026591, g_loss:7.381567, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.019376, g_loss:6.973466, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.016656, g_loss:6.822860, d accuracy:0.968750, d AUC:0.980794, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:40, d_loss:2.185000, g_loss:5.534888, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.050140, g_loss:9.403261, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.086043, g_loss:6.430141, d accuracy:0.968750, d AUC:0.995117, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:43, d_loss:0.195612, g_loss:4.374778, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.111137, g_loss:5.483534, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.077949, g_loss:6.208694, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.095758, g_loss:5.682441, d accuracy:0.953125, d AUC:0.999674, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:47, d_loss:0.336836, g_loss:3.905593, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:48, d_loss:0.248041, g_loss:4.075319, d accuracy:0.901042, d AUC:0.957357, g accuracy:0.802083, rdf 0.000000\n",
      "Epoch:49, d_loss:0.445800, g_loss:3.716168, d accuracy:0.869792, d AUC:0.944987, g accuracy:0.927083, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.201375, validLoss:0.144989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.138232, validLoss:0.124001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.121319, validLoss:0.109789, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.109479, validLoss:0.102720, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.101592, validLoss:0.095615, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.096785, validLoss:0.090819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.093481, validLoss:0.090906, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.091622, validLoss:0.088616, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.090678, validLoss:0.086843, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.089952, validLoss:0.085402, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.089580, validLoss:0.086197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.089359, validLoss:0.086991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.089162, validLoss:0.085798, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.089109, validLoss:0.085678, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.088770, validLoss:0.086666, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.088667, validLoss:0.086588, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.088615, validLoss:0.085459, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.088783, validLoss:0.087487, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.088629, validLoss:0.086379, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.088730, validLoss:0.086396, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.088472, validLoss:0.086358, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.088547, validLoss:0.086265, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.088650, validLoss:0.087321, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.088633, validLoss:0.086245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.088624, validLoss:0.086257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.088617, validLoss:0.084194, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.088488, validLoss:0.087266, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.088738, validLoss:0.086288, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.088526, validLoss:0.085213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.088509, validLoss:0.084161, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.088608, validLoss:0.084184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.088602, validLoss:0.087318, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.088401, validLoss:0.085180, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.088835, validLoss:0.087274, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.088613, validLoss:0.088325, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.088621, validLoss:0.085207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.088527, validLoss:0.087316, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.088407, validLoss:0.087300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.088643, validLoss:0.086224, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.088423, validLoss:0.085215, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.088646, validLoss:0.085246, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.088535, validLoss:0.084108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.088630, validLoss:0.086277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.088446, validLoss:0.088306, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.088773, validLoss:0.085222, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.088534, validLoss:0.086279, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.088655, validLoss:0.085211, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.088775, validLoss:0.087326, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.088586, validLoss:0.088347, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.088581, validLoss:0.086286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.088456, validLoss:0.086286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.086935, validLoss:0.071982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.068451, validLoss:0.061118, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:53, trainLoss:0.059881, validLoss:0.054767, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.055428, validLoss:0.052742, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.054073, validLoss:0.053098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.053785, validLoss:0.052214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.053725, validLoss:0.050957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.053713, validLoss:0.050966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.053789, validLoss:0.050923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.053775, validLoss:0.050938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.053662, validLoss:0.051975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.053680, validLoss:0.053013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.053686, validLoss:0.053029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.053793, validLoss:0.051969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.053773, validLoss:0.052989, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.053701, validLoss:0.051973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.053803, validLoss:0.051968, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.053788, validLoss:0.051930, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.053784, validLoss:0.051931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.053800, validLoss:0.051982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.053687, validLoss:0.051978, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.053792, validLoss:0.050928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.053783, validLoss:0.051898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.053677, validLoss:0.052990, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.053811, validLoss:0.050926, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.053678, validLoss:0.054051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.053808, validLoss:0.051905, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.053804, validLoss:0.050906, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.053639, validLoss:0.053070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.053814, validLoss:0.045888, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.020021, validLoss:0.011881, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.010864, validLoss:0.009728, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.008105, validLoss:0.007645, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.005673, validLoss:0.005192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.003904, validLoss:0.003191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.002737, validLoss:0.001997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.002138, validLoss:0.001462, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.001882, validLoss:0.001235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.001804, validLoss:0.001258, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.001771, validLoss:0.001176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.001763, validLoss:0.001095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.001750, validLoss:0.001225, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.001700, validLoss:0.001008, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.001689, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.001717, validLoss:0.001111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.001697, validLoss:0.001093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.001683, validLoss:0.001091, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.001696, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.001685, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.001707, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.001681, validLoss:0.001026, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.001681, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.001677, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.001707, validLoss:0.000980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.001680, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.001688, validLoss:0.001086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.001685, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.001668, validLoss:0.001029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.001683, validLoss:0.001092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.001677, validLoss:0.001062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.001716, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.001709, validLoss:0.001200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.001719, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.001690, validLoss:0.001024, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.001696, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.001681, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.001673, validLoss:0.001093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.001669, validLoss:0.000995, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.001710, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.001727, validLoss:0.000967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.001678, validLoss:0.001005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.001684, validLoss:0.001061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.001750, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.001693, validLoss:0.001089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001680, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001694, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001676, validLoss:0.001098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001697, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001703, validLoss:0.001059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001677, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001718, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001684, validLoss:0.000988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001656, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001697, validLoss:0.001002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001684, validLoss:0.001017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001668, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001701, validLoss:0.001110, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001713, validLoss:0.000999, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001673, validLoss:0.001075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001666, validLoss:0.000983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001683, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001696, validLoss:0.001024, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001543, validLoss:0.001007, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001669, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001658, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001665, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001666, validLoss:0.000995, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001658, validLoss:0.001053, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:149, trainLoss:0.001663, validLoss:0.001063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001680, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001712, validLoss:0.001167, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001731, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001689, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001730, validLoss:0.001005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001663, validLoss:0.000931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001659, validLoss:0.001080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001695, validLoss:0.001068, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001668, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001682, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001687, validLoss:0.000955, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001661, validLoss:0.000917, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001665, validLoss:0.001041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001701, validLoss:0.001220, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001690, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001728, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001662, validLoss:0.000974, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001684, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001645, validLoss:0.000993, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001645, validLoss:0.001054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001628, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001699, validLoss:0.001022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001714, validLoss:0.001063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001677, validLoss:0.001071, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001657, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001699, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001684, validLoss:0.001048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001678, validLoss:0.000943, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001703, validLoss:0.000996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001661, validLoss:0.000968, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001643, validLoss:0.001130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001695, validLoss:0.001038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001676, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001667, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001670, validLoss:0.001041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001675, validLoss:0.000973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001655, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001663, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001648, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001649, validLoss:0.000979, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001690, validLoss:0.001045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001627, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001637, validLoss:0.000851, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001688, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001688, validLoss:0.001025, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001654, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001647, validLoss:0.000950, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001683, validLoss:0.001100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001673, validLoss:0.001002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001644, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.371782, g_loss:2.453869, d accuracy:0.625000, d AUC:0.991862, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.749878, g_loss:2.942938, d accuracy:0.916667, d AUC:0.999674, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.495396, g_loss:4.860915, d accuracy:0.916667, d AUC:0.973958, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:3, d_loss:0.525515, g_loss:9.594549, d accuracy:0.968750, d AUC:0.996419, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:4, d_loss:0.131463, g_loss:12.725159, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:5, d_loss:0.062215, g_loss:12.539471, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:6, d_loss:0.042399, g_loss:10.092414, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.050882, g_loss:9.703142, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.030019, g_loss:8.313381, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.009467, g_loss:9.177175, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.004282, g_loss:9.080439, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.003866, g_loss:8.871445, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.008147, g_loss:8.240946, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.055527, g_loss:6.161749, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.053612, g_loss:5.116569, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.166156, g_loss:2.186100, d accuracy:0.953125, d AUC:1.000000, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:16, d_loss:0.169654, g_loss:3.246124, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.865968, g_loss:2.803085, d accuracy:0.541667, d AUC:0.569661, g accuracy:0.333333, rdf 0.000000\n",
      "Epoch:18, d_loss:0.287561, g_loss:5.477046, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.050886, g_loss:4.296830, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.059996, g_loss:4.384593, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:21, d_loss:0.089067, g_loss:4.375919, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.031037, g_loss:5.254111, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.024222, g_loss:4.766326, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.024818, g_loss:4.575539, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:25, d_loss:0.043262, g_loss:3.839556, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.048673, g_loss:4.609992, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:27, d_loss:0.064431, g_loss:4.589067, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:28, d_loss:0.064711, g_loss:7.495364, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.057302, g_loss:9.193992, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:30, d_loss:0.038803, g_loss:11.220930, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.436069, g_loss:5.615975, d accuracy:0.963542, d AUC:0.999674, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:32, d_loss:0.095829, g_loss:6.294432, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.111033, g_loss:6.424619, d accuracy:0.994792, d AUC:0.992839, g accuracy:0.989583, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34, d_loss:0.121481, g_loss:8.138955, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.058565, g_loss:10.034414, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.026359, g_loss:9.076183, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.033934, g_loss:6.679282, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.139809, g_loss:6.878687, d accuracy:0.973958, d AUC:0.999349, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:39, d_loss:0.051875, g_loss:9.756320, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.013481, g_loss:8.719377, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.015942, g_loss:8.265359, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:42, d_loss:0.028731, g_loss:9.766892, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.027829, g_loss:7.878291, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.032363, g_loss:5.589774, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.035413, g_loss:4.328790, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.026046, g_loss:4.905621, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.021432, g_loss:5.033317, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.019466, g_loss:5.226855, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.019443, g_loss:5.079491, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.117822, validLoss:0.070898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.065128, validLoss:0.049002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.043948, validLoss:0.033595, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.030475, validLoss:0.023361, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.021660, validLoss:0.015843, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.016684, validLoss:0.013017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.013529, validLoss:0.010054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.008414, validLoss:0.005369, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.006203, validLoss:0.004014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.005179, validLoss:0.003506, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.004629, validLoss:0.003054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.004271, validLoss:0.002839, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.004003, validLoss:0.002622, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.003800, validLoss:0.002448, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.003625, validLoss:0.002319, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.003458, validLoss:0.002229, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.003390, validLoss:0.002074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.003301, validLoss:0.002068, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.003202, validLoss:0.001957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.003145, validLoss:0.001944, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.003079, validLoss:0.001871, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.003024, validLoss:0.001718, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.002968, validLoss:0.001805, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.002938, validLoss:0.001722, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.002910, validLoss:0.001773, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.002898, validLoss:0.001670, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.002863, validLoss:0.001697, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.002877, validLoss:0.001719, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.002858, validLoss:0.001643, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.002843, validLoss:0.001633, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.002839, validLoss:0.001627, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.002678, validLoss:0.001395, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.002253, validLoss:0.001269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.002150, validLoss:0.001261, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.002150, validLoss:0.001281, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.002141, validLoss:0.001231, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.002094, validLoss:0.001317, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.002012, validLoss:0.001235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.002095, validLoss:0.001202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.002112, validLoss:0.001260, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.002092, validLoss:0.001247, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.002071, validLoss:0.001225, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.002039, validLoss:0.001237, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.002015, validLoss:0.001117, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.001949, validLoss:0.001153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.001902, validLoss:0.001130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.001901, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.001893, validLoss:0.001165, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.001925, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.001905, validLoss:0.001158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.001887, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.001866, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.001879, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.001869, validLoss:0.001123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.001872, validLoss:0.001094, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.001878, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.001892, validLoss:0.001151, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.001853, validLoss:0.001110, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.001838, validLoss:0.001107, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.001803, validLoss:0.001095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.001817, validLoss:0.001123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.001805, validLoss:0.001118, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:62, trainLoss:0.001824, validLoss:0.001097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.001820, validLoss:0.001071, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.001821, validLoss:0.001071, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.001793, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.001802, validLoss:0.001094, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.001790, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.001777, validLoss:0.001050, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.001779, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.001785, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.001773, validLoss:0.001076, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.001761, validLoss:0.001051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.001749, validLoss:0.000988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.001754, validLoss:0.001042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.001787, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.001758, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.001765, validLoss:0.000971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.001738, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.001686, validLoss:0.001116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.001774, validLoss:0.001134, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.001763, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.001772, validLoss:0.001037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.001744, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.001740, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.001733, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.001743, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.001722, validLoss:0.001126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.001727, validLoss:0.001084, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.001723, validLoss:0.001108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.001731, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.001730, validLoss:0.001026, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.001724, validLoss:0.001125, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.001688, validLoss:0.000996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.001685, validLoss:0.001042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.001722, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.001705, validLoss:0.001061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.001688, validLoss:0.001098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.001714, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.001700, validLoss:0.001025, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.001712, validLoss:0.001080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.001677, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.001686, validLoss:0.001050, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.001680, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.001697, validLoss:0.001016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.001669, validLoss:0.001079, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.001686, validLoss:0.001081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.001683, validLoss:0.001091, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.001664, validLoss:0.001007, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.001675, validLoss:0.001086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.001679, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.001710, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.001704, validLoss:0.001184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.001701, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.001676, validLoss:0.001010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.001682, validLoss:0.001067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.001658, validLoss:0.001022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.001664, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.001660, validLoss:0.001003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.001714, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.001701, validLoss:0.000981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.001668, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.001666, validLoss:0.001080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.001722, validLoss:0.001062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.001677, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001683, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001674, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001654, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001686, validLoss:0.001125, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001699, validLoss:0.001096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001656, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001693, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001665, validLoss:0.001013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001633, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001677, validLoss:0.001017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001666, validLoss:0.001028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001652, validLoss:0.001013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001680, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001688, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001641, validLoss:0.001111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001643, validLoss:0.001003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001659, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001668, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001534, validLoss:0.001030, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001642, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001640, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001639, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001636, validLoss:0.001025, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001637, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001644, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001659, validLoss:0.001101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001674, validLoss:0.001169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001694, validLoss:0.001086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001677, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001690, validLoss:0.001028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001631, validLoss:0.000968, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001634, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001661, validLoss:0.001106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001637, validLoss:0.001029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001649, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001659, validLoss:0.001000, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:161, trainLoss:0.001622, validLoss:0.000974, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001638, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001668, validLoss:0.001240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001669, validLoss:0.001103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001688, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001636, validLoss:0.000999, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001658, validLoss:0.001051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001624, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001618, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001603, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001678, validLoss:0.001048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001673, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001636, validLoss:0.001093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001632, validLoss:0.001081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001684, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001669, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001663, validLoss:0.000988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001676, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001625, validLoss:0.001003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001612, validLoss:0.001130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001659, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001654, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001643, validLoss:0.001079, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001643, validLoss:0.001079, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001648, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001640, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001629, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001624, validLoss:0.001084, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001615, validLoss:0.001019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001666, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001597, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001612, validLoss:0.000914, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001671, validLoss:0.001096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001664, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001628, validLoss:0.001092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001614, validLoss:0.000993, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001664, validLoss:0.001135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001646, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001630, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.834451, g_loss:2.355784, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.586761, g_loss:2.259322, d accuracy:0.937500, d AUC:0.996419, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:2, d_loss:0.459860, g_loss:3.239017, d accuracy:0.973958, d AUC:0.998047, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:3, d_loss:0.428819, g_loss:4.582484, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.081979, g_loss:7.190765, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:5, d_loss:0.063730, g_loss:7.569736, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.382617, g_loss:3.635420, d accuracy:0.500000, d AUC:1.000000, g accuracy:0.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.541936, g_loss:1.459869, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.228636, g_loss:1.946840, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:9, d_loss:0.113298, g_loss:4.070725, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.060047, g_loss:3.886046, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.022438, g_loss:4.758460, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.137400, g_loss:3.163388, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.012988, g_loss:7.388274, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:14, d_loss:0.112719, g_loss:3.568324, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.037854, g_loss:7.081993, d accuracy:0.843750, d AUC:1.000000, g accuracy:0.687500, rdf 0.000000\n",
      "Epoch:16, d_loss:0.140066, g_loss:5.864562, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.010514, g_loss:5.831283, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.007210, g_loss:5.604402, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.008787, g_loss:5.088332, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.010007, g_loss:5.472144, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.006307, g_loss:6.838482, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.004552, g_loss:7.047114, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.004324, g_loss:6.587389, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.007463, g_loss:4.523586, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.010823, g_loss:6.511458, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.010892, g_loss:10.027718, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:27, d_loss:0.022665, g_loss:10.105739, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.005822, g_loss:9.442714, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.012333, g_loss:12.183321, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.005060, g_loss:12.360636, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.003264, g_loss:10.287729, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.002495, g_loss:8.505872, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.005022, g_loss:6.612757, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.004939, g_loss:6.834156, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.003603, g_loss:6.887674, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.003395, g_loss:6.849683, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.003660, g_loss:6.823615, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.006891, g_loss:5.968295, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.009281, g_loss:7.138124, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.003509, g_loss:11.218116, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.010241, g_loss:7.017971, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:42, d_loss:0.022290, g_loss:8.133425, d accuracy:0.963542, d AUC:1.000000, g accuracy:0.927083, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:43, d_loss:0.179551, g_loss:6.391738, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.015008, g_loss:7.678690, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.084051, g_loss:8.595394, d accuracy:0.947917, d AUC:0.987956, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:46, d_loss:0.241797, g_loss:8.177214, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.050300, g_loss:8.279846, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.038009, g_loss:9.483690, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.035792, g_loss:6.460528, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n",
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "0    400\n",
      "1    278\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.205120, validLoss:0.158890, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.152614, validLoss:0.138078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.137388, validLoss:0.130936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.127932, validLoss:0.119885, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.121777, validLoss:0.113313, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.117555, validLoss:0.111681, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.115259, validLoss:0.112105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.113881, validLoss:0.110152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.112628, validLoss:0.108005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.112043, validLoss:0.107490, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.111779, validLoss:0.107819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.111383, validLoss:0.107988, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.111505, validLoss:0.107794, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.110728, validLoss:0.107727, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.110763, validLoss:0.110135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.110493, validLoss:0.103824, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.111116, validLoss:0.107957, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.110679, validLoss:0.109009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.110922, validLoss:0.107380, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.110685, validLoss:0.108260, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.110663, validLoss:0.106807, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.110690, validLoss:0.109969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.110688, validLoss:0.107264, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.110757, validLoss:0.106832, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.110691, validLoss:0.106819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.110460, validLoss:0.109787, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.110758, validLoss:0.107851, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.110646, validLoss:0.108321, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.110687, validLoss:0.105762, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.110965, validLoss:0.107292, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.110797, validLoss:0.108366, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.110645, validLoss:0.104576, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.110854, validLoss:0.109360, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.110474, validLoss:0.109827, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.110869, validLoss:0.107834, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.110872, validLoss:0.107296, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.110495, validLoss:0.107179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.110667, validLoss:0.107821, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.110670, validLoss:0.107238, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.110779, validLoss:0.106221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.110895, validLoss:0.104706, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.110903, validLoss:0.109343, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.110465, validLoss:0.108861, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.110907, validLoss:0.108891, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.110775, validLoss:0.107720, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.110896, validLoss:0.104584, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.110951, validLoss:0.110439, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.110822, validLoss:0.106211, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.110709, validLoss:0.107654, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.110633, validLoss:0.107282, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.110916, validLoss:0.106257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.110818, validLoss:0.107817, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.110810, validLoss:0.106137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.110704, validLoss:0.108295, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.110764, validLoss:0.106218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.110334, validLoss:0.108348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.110102, validLoss:0.108034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.109069, validLoss:0.107822, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.106656, validLoss:0.104150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.105118, validLoss:0.106744, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.104653, validLoss:0.105804, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.097237, validLoss:0.093769, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.087942, validLoss:0.088478, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.081614, validLoss:0.079725, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.075813, validLoss:0.076950, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.074528, validLoss:0.074582, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.074357, validLoss:0.074904, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.074387, validLoss:0.075900, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:68, trainLoss:0.074281, validLoss:0.074292, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.074425, validLoss:0.074486, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.074282, validLoss:0.073918, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.074233, validLoss:0.075368, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.074117, validLoss:0.074829, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.074126, validLoss:0.074408, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.074300, validLoss:0.076971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.074129, validLoss:0.074750, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.074180, validLoss:0.075297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.074293, validLoss:0.076502, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.074008, validLoss:0.074895, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.074243, validLoss:0.075422, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.074255, validLoss:0.075351, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.074145, validLoss:0.074871, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.074182, validLoss:0.074938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.074172, validLoss:0.076436, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.074236, validLoss:0.075923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.074155, validLoss:0.074846, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.074158, validLoss:0.078067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.074117, validLoss:0.075927, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.074125, validLoss:0.074351, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.074059, validLoss:0.076975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.074286, validLoss:0.075419, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.074345, validLoss:0.077003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.074037, validLoss:0.076941, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.074094, validLoss:0.075905, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.074339, validLoss:0.075946, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.064576, validLoss:0.059290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.052082, validLoss:0.052656, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.046605, validLoss:0.047589, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.043019, validLoss:0.044742, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.040884, validLoss:0.043173, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.039714, validLoss:0.040665, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.039322, validLoss:0.041082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.039262, validLoss:0.041083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.039305, validLoss:0.040958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.039321, validLoss:0.040579, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.039252, validLoss:0.042221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.039311, validLoss:0.041609, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.039283, validLoss:0.041581, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.039282, validLoss:0.041671, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.039225, validLoss:0.040462, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.039270, validLoss:0.041680, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.039266, validLoss:0.042270, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.039324, validLoss:0.042232, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.039249, validLoss:0.042118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.039179, validLoss:0.042242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.039235, validLoss:0.040966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.039285, validLoss:0.040517, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.039275, validLoss:0.041607, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.039314, validLoss:0.042226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.039333, validLoss:0.042116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.039155, validLoss:0.042150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.039229, validLoss:0.042245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.039354, validLoss:0.041033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.039316, validLoss:0.041681, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.039298, validLoss:0.035305, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.009411, validLoss:0.003246, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.003450, validLoss:0.002126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.002431, validLoss:0.001610, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.002137, validLoss:0.001407, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001965, validLoss:0.001341, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001935, validLoss:0.001191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001864, validLoss:0.001133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001791, validLoss:0.001170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001823, validLoss:0.001148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001798, validLoss:0.001111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001771, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001796, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001804, validLoss:0.001081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001756, validLoss:0.001186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001754, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001764, validLoss:0.001131, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001760, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001615, validLoss:0.001122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001741, validLoss:0.001167, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001721, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001727, validLoss:0.001118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001719, validLoss:0.001054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001717, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001711, validLoss:0.001137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001737, validLoss:0.001169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001745, validLoss:0.001234, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001763, validLoss:0.001138, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001726, validLoss:0.001067, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001754, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001699, validLoss:0.000992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001706, validLoss:0.001118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001727, validLoss:0.001132, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001703, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001705, validLoss:0.001045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001717, validLoss:0.000981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001682, validLoss:0.000982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001691, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001718, validLoss:0.001245, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001714, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001742, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001679, validLoss:0.000998, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:166, trainLoss:0.001708, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001676, validLoss:0.001003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001670, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001653, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001718, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001737, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001690, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001681, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001740, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001720, validLoss:0.001054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001688, validLoss:0.000983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001715, validLoss:0.001014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001682, validLoss:0.000971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001656, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001697, validLoss:0.001026, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001686, validLoss:0.001062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001690, validLoss:0.001045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001680, validLoss:0.001026, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001688, validLoss:0.000974, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001656, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001679, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001665, validLoss:0.001083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001660, validLoss:0.000990, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001694, validLoss:0.001054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001641, validLoss:0.001017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001653, validLoss:0.000884, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001690, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001693, validLoss:0.001022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001670, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001649, validLoss:0.000993, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001683, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001680, validLoss:0.001007, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001652, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001641, validLoss:0.001008, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.749699, g_loss:2.710405, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:1, d_loss:0.621800, g_loss:1.475605, d accuracy:0.708333, d AUC:0.938151, g accuracy:0.416667, rdf 0.000000\n",
      "Epoch:2, d_loss:0.926878, g_loss:1.276004, d accuracy:0.958333, d AUC:0.991862, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:3, d_loss:0.589137, g_loss:1.606484, d accuracy:0.609375, d AUC:0.994466, g accuracy:0.218750, rdf 0.000000\n",
      "Epoch:4, d_loss:0.431206, g_loss:2.829534, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.483336, g_loss:1.951252, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:6, d_loss:0.260297, g_loss:3.771725, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.051847, g_loss:6.269382, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.179295, g_loss:4.004605, d accuracy:0.979167, d AUC:0.999023, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:9, d_loss:0.129383, g_loss:6.020328, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.044548, g_loss:5.411517, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.016870, g_loss:6.415327, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.070654, g_loss:3.683773, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.015955, g_loss:7.335778, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.011895, g_loss:5.530026, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.010144, g_loss:5.553192, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.008731, g_loss:5.635070, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.083831, g_loss:4.475300, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.009865, g_loss:11.002234, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.019143, g_loss:6.428528, d accuracy:0.963542, d AUC:1.000000, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:20, d_loss:0.058469, g_loss:7.286855, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.010587, g_loss:6.479990, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.013650, g_loss:5.894866, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.008941, g_loss:8.001463, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.006965, g_loss:6.725711, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.005870, g_loss:6.373557, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.005607, g_loss:6.173213, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.005818, g_loss:6.160492, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.005067, g_loss:6.314795, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.004755, g_loss:6.356150, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.004269, g_loss:6.458891, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.004918, g_loss:6.445637, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.004184, g_loss:6.510184, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.004541, g_loss:6.518624, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.003471, g_loss:6.454108, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.003382, g_loss:6.555353, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.003040, g_loss:6.601399, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.003075, g_loss:6.608850, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.002815, g_loss:6.545378, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.002986, g_loss:6.512030, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.041341, g_loss:5.991940, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.003103, g_loss:11.674354, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.002466, g_loss:7.784027, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.002098, g_loss:7.600425, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.002393, g_loss:7.484354, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.002225, g_loss:7.441034, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:46, d_loss:0.020550, g_loss:6.445519, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.004541, g_loss:9.170936, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.002780, g_loss:7.973909, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.002134, g_loss:7.867460, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.171571, validLoss:0.152052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.140116, validLoss:0.130115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.122001, validLoss:0.118791, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.112041, validLoss:0.110713, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.105997, validLoss:0.106338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.102249, validLoss:0.104404, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.099894, validLoss:0.098902, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.098780, validLoss:0.100603, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.097987, validLoss:0.098498, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.097445, validLoss:0.098643, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.097192, validLoss:0.098410, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.097139, validLoss:0.098773, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.096969, validLoss:0.098063, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.096944, validLoss:0.097967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.089258, validLoss:0.078303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.080466, validLoss:0.079086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.078831, validLoss:0.072472, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.078417, validLoss:0.074591, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.077320, validLoss:0.076152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.076881, validLoss:0.073844, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.076366, validLoss:0.073201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.075938, validLoss:0.072600, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.075694, validLoss:0.074541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.075719, validLoss:0.073880, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.075747, validLoss:0.071322, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.075666, validLoss:0.073423, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.075539, validLoss:0.074288, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.075621, validLoss:0.073410, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.075628, validLoss:0.073851, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.075646, validLoss:0.072336, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.075802, validLoss:0.073875, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.075740, validLoss:0.072862, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.075702, validLoss:0.071154, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.075697, validLoss:0.073819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.075424, validLoss:0.073246, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.075697, validLoss:0.074408, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.075818, validLoss:0.071768, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.075434, validLoss:0.072687, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.075614, validLoss:0.073348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.075713, validLoss:0.072743, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.075707, validLoss:0.071762, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.075826, validLoss:0.071226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.075825, validLoss:0.074863, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.075502, validLoss:0.074359, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.075728, validLoss:0.074408, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.075705, validLoss:0.073267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.075716, validLoss:0.070118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.075770, validLoss:0.073878, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.075756, validLoss:0.070684, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.075637, validLoss:0.072116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.075673, validLoss:0.071743, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.075845, validLoss:0.070714, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.075747, validLoss:0.075446, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.062846, validLoss:0.034928, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.040894, validLoss:0.034888, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.038909, validLoss:0.031494, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.038472, validLoss:0.033528, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.038478, validLoss:0.032353, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.038448, validLoss:0.034454, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.038184, validLoss:0.031282, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.038384, validLoss:0.034436, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.038248, validLoss:0.032326, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.038367, validLoss:0.033365, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.038360, validLoss:0.033348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.038350, validLoss:0.033303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.038330, validLoss:0.033303, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.038017, validLoss:0.030235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.038220, validLoss:0.032257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.038313, validLoss:0.032290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.038221, validLoss:0.034320, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.038093, validLoss:0.032276, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.038319, validLoss:0.032280, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.038203, validLoss:0.030190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.038187, validLoss:0.031115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.038184, validLoss:0.032218, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:75, trainLoss:0.038299, validLoss:0.031212, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.038192, validLoss:0.033283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.034314, validLoss:0.021479, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.022876, validLoss:0.018042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.019277, validLoss:0.012113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.012646, validLoss:0.005365, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.008391, validLoss:0.003450, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.007781, validLoss:0.003181, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.007796, validLoss:0.003281, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.007781, validLoss:0.003228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.007778, validLoss:0.003169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.007751, validLoss:0.002097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.007732, validLoss:0.003201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.007732, validLoss:0.003122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.007739, validLoss:0.003190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.007743, validLoss:0.002089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.007748, validLoss:0.003090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.007744, validLoss:0.003210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.007711, validLoss:0.003115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.007700, validLoss:0.003099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.007718, validLoss:0.003111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.007374, validLoss:0.003473, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.006898, validLoss:0.003189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.006178, validLoss:0.004197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.005079, validLoss:0.002100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.003364, validLoss:0.001657, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.002179, validLoss:0.001238, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.001815, validLoss:0.001125, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.001754, validLoss:0.001112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.001780, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.001745, validLoss:0.001158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.001741, validLoss:0.001126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.001718, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.001710, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.001729, validLoss:0.001130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.001712, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.001749, validLoss:0.001139, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.001751, validLoss:0.001188, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.001744, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.001717, validLoss:0.001020, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.001716, validLoss:0.001108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.001707, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.001696, validLoss:0.001096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.001694, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.001734, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.001728, validLoss:0.000975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.001692, validLoss:0.001017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.001702, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.001753, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.001716, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001705, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001707, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001688, validLoss:0.001122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001695, validLoss:0.001136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001715, validLoss:0.001078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001681, validLoss:0.001124, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001730, validLoss:0.001042, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001713, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001656, validLoss:0.001058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001705, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001710, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001684, validLoss:0.001004, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001710, validLoss:0.001160, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001723, validLoss:0.001024, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001685, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001684, validLoss:0.001013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001697, validLoss:0.001093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001704, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001560, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001685, validLoss:0.001109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001661, validLoss:0.001011, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001681, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001674, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001667, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001674, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001695, validLoss:0.001123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001709, validLoss:0.001203, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001726, validLoss:0.001123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001690, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001720, validLoss:0.001019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001659, validLoss:0.000971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001674, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001695, validLoss:0.001093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001670, validLoss:0.001044, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001684, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001688, validLoss:0.000968, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001655, validLoss:0.000967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001672, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001702, validLoss:0.001248, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001697, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001721, validLoss:0.001037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001662, validLoss:0.000985, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001685, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001658, validLoss:0.001006, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001652, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001631, validLoss:0.001061, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:171, trainLoss:0.001698, validLoss:0.001051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001711, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001676, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001664, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001725, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001700, validLoss:0.001059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001677, validLoss:0.000969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001698, validLoss:0.001005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001667, validLoss:0.000980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001643, validLoss:0.001113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001687, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001677, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001672, validLoss:0.001059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001672, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001676, validLoss:0.000991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001642, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001667, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001647, validLoss:0.001080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001652, validLoss:0.001005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001687, validLoss:0.001060, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001638, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001644, validLoss:0.000906, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001681, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001687, validLoss:0.001021, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001661, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001643, validLoss:0.000996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001680, validLoss:0.001115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001673, validLoss:0.001016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001643, validLoss:0.001027, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.071564, g_loss:2.189880, d accuracy:0.755208, d AUC:0.980794, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.691258, g_loss:3.855129, d accuracy:0.817708, d AUC:0.963216, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:2, d_loss:0.706043, g_loss:5.127368, d accuracy:0.895833, d AUC:0.976237, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:3, d_loss:0.224781, g_loss:6.834394, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.092243, g_loss:6.739848, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:5, d_loss:0.030586, g_loss:8.351009, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.018934, g_loss:9.665892, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:7, d_loss:0.016398, g_loss:13.206062, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.035668, g_loss:11.024230, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.018372, g_loss:9.597789, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.005319, g_loss:8.811806, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.062549, g_loss:7.190230, d accuracy:0.848958, d AUC:1.000000, g accuracy:0.697917, rdf 0.000000\n",
      "Epoch:12, d_loss:0.077616, g_loss:6.976926, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.096285, g_loss:4.021054, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.212694, g_loss:2.872314, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:15, d_loss:0.144666, g_loss:4.406817, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:16, d_loss:0.170098, g_loss:3.425726, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.061522, g_loss:4.135918, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.053442, g_loss:4.159003, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.023832, g_loss:5.616377, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.015824, g_loss:6.134949, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.022391, g_loss:5.932861, d accuracy:0.953125, d AUC:1.000000, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:22, d_loss:0.772519, g_loss:4.813726, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.073740, g_loss:5.768858, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:24, d_loss:0.107418, g_loss:4.354200, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:25, d_loss:0.092440, g_loss:4.523495, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.045050, g_loss:5.804063, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.028449, g_loss:5.960280, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.019141, g_loss:5.943825, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.017972, g_loss:5.749258, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.034667, g_loss:5.393975, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.083347, g_loss:5.130238, d accuracy:0.979167, d AUC:0.999023, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:32, d_loss:0.094279, g_loss:7.825685, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.064175, g_loss:6.126840, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.025020, g_loss:6.288736, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.016550, g_loss:6.418712, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.018551, g_loss:5.768366, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.024683, g_loss:4.815372, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.033490, g_loss:4.577615, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.016647, g_loss:5.669741, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.019674, g_loss:5.339849, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.036716, g_loss:5.083537, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:42, d_loss:0.095539, g_loss:5.271379, d accuracy:0.989583, d AUC:0.997070, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:43, d_loss:0.613571, g_loss:3.107617, d accuracy:0.968750, d AUC:0.995117, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:44, d_loss:0.283841, g_loss:6.386009, d accuracy:0.932292, d AUC:0.982422, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:45, d_loss:0.145670, g_loss:7.692204, d accuracy:0.927083, d AUC:0.997396, g accuracy:0.854167, rdf 0.000000\n",
      "Epoch:46, d_loss:0.392214, g_loss:6.955787, d accuracy:0.953125, d AUC:0.997721, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:47, d_loss:0.195251, g_loss:7.766098, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.080749, g_loss:6.953023, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.083180, g_loss:6.429317, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.243857, validLoss:0.187613, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.152058, validLoss:0.109840, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.087137, validLoss:0.072425, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.067076, validLoss:0.059229, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.055393, validLoss:0.052151, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.048586, validLoss:0.044363, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.044120, validLoss:0.042962, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.041504, validLoss:0.040417, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.039671, validLoss:0.039909, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.037774, validLoss:0.027657, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.022975, validLoss:0.020105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.020780, validLoss:0.017924, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.019221, validLoss:0.016923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.018001, validLoss:0.016510, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.017017, validLoss:0.015014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.016034, validLoss:0.015044, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.015755, validLoss:0.014263, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.015459, validLoss:0.014289, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.015340, validLoss:0.014075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.015270, validLoss:0.014392, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.015153, validLoss:0.014422, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.015238, validLoss:0.012881, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.015201, validLoss:0.013890, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.015180, validLoss:0.013046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.015220, validLoss:0.013087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.015149, validLoss:0.014275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.015180, validLoss:0.014172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.015080, validLoss:0.013348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.015209, validLoss:0.013919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.015156, validLoss:0.014320, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.015201, validLoss:0.014524, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.015139, validLoss:0.014116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.015191, validLoss:0.014314, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.015086, validLoss:0.014153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.015115, validLoss:0.014425, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.015224, validLoss:0.013779, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.015202, validLoss:0.014626, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.014902, validLoss:0.014463, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.014949, validLoss:0.013773, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.015063, validLoss:0.014005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.015051, validLoss:0.013666, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.015012, validLoss:0.014228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.014910, validLoss:0.014010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.015036, validLoss:0.014051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.015050, validLoss:0.013512, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.014926, validLoss:0.013635, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.014998, validLoss:0.013882, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.015054, validLoss:0.014565, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.014982, validLoss:0.013522, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.015048, validLoss:0.014287, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.015063, validLoss:0.013338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.015047, validLoss:0.014095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.015018, validLoss:0.012945, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.015017, validLoss:0.013290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.015083, validLoss:0.012720, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.015086, validLoss:0.013210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.015074, validLoss:0.013333, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.015117, validLoss:0.014196, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.015115, validLoss:0.013997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.015021, validLoss:0.014572, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.015089, validLoss:0.013696, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.014966, validLoss:0.013311, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.015065, validLoss:0.013864, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.015107, validLoss:0.013062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.015096, validLoss:0.014203, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.015104, validLoss:0.013399, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.015121, validLoss:0.013451, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.015123, validLoss:0.013866, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.015055, validLoss:0.014120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.015099, validLoss:0.014242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.015098, validLoss:0.013339, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.015094, validLoss:0.013967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.015113, validLoss:0.013047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.015020, validLoss:0.014300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.015053, validLoss:0.014502, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.015136, validLoss:0.013624, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.015113, validLoss:0.013893, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.015023, validLoss:0.014545, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.015020, validLoss:0.014513, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.015043, validLoss:0.013907, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:80, trainLoss:0.015050, validLoss:0.013842, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.015107, validLoss:0.014296, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.015108, validLoss:0.014472, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.015127, validLoss:0.014264, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.015084, validLoss:0.014170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.015047, validLoss:0.014428, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.015120, validLoss:0.014456, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.015025, validLoss:0.013636, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.015128, validLoss:0.013741, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.015119, validLoss:0.014226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.015134, validLoss:0.014144, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.015151, validLoss:0.013438, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.015041, validLoss:0.013383, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.015113, validLoss:0.013922, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.015121, validLoss:0.014265, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.015095, validLoss:0.013411, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.015128, validLoss:0.014050, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.015125, validLoss:0.014280, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.015119, validLoss:0.013656, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.015056, validLoss:0.013286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.015133, validLoss:0.013718, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.015132, validLoss:0.014116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.015125, validLoss:0.014248, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.015117, validLoss:0.013592, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.015160, validLoss:0.013839, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.015104, validLoss:0.013536, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.015145, validLoss:0.013559, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.015116, validLoss:0.014361, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.015064, validLoss:0.013814, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.015089, validLoss:0.014509, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.015102, validLoss:0.014238, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.015126, validLoss:0.013862, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.015138, validLoss:0.014549, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.015184, validLoss:0.014088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.015155, validLoss:0.012787, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.015150, validLoss:0.013840, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.015159, validLoss:0.013377, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.015118, validLoss:0.013560, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.015099, validLoss:0.013765, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.015169, validLoss:0.013924, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.015198, validLoss:0.014017, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.015146, validLoss:0.013758, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.015170, validLoss:0.014218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.015170, validLoss:0.014498, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.015179, validLoss:0.013777, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.015175, validLoss:0.014097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.015156, validLoss:0.013721, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.015057, validLoss:0.013774, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.015143, validLoss:0.014439, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.015179, validLoss:0.014142, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.015041, validLoss:0.013907, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.015128, validLoss:0.013922, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.015126, validLoss:0.013595, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.015138, validLoss:0.014013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.015188, validLoss:0.013581, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.015146, validLoss:0.014150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.015125, validLoss:0.014145, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.015141, validLoss:0.014353, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.015184, validLoss:0.013788, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.015085, validLoss:0.014162, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.015157, validLoss:0.014604, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.015149, validLoss:0.014391, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.015112, validLoss:0.013964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.014955, validLoss:0.013487, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.015164, validLoss:0.014404, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.015140, validLoss:0.013096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.015078, validLoss:0.014351, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.015037, validLoss:0.014277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.014967, validLoss:0.014073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.015143, validLoss:0.014694, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.015137, validLoss:0.013586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.015192, validLoss:0.013846, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.015212, validLoss:0.013118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.015164, validLoss:0.014090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.015182, validLoss:0.013763, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.015152, validLoss:0.013322, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.015163, validLoss:0.014286, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.015175, validLoss:0.012781, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.015122, validLoss:0.013504, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.015110, validLoss:0.014012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.015137, validLoss:0.014160, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.015113, validLoss:0.014285, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.014974, validLoss:0.014365, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.015154, validLoss:0.014385, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.015114, validLoss:0.014177, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.015204, validLoss:0.013667, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.015095, validLoss:0.014629, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.015143, validLoss:0.013491, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.015107, validLoss:0.013808, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.015144, validLoss:0.014069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.015120, validLoss:0.014126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.010275, validLoss:0.006525, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.006964, validLoss:0.005417, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.005170, validLoss:0.003113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.002944, validLoss:0.001399, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001894, validLoss:0.001094, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:176, trainLoss:0.001717, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001682, validLoss:0.000916, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001707, validLoss:0.001002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001676, validLoss:0.000958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001645, validLoss:0.001104, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001686, validLoss:0.001014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001682, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001677, validLoss:0.001033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001670, validLoss:0.001028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001674, validLoss:0.000967, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001647, validLoss:0.001035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001669, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001651, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001652, validLoss:0.000975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001680, validLoss:0.001041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001630, validLoss:0.001013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001641, validLoss:0.000857, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001681, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001686, validLoss:0.001023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001657, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001643, validLoss:0.000964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001681, validLoss:0.001091, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001668, validLoss:0.000991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001640, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.983370, g_loss:2.330050, d accuracy:0.786458, d AUC:0.994466, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.916081, g_loss:1.913406, d accuracy:0.661458, d AUC:0.752279, g accuracy:0.833333, rdf 0.000000\n",
      "Epoch:2, d_loss:0.842827, g_loss:2.945933, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:3, d_loss:0.184493, g_loss:4.993636, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.425796, g_loss:2.474673, d accuracy:0.817708, d AUC:1.000000, g accuracy:0.635417, rdf 0.000000\n",
      "Epoch:5, d_loss:0.491723, g_loss:1.244961, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:6, d_loss:0.336563, g_loss:1.877669, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.155138, g_loss:3.424862, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.056370, g_loss:5.875526, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.043914, g_loss:4.038465, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.108861, g_loss:3.029129, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.046740, g_loss:5.737600, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.012443, g_loss:7.973048, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.013457, g_loss:5.156158, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.014193, g_loss:4.816703, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.012090, g_loss:5.024993, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.010495, g_loss:5.123193, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.011625, g_loss:4.872621, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.130794, g_loss:5.718046, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.047524, g_loss:5.401187, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:20, d_loss:0.019680, g_loss:9.047937, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.003206, g_loss:8.615340, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.002568, g_loss:7.173717, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.003295, g_loss:6.346269, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.039687, g_loss:5.576221, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.010227, g_loss:7.637553, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.004192, g_loss:7.311915, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.004017, g_loss:6.904904, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.003303, g_loss:6.907928, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.003016, g_loss:6.949111, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.002715, g_loss:6.994105, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.002749, g_loss:7.016703, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.002405, g_loss:7.124895, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.002324, g_loss:7.297104, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.002334, g_loss:7.280143, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.002176, g_loss:7.209915, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.002071, g_loss:7.106454, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.002301, g_loss:7.117983, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.002202, g_loss:7.000597, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.002255, g_loss:6.867667, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.003260, g_loss:6.564056, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.004215, g_loss:6.563482, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.006419, g_loss:6.205116, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.004090, g_loss:7.887872, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.134349, g_loss:6.792388, d accuracy:0.536458, d AUC:0.919596, g accuracy:0.072917, rdf 0.000000\n",
      "Epoch:45, d_loss:0.731522, g_loss:5.873671, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:46, d_loss:0.354128, g_loss:4.475287, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:47, d_loss:0.058956, g_loss:10.434489, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.030882, g_loss:10.637562, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.029186, g_loss:11.053099, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n",
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "0    353\n",
      "1    325\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.235158, validLoss:0.188148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.171057, validLoss:0.157338, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.147370, validLoss:0.136919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.131828, validLoss:0.125609, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.122034, validLoss:0.116926, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.116305, validLoss:0.116114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.113446, validLoss:0.113767, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.111894, validLoss:0.111053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.110821, validLoss:0.110763, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.110331, validLoss:0.110838, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.109975, validLoss:0.110233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.109702, validLoss:0.110171, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.109638, validLoss:0.112207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.109061, validLoss:0.109808, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.108470, validLoss:0.111570, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.108421, validLoss:0.109393, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.108451, validLoss:0.110037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.108166, validLoss:0.110068, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.108406, validLoss:0.108680, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.107923, validLoss:0.109945, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.108081, validLoss:0.109397, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.108181, validLoss:0.109575, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.108181, validLoss:0.107485, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.108180, validLoss:0.111602, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.108172, validLoss:0.107709, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.107754, validLoss:0.111113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.108280, validLoss:0.110023, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.108099, validLoss:0.108772, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.108039, validLoss:0.107584, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.108241, validLoss:0.106965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.108163, validLoss:0.110689, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.108012, validLoss:0.106996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.108122, validLoss:0.109877, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.107988, validLoss:0.114781, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.108176, validLoss:0.108448, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.107981, validLoss:0.111514, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.107902, validLoss:0.108932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.108022, validLoss:0.109085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.107879, validLoss:0.108980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.108141, validLoss:0.110321, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.107941, validLoss:0.107775, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.108061, validLoss:0.108905, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.107963, validLoss:0.110086, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.108237, validLoss:0.109915, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.107991, validLoss:0.109237, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.108192, validLoss:0.107800, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.108133, validLoss:0.111586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.108171, validLoss:0.110555, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.108182, validLoss:0.110791, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.107991, validLoss:0.110080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.108160, validLoss:0.110852, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.108090, validLoss:0.105356, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.108144, validLoss:0.109459, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.107969, validLoss:0.107413, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.108186, validLoss:0.109495, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.108050, validLoss:0.109895, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.108155, validLoss:0.110199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.108118, validLoss:0.109088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.108071, validLoss:0.108222, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.108105, validLoss:0.108868, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.107877, validLoss:0.110610, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.108219, validLoss:0.111406, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.108172, validLoss:0.110325, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.108230, validLoss:0.112717, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.107980, validLoss:0.109748, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.108054, validLoss:0.107072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.108157, validLoss:0.109842, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.108273, validLoss:0.111164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.108095, validLoss:0.107800, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.108136, validLoss:0.105407, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.108182, validLoss:0.108022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.108144, validLoss:0.109200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.107932, validLoss:0.108135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.096719, validLoss:0.091033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.093193, validLoss:0.092689, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.091957, validLoss:0.090036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.090946, validLoss:0.089355, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.089483, validLoss:0.087897, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.088009, validLoss:0.085883, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.087351, validLoss:0.085660, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.086987, validLoss:0.086244, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.086866, validLoss:0.085150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.086863, validLoss:0.085233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.086865, validLoss:0.086517, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:84, trainLoss:0.086928, validLoss:0.086192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.073273, validLoss:0.040559, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.043949, validLoss:0.043721, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.041434, validLoss:0.039545, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.034673, validLoss:0.023667, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.018251, validLoss:0.012861, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.011246, validLoss:0.007815, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.007695, validLoss:0.005475, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.005158, validLoss:0.002946, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.003498, validLoss:0.002190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.002669, validLoss:0.001683, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.002306, validLoss:0.001550, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.002144, validLoss:0.001459, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.002102, validLoss:0.001352, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.002044, validLoss:0.001344, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.002013, validLoss:0.001363, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.001956, validLoss:0.001213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.001939, validLoss:0.001260, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.001940, validLoss:0.001263, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.001953, validLoss:0.001168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.001931, validLoss:0.001350, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.001935, validLoss:0.001298, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.001919, validLoss:0.001223, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.001907, validLoss:0.001177, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.001908, validLoss:0.001233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.001903, validLoss:0.001228, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.001923, validLoss:0.001317, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.001913, validLoss:0.001297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.001914, validLoss:0.001215, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.001897, validLoss:0.001156, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.001907, validLoss:0.001250, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.001897, validLoss:0.001198, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.001898, validLoss:0.001277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.001893, validLoss:0.001201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.001930, validLoss:0.001244, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.001916, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.001889, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.001890, validLoss:0.001275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.001920, validLoss:0.001207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.001907, validLoss:0.001249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.001896, validLoss:0.001210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001899, validLoss:0.001207, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001885, validLoss:0.001291, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001901, validLoss:0.001300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001904, validLoss:0.001233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001885, validLoss:0.001247, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001928, validLoss:0.001223, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001906, validLoss:0.001148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001853, validLoss:0.001232, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001906, validLoss:0.001164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001911, validLoss:0.001149, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001890, validLoss:0.001183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001907, validLoss:0.001343, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001921, validLoss:0.001211, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001893, validLoss:0.001255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001883, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001889, validLoss:0.001268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001906, validLoss:0.001151, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001766, validLoss:0.001174, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001886, validLoss:0.001274, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001873, validLoss:0.001147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001883, validLoss:0.001240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001879, validLoss:0.001159, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001874, validLoss:0.001214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001881, validLoss:0.001217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001898, validLoss:0.001258, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001908, validLoss:0.001393, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001908, validLoss:0.001257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001908, validLoss:0.001190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001937, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001875, validLoss:0.001170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001874, validLoss:0.001221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001908, validLoss:0.001259, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001876, validLoss:0.001189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001894, validLoss:0.001208, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001894, validLoss:0.001184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001871, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001876, validLoss:0.001268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001901, validLoss:0.001385, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001900, validLoss:0.001244, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001931, validLoss:0.001199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001882, validLoss:0.001177, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001910, validLoss:0.001240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001877, validLoss:0.001143, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001869, validLoss:0.001241, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001849, validLoss:0.001241, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001902, validLoss:0.001222, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001925, validLoss:0.001221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001876, validLoss:0.001248, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001877, validLoss:0.001172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001932, validLoss:0.001225, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001914, validLoss:0.001194, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001870, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001915, validLoss:0.001132, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001883, validLoss:0.001127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001866, validLoss:0.001230, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001901, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001896, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001883, validLoss:0.001218, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001895, validLoss:0.001214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001904, validLoss:0.001162, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:185, trainLoss:0.001863, validLoss:0.001181, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001881, validLoss:0.001241, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001864, validLoss:0.001269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001864, validLoss:0.001158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001893, validLoss:0.001231, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001861, validLoss:0.001191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001863, validLoss:0.001106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001891, validLoss:0.001248, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001907, validLoss:0.001165, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001860, validLoss:0.001219, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001864, validLoss:0.001173, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001902, validLoss:0.001267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001898, validLoss:0.001198, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001864, validLoss:0.001183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001856, validLoss:0.001179, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.317206, g_loss:2.140637, d accuracy:0.697917, d AUC:0.945964, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.863827, g_loss:2.866172, d accuracy:0.859375, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.348986, g_loss:5.177577, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:3, d_loss:0.308323, g_loss:5.623213, d accuracy:0.994792, d AUC:0.999349, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:4, d_loss:0.111713, g_loss:7.112702, d accuracy:0.958333, d AUC:0.969727, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:5, d_loss:0.105423, g_loss:7.681703, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.057554, g_loss:9.045237, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.028189, g_loss:9.739260, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.011876, g_loss:8.572903, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.024054, g_loss:6.529404, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.038263, g_loss:7.139297, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.023978, g_loss:11.938837, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.010802, g_loss:10.674932, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.007413, g_loss:8.047451, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.019781, g_loss:6.802846, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:15, d_loss:0.138672, g_loss:4.040887, d accuracy:0.953125, d AUC:0.999349, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:16, d_loss:0.247742, g_loss:2.642667, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.090550, g_loss:3.352774, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.033221, g_loss:4.058974, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.068403, g_loss:3.210252, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.029850, g_loss:5.145487, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.022732, g_loss:5.268044, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:22, d_loss:0.097871, g_loss:3.861444, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.031914, g_loss:5.512970, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.028653, g_loss:6.007379, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.017007, g_loss:6.115581, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.014804, g_loss:5.651479, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.022023, g_loss:5.450241, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.030642, g_loss:5.987156, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.014070, g_loss:6.774257, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.016695, g_loss:7.726529, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:31, d_loss:0.162534, g_loss:5.449495, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:32, d_loss:0.194246, g_loss:3.712346, d accuracy:0.791667, d AUC:0.857422, g accuracy:0.625000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.649873, g_loss:4.296919, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.153321, g_loss:6.738122, d accuracy:0.968750, d AUC:0.997396, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:35, d_loss:0.166088, g_loss:5.876426, d accuracy:0.916667, d AUC:0.971029, g accuracy:0.895833, rdf 0.000000\n",
      "Epoch:36, d_loss:0.273622, g_loss:8.839535, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:37, d_loss:0.034320, g_loss:8.168020, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:38, d_loss:0.034518, g_loss:9.139082, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.023831, g_loss:10.114542, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.108844, g_loss:7.578708, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.281680, g_loss:6.065148, d accuracy:0.812500, d AUC:0.837240, g accuracy:0.708333, rdf 0.000000\n",
      "Epoch:42, d_loss:0.203565, g_loss:9.361464, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.063947, g_loss:9.724413, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.107928, g_loss:5.994111, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:45, d_loss:0.156557, g_loss:3.187399, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:46, d_loss:0.091771, g_loss:3.622158, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.118127, g_loss:3.222542, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:48, d_loss:0.174343, g_loss:3.019600, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.177446, g_loss:3.153421, d accuracy:0.984375, d AUC:0.998047, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.235586, validLoss:0.184274, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.177082, validLoss:0.169239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.162439, validLoss:0.157656, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.154943, validLoss:0.154588, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.150995, validLoss:0.150839, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.148616, validLoss:0.150487, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.146840, validLoss:0.149357, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.145722, validLoss:0.147588, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.144732, validLoss:0.146724, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.144216, validLoss:0.144671, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.144002, validLoss:0.145756, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.143781, validLoss:0.144000, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.143694, validLoss:0.144179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.143623, validLoss:0.144686, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.143241, validLoss:0.142667, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.143145, validLoss:0.146465, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.143105, validLoss:0.141250, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.143325, validLoss:0.144009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.143001, validLoss:0.147292, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.143244, validLoss:0.144291, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.143085, validLoss:0.145191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.143134, validLoss:0.144554, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.143089, validLoss:0.146572, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.143238, validLoss:0.146254, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.143314, validLoss:0.142865, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.143166, validLoss:0.143939, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.142919, validLoss:0.147226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.143198, validLoss:0.146257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.143065, validLoss:0.144442, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.143123, validLoss:0.142816, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.143303, validLoss:0.143693, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.143270, validLoss:0.144559, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.143188, validLoss:0.142112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.143387, validLoss:0.146342, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.143084, validLoss:0.146502, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.143145, validLoss:0.146001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.143166, validLoss:0.144353, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.143083, validLoss:0.145541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.143213, validLoss:0.146133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.143166, validLoss:0.143642, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.143337, validLoss:0.143909, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.143224, validLoss:0.142771, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.143419, validLoss:0.147474, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.143247, validLoss:0.148702, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.143327, validLoss:0.146186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.143267, validLoss:0.145412, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.143185, validLoss:0.141602, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.143354, validLoss:0.145983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.143257, validLoss:0.143374, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.143160, validLoss:0.143712, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.143127, validLoss:0.142654, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.143319, validLoss:0.144736, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.143371, validLoss:0.145534, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.143340, validLoss:0.145040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.143248, validLoss:0.144939, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.143212, validLoss:0.145199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.143161, validLoss:0.146669, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.143359, validLoss:0.144670, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.143302, validLoss:0.146092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.143345, validLoss:0.144252, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.143431, validLoss:0.145038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.143095, validLoss:0.146119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.143271, validLoss:0.146794, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.143286, validLoss:0.147889, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.143413, validLoss:0.146275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.143477, validLoss:0.147334, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.143111, validLoss:0.143351, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.143334, validLoss:0.146833, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.143461, validLoss:0.144389, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.143285, validLoss:0.146847, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.143184, validLoss:0.144549, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.143368, validLoss:0.145037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.143273, validLoss:0.141193, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.143316, validLoss:0.143048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.143336, validLoss:0.145951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.143316, validLoss:0.142932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.143213, validLoss:0.147204, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.143166, validLoss:0.145963, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.143459, validLoss:0.146838, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.143076, validLoss:0.144703, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.143448, validLoss:0.143923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.143271, validLoss:0.146651, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.143463, validLoss:0.146643, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.143238, validLoss:0.146208, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.143152, validLoss:0.144031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.143282, validLoss:0.146355, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.143339, validLoss:0.145135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.119449, validLoss:0.105147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.106866, validLoss:0.102408, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.106059, validLoss:0.103210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.105973, validLoss:0.105844, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.105884, validLoss:0.103051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.105731, validLoss:0.102541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.105794, validLoss:0.105689, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.105770, validLoss:0.105672, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:95, trainLoss:0.106071, validLoss:0.102848, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.105947, validLoss:0.104933, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.105789, validLoss:0.102175, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.105708, validLoss:0.107405, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.105625, validLoss:0.105821, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.105701, validLoss:0.102583, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.105633, validLoss:0.105300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.105509, validLoss:0.105316, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.105732, validLoss:0.103439, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.105663, validLoss:0.107169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.105283, validLoss:0.104408, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.105406, validLoss:0.101851, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.105635, validLoss:0.106158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.105493, validLoss:0.107325, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.105436, validLoss:0.105120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.105530, validLoss:0.105980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.105513, validLoss:0.103362, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.105416, validLoss:0.103981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.105447, validLoss:0.104759, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.105232, validLoss:0.104713, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.104564, validLoss:0.090807, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.091316, validLoss:0.086249, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.089970, validLoss:0.087966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.089095, validLoss:0.084727, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.087539, validLoss:0.085331, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.085749, validLoss:0.081811, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.084687, validLoss:0.081298, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.084283, validLoss:0.080198, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.084392, validLoss:0.081209, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.084246, validLoss:0.081212, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.084230, validLoss:0.080140, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.084325, validLoss:0.081190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.084188, validLoss:0.081221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.084094, validLoss:0.082282, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.084437, validLoss:0.081189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.084073, validLoss:0.080164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.084323, validLoss:0.079024, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.084187, validLoss:0.081133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.084155, validLoss:0.083281, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.084212, validLoss:0.082187, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.084307, validLoss:0.082178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.084286, validLoss:0.079044, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.084308, validLoss:0.082304, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.084321, validLoss:0.080101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.084177, validLoss:0.081205, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.084280, validLoss:0.083197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.084295, validLoss:0.082246, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.084082, validLoss:0.081147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.083953, validLoss:0.079039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.084284, validLoss:0.081181, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.084160, validLoss:0.083198, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.084071, validLoss:0.080092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.084047, validLoss:0.082145, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.084264, validLoss:0.082192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.084164, validLoss:0.080133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.084298, validLoss:0.082243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.084316, validLoss:0.082319, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.084107, validLoss:0.082276, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.084307, validLoss:0.081143, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.084300, validLoss:0.082168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.084251, validLoss:0.081072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.084158, validLoss:0.081152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.084291, validLoss:0.081214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.084366, validLoss:0.080079, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.084163, validLoss:0.080099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.084174, validLoss:0.078990, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.084038, validLoss:0.081085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.084278, validLoss:0.083214, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.084068, validLoss:0.080227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.084289, validLoss:0.080096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.084313, validLoss:0.081123, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.084156, validLoss:0.081070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.084284, validLoss:0.080101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.084047, validLoss:0.083213, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.084153, validLoss:0.082164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.084355, validLoss:0.081177, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.084198, validLoss:0.081155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.084210, validLoss:0.082189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.084262, validLoss:0.079098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.084055, validLoss:0.082182, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.084208, validLoss:0.084263, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.084175, validLoss:0.081101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.084158, validLoss:0.081061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.084298, validLoss:0.081069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.084158, validLoss:0.080006, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.084360, validLoss:0.081196, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.084172, validLoss:0.082184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.080131, validLoss:0.070297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.069676, validLoss:0.066632, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.066344, validLoss:0.062403, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.060087, validLoss:0.054696, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.054760, validLoss:0.052132, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.053940, validLoss:0.050959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.050106, validLoss:0.018733, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.017337, validLoss:0.013149, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.012039, validLoss:0.011403, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.009863, validLoss:0.008645, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.006956, validLoss:0.005686, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:193, trainLoss:0.004606, validLoss:0.003543, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.002808, validLoss:0.001761, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001973, validLoss:0.001211, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001745, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001769, validLoss:0.001175, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001748, validLoss:0.001099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001699, validLoss:0.001121, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.852202, g_loss:2.569655, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.919545, g_loss:1.138249, d accuracy:0.635417, d AUC:0.892904, g accuracy:0.281250, rdf 0.000000\n",
      "Epoch:2, d_loss:0.969904, g_loss:1.580923, d accuracy:0.598958, d AUC:0.865885, g accuracy:0.197917, rdf 0.000000\n",
      "Epoch:3, d_loss:0.961756, g_loss:1.477478, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.379376, g_loss:3.617838, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.158682, g_loss:5.257826, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.092655, g_loss:6.167029, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.066379, g_loss:6.455422, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:8, d_loss:0.189437, g_loss:4.694230, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.161001, g_loss:2.797859, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.151714, g_loss:2.652126, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.047405, g_loss:4.061587, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.029880, g_loss:4.125068, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.137005, g_loss:3.198781, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:14, d_loss:0.081738, g_loss:4.450970, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:15, d_loss:0.070751, g_loss:4.785987, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.042933, g_loss:5.181720, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.173218, g_loss:5.924304, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.043971, g_loss:7.238116, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.067162, g_loss:8.738674, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.061448, g_loss:6.190734, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.026953, g_loss:7.634245, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.013844, g_loss:7.943902, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.018771, g_loss:6.633770, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:24, d_loss:0.087077, g_loss:6.171168, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.020997, g_loss:6.830314, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.026447, g_loss:6.175878, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.051398, g_loss:4.072140, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.037288, g_loss:4.275537, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.100048, g_loss:4.036735, d accuracy:0.973958, d AUC:0.995443, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:30, d_loss:0.090404, g_loss:6.183404, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.055970, g_loss:6.877183, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.018084, g_loss:6.658050, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.030993, g_loss:6.079729, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.221174, g_loss:6.897188, d accuracy:0.708333, d AUC:0.776367, g accuracy:0.697917, rdf 0.000000\n",
      "Epoch:35, d_loss:0.790610, g_loss:4.376592, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.140503, g_loss:4.874784, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.254528, g_loss:4.054212, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:38, d_loss:0.185276, g_loss:4.860986, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.197081, g_loss:5.020881, d accuracy:0.958333, d AUC:0.996419, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:40, d_loss:0.362241, g_loss:3.594842, d accuracy:0.947917, d AUC:0.998047, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:41, d_loss:0.370724, g_loss:3.047533, d accuracy:0.796875, d AUC:0.920573, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:42, d_loss:0.269104, g_loss:4.678435, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.182564, g_loss:3.275201, d accuracy:0.984375, d AUC:0.999349, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:44, d_loss:0.351387, g_loss:2.954718, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:45, d_loss:0.210935, g_loss:3.335615, d accuracy:0.989583, d AUC:0.999674, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:46, d_loss:0.169245, g_loss:2.994750, d accuracy:0.979167, d AUC:0.997070, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:47, d_loss:0.214590, g_loss:2.971987, d accuracy:0.947917, d AUC:0.998698, g accuracy:0.895833, rdf 0.000000\n",
      "Epoch:48, d_loss:0.449947, g_loss:2.569126, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:49, d_loss:0.282570, g_loss:3.166307, d accuracy:0.963542, d AUC:0.996419, g accuracy:0.958333, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.214423, validLoss:0.172938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.162710, validLoss:0.148529, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.119768, validLoss:0.097319, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.094347, validLoss:0.087724, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.084981, validLoss:0.080851, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.079137, validLoss:0.075586, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:6, trainLoss:0.075336, validLoss:0.073144, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.072672, validLoss:0.072541, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.071196, validLoss:0.071437, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.070086, validLoss:0.070879, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.069489, validLoss:0.070482, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.069110, validLoss:0.071331, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.068703, validLoss:0.071061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.068716, validLoss:0.069898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.068361, validLoss:0.069844, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.068357, validLoss:0.070814, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.068319, validLoss:0.069669, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.068068, validLoss:0.061992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.051738, validLoss:0.045141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.043799, validLoss:0.039164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.038639, validLoss:0.037436, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.037369, validLoss:0.035755, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.036989, validLoss:0.036511, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.036687, validLoss:0.034300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.036605, validLoss:0.036324, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.036556, validLoss:0.034240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.036416, validLoss:0.036271, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.036653, validLoss:0.035266, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.036553, validLoss:0.035256, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.036535, validLoss:0.034221, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.036620, validLoss:0.034235, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.036514, validLoss:0.036328, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.036419, validLoss:0.034138, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.036618, validLoss:0.036262, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.036508, validLoss:0.037307, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.036629, validLoss:0.034201, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.036525, validLoss:0.036300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.036397, validLoss:0.035226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.036533, validLoss:0.035208, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.036424, validLoss:0.035202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.036531, validLoss:0.035233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.036531, validLoss:0.034146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.036511, validLoss:0.035233, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.036433, validLoss:0.035199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.036654, validLoss:0.035229, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.036526, validLoss:0.035255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.036646, validLoss:0.035217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.036653, validLoss:0.037375, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.036578, validLoss:0.036289, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.036573, validLoss:0.036313, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.036447, validLoss:0.036296, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.036565, validLoss:0.036307, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.036572, validLoss:0.033165, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.036558, validLoss:0.035271, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.036462, validLoss:0.035260, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.036593, validLoss:0.035227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.036591, validLoss:0.035391, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.036572, validLoss:0.035290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.036583, validLoss:0.034253, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.036562, validLoss:0.034216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.036572, validLoss:0.035283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.036454, validLoss:0.035256, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.036690, validLoss:0.036333, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.036695, validLoss:0.035272, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.036703, validLoss:0.036300, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.036465, validLoss:0.035239, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.036584, validLoss:0.033204, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.036590, validLoss:0.034203, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.036687, validLoss:0.036295, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.036585, validLoss:0.034186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.036703, validLoss:0.033193, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.036592, validLoss:0.033197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.036588, validLoss:0.035279, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.036468, validLoss:0.034159, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.036475, validLoss:0.033155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.036707, validLoss:0.036304, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.036483, validLoss:0.035274, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.036610, validLoss:0.035222, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.036586, validLoss:0.035282, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.036432, validLoss:0.034257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.036614, validLoss:0.035348, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.036608, validLoss:0.035285, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.036521, validLoss:0.034220, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.036610, validLoss:0.034290, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.036604, validLoss:0.036375, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.036599, validLoss:0.035292, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.036592, validLoss:0.034212, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.036588, validLoss:0.037400, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.036486, validLoss:0.035306, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.026076, validLoss:0.016770, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.011353, validLoss:0.006695, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.005790, validLoss:0.003688, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.003692, validLoss:0.002150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.002380, validLoss:0.001297, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.001913, validLoss:0.001077, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.001799, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.001726, validLoss:0.000998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.001697, validLoss:0.001008, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.001724, validLoss:0.000980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.001704, validLoss:0.000953, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.001721, validLoss:0.001044, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.001676, validLoss:0.000986, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.001678, validLoss:0.000956, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:103, trainLoss:0.001679, validLoss:0.000958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.001722, validLoss:0.000919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.001688, validLoss:0.001073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.001688, validLoss:0.001001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.001681, validLoss:0.000966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.001666, validLoss:0.000935, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.001676, validLoss:0.001029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.001668, validLoss:0.000980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.001705, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.001708, validLoss:0.001085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.001705, validLoss:0.001000, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.001683, validLoss:0.000921, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.001687, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.001684, validLoss:0.000931, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.001670, validLoss:0.001006, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.001666, validLoss:0.000965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.001709, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.001710, validLoss:0.000911, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.001666, validLoss:0.000938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.001669, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.001733, validLoss:0.001008, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.001697, validLoss:0.000982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001676, validLoss:0.000949, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001677, validLoss:0.000970, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001665, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001683, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001702, validLoss:0.000999, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001676, validLoss:0.001045, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001715, validLoss:0.000964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001684, validLoss:0.000929, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001638, validLoss:0.000986, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001689, validLoss:0.000940, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001685, validLoss:0.000945, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001665, validLoss:0.000935, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001697, validLoss:0.001090, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001707, validLoss:0.000936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001675, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001671, validLoss:0.000932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001680, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001694, validLoss:0.000962, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001545, validLoss:0.000950, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001671, validLoss:0.001019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001647, validLoss:0.000951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001662, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001663, validLoss:0.000939, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001654, validLoss:0.000977, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001660, validLoss:0.001014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001678, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001696, validLoss:0.001112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001719, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001684, validLoss:0.000973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001725, validLoss:0.000948, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001653, validLoss:0.000892, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001659, validLoss:0.001011, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001688, validLoss:0.001008, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001658, validLoss:0.000969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001680, validLoss:0.000970, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001683, validLoss:0.000897, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001649, validLoss:0.000889, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001658, validLoss:0.000978, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001699, validLoss:0.001145, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001679, validLoss:0.001016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001711, validLoss:0.000980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001659, validLoss:0.000919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001687, validLoss:0.000992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001643, validLoss:0.000938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001647, validLoss:0.000991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001624, validLoss:0.000983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001683, validLoss:0.000971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001699, validLoss:0.001007, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001652, validLoss:0.001006, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001656, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001718, validLoss:0.001028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001702, validLoss:0.001003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001675, validLoss:0.000913, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001702, validLoss:0.000956, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001661, validLoss:0.000896, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001642, validLoss:0.001060, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001685, validLoss:0.000973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001674, validLoss:0.000992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001667, validLoss:0.000978, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001665, validLoss:0.000986, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001678, validLoss:0.000934, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001642, validLoss:0.000973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001668, validLoss:0.001012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001644, validLoss:0.001011, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001644, validLoss:0.000941, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001687, validLoss:0.001001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001634, validLoss:0.000961, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001638, validLoss:0.000834, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001680, validLoss:0.001002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001688, validLoss:0.000953, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001660, validLoss:0.001022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001644, validLoss:0.000939, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001679, validLoss:0.001062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001674, validLoss:0.000980, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:199, trainLoss:0.001642, validLoss:0.000979, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.504650, g_loss:2.029780, d accuracy:0.505208, d AUC:0.877930, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.886776, g_loss:3.584935, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:2, d_loss:0.363964, g_loss:5.947423, d accuracy:0.932292, d AUC:0.972656, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:3, d_loss:0.341806, g_loss:8.721704, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.073519, g_loss:8.696337, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.027063, g_loss:9.019373, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.018748, g_loss:9.636394, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.027769, g_loss:10.503533, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.095785, g_loss:9.622135, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.040733, g_loss:8.207273, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.014177, g_loss:9.238085, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.016017, g_loss:9.851420, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.030464, g_loss:8.650668, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.034352, g_loss:7.140953, d accuracy:0.953125, d AUC:0.992513, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:14, d_loss:0.070606, g_loss:10.278461, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.024176, g_loss:9.855316, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.023787, g_loss:8.002782, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.029994, g_loss:9.013806, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:18, d_loss:0.045539, g_loss:7.490197, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.179257, g_loss:3.027122, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.148607, g_loss:2.319014, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.066860, g_loss:3.011581, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.080384, g_loss:2.974845, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:23, d_loss:0.101941, g_loss:3.085237, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.034019, g_loss:5.043561, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.046671, g_loss:4.620256, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.017864, g_loss:5.588243, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.023681, g_loss:5.467803, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.051119, g_loss:5.649919, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.196590, g_loss:3.920248, d accuracy:0.968750, d AUC:0.989909, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:30, d_loss:0.113335, g_loss:6.009974, d accuracy:0.984375, d AUC:0.999349, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:31, d_loss:0.153184, g_loss:7.863509, d accuracy:0.963542, d AUC:0.982422, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:32, d_loss:0.328448, g_loss:4.594808, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.336599, g_loss:4.632802, d accuracy:0.890625, d AUC:0.934896, g accuracy:0.791667, rdf 0.000000\n",
      "Epoch:34, d_loss:0.183152, g_loss:8.478549, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.077365, g_loss:6.332474, d accuracy:0.989583, d AUC:0.999674, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:36, d_loss:0.153643, g_loss:5.674838, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.052628, g_loss:5.597250, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.096866, g_loss:4.946011, d accuracy:0.989583, d AUC:0.999349, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:39, d_loss:0.200804, g_loss:4.335293, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.167729, g_loss:5.458452, d accuracy:0.973958, d AUC:1.000000, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:41, d_loss:0.238731, g_loss:4.391927, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.097530, g_loss:5.022980, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.201601, g_loss:3.474228, d accuracy:0.989583, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:44, d_loss:0.178397, g_loss:3.235485, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.159630, g_loss:3.079953, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.169051, g_loss:3.519191, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:47, d_loss:0.164537, g_loss:3.343286, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:48, d_loss:0.203611, g_loss:3.106086, d accuracy:0.989583, d AUC:0.998372, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:49, d_loss:0.236329, g_loss:3.192299, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n",
      "0      8\n",
      "1      4\n",
      "2      4\n",
      "3      8\n",
      "4      8\n",
      "      ..\n",
      "673    4\n",
      "674    8\n",
      "675    3\n",
      "676    8\n",
      "677    4\n",
      "Name: ethnicity, Length: 678, dtype: int64\n",
      "1    373\n",
      "0    305\n",
      "Name: approved, dtype: int64\n",
      "265 265 413 413\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.177721, validLoss:0.147367, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.138912, validLoss:0.127457, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.120064, validLoss:0.112041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.109248, validLoss:0.104151, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.103054, validLoss:0.097464, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:5, trainLoss:0.099664, validLoss:0.095883, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.098044, validLoss:0.097448, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.097059, validLoss:0.093318, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.096315, validLoss:0.096161, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.095942, validLoss:0.096184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.095820, validLoss:0.096283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.095701, validLoss:0.094796, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.095456, validLoss:0.096268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.095278, validLoss:0.093932, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.095363, validLoss:0.094022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.095103, validLoss:0.092965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.095313, validLoss:0.093991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.094809, validLoss:0.094852, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.094162, validLoss:0.094357, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.093243, validLoss:0.092099, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.092138, validLoss:0.094199, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.090820, validLoss:0.092848, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.089945, validLoss:0.092659, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.089493, validLoss:0.093876, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.089302, validLoss:0.092986, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.089062, validLoss:0.091741, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.089315, validLoss:0.092887, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.089281, validLoss:0.092306, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.089045, validLoss:0.092844, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.089164, validLoss:0.092275, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.089223, validLoss:0.093064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.089194, validLoss:0.091633, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.089105, validLoss:0.091455, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.089050, validLoss:0.094002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.089204, validLoss:0.093586, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.089214, validLoss:0.093062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.088991, validLoss:0.091098, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.089225, validLoss:0.092022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.089142, validLoss:0.092240, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.089234, validLoss:0.092276, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.089150, validLoss:0.091982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.089265, validLoss:0.091478, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.089167, validLoss:0.093558, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.089244, validLoss:0.092842, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.089156, validLoss:0.091692, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.089246, validLoss:0.090906, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.089105, validLoss:0.091534, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.089298, validLoss:0.093039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.089295, validLoss:0.090548, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.089213, validLoss:0.092269, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.089324, validLoss:0.093054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.089204, validLoss:0.092066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.089279, validLoss:0.091108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.089216, validLoss:0.091516, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.089249, validLoss:0.092236, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.089159, validLoss:0.092402, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.089295, validLoss:0.093651, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.089305, validLoss:0.093065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.089210, validLoss:0.092073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.089161, validLoss:0.091712, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.089150, validLoss:0.093617, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.089105, validLoss:0.092497, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.089177, validLoss:0.093651, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.089329, validLoss:0.093258, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.089223, validLoss:0.093621, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.089242, validLoss:0.092885, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.089335, validLoss:0.093052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.089318, validLoss:0.091389, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.089325, validLoss:0.090886, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.089265, validLoss:0.092085, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.089344, validLoss:0.093062, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.089288, validLoss:0.091705, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.089252, validLoss:0.092973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.089338, validLoss:0.093613, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.089222, validLoss:0.092295, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.089265, validLoss:0.090330, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.089211, validLoss:0.091643, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.089321, validLoss:0.092863, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.089156, validLoss:0.092316, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.089296, validLoss:0.090987, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.089290, validLoss:0.091697, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.089375, validLoss:0.092268, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.089228, validLoss:0.092341, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.089229, validLoss:0.090980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.089371, validLoss:0.092314, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.089374, validLoss:0.091482, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.089287, validLoss:0.093112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.089355, validLoss:0.091525, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.089388, validLoss:0.091745, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.089230, validLoss:0.093080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.069056, validLoss:0.052056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.045899, validLoss:0.045659, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.043187, validLoss:0.044081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.042535, validLoss:0.044226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.042157, validLoss:0.043729, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.041659, validLoss:0.043430, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.041147, validLoss:0.043027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.040643, validLoss:0.042375, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.040164, validLoss:0.042891, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.039841, validLoss:0.042664, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.039579, validLoss:0.040626, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.039386, validLoss:0.041219, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.039312, validLoss:0.041169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.039320, validLoss:0.041047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.039328, validLoss:0.040604, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.039259, validLoss:0.042282, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:106, trainLoss:0.039307, validLoss:0.041707, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.039298, validLoss:0.041637, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.039289, validLoss:0.041726, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.039234, validLoss:0.040514, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.039262, validLoss:0.041728, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.039259, validLoss:0.042344, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.039326, validLoss:0.042294, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.039234, validLoss:0.042158, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.039177, validLoss:0.042277, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.039222, validLoss:0.041022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.039283, validLoss:0.040533, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.039271, validLoss:0.041611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.039316, validLoss:0.042243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.039321, validLoss:0.042156, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.016190, validLoss:0.004020, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.003589, validLoss:0.002197, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.002637, validLoss:0.001833, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.002240, validLoss:0.001518, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.002055, validLoss:0.001405, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.001951, validLoss:0.001345, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.001860, validLoss:0.001289, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.001823, validLoss:0.001255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.001795, validLoss:0.001200, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.001752, validLoss:0.001227, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.001795, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.001756, validLoss:0.001088, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.001695, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.001751, validLoss:0.001117, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.001735, validLoss:0.001122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.001716, validLoss:0.001081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.001747, validLoss:0.001217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.001756, validLoss:0.001100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.001720, validLoss:0.001183, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.001719, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.001716, validLoss:0.001152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.001729, validLoss:0.001112, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.001586, validLoss:0.001103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.001709, validLoss:0.001170, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.001693, validLoss:0.001061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.001690, validLoss:0.001111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.001693, validLoss:0.001069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001696, validLoss:0.001114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001695, validLoss:0.001108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001712, validLoss:0.001147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001732, validLoss:0.001242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001752, validLoss:0.001166, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001721, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001748, validLoss:0.001091, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001687, validLoss:0.001021, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001689, validLoss:0.001140, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001720, validLoss:0.001109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001684, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001698, validLoss:0.001075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001706, validLoss:0.000987, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001670, validLoss:0.000998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001684, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001725, validLoss:0.001267, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001704, validLoss:0.001141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001740, validLoss:0.001089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001674, validLoss:0.001029, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001701, validLoss:0.001097, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001669, validLoss:0.001031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001667, validLoss:0.001102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001656, validLoss:0.001107, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001714, validLoss:0.001101, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001735, validLoss:0.001125, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001685, validLoss:0.001125, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001679, validLoss:0.001119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001741, validLoss:0.001106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001722, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001693, validLoss:0.001027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001720, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001681, validLoss:0.001001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001658, validLoss:0.001157, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001705, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001704, validLoss:0.001076, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001692, validLoss:0.001092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001684, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001687, validLoss:0.001038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001673, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001691, validLoss:0.001111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001665, validLoss:0.001116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001656, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001696, validLoss:0.001110, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001655, validLoss:0.001064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001658, validLoss:0.000913, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001691, validLoss:0.001108, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001706, validLoss:0.001081, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001675, validLoss:0.001080, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001652, validLoss:0.000997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001686, validLoss:0.001146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001688, validLoss:0.001070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001655, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001641, validLoss:0.001052, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.317718, g_loss:2.132915, d accuracy:0.593750, d AUC:0.991211, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, d_loss:0.834071, g_loss:4.277126, d accuracy:0.817708, d AUC:0.963216, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:2, d_loss:0.612756, g_loss:5.562011, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:3, d_loss:0.137172, g_loss:7.141167, d accuracy:0.968750, d AUC:0.989258, g accuracy:0.937500, rdf 0.000000\n",
      "Epoch:4, d_loss:0.166192, g_loss:9.108832, d accuracy:0.989583, d AUC:0.998698, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:5, d_loss:0.108320, g_loss:11.426302, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:6, d_loss:0.092876, g_loss:10.008698, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.074491, g_loss:8.544839, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.025374, g_loss:8.826416, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.011206, g_loss:9.487642, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.005502, g_loss:9.709200, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.003966, g_loss:9.537326, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.003169, g_loss:9.398135, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.005137, g_loss:8.663976, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.003797, g_loss:9.682992, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.007062, g_loss:7.832926, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:16, d_loss:0.257833, g_loss:2.253041, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:17, d_loss:0.117865, g_loss:2.518210, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:18, d_loss:0.103487, g_loss:2.293839, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.025709, g_loss:4.681380, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.016322, g_loss:4.782111, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.346148, g_loss:2.789261, d accuracy:0.973958, d AUC:0.999349, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:22, d_loss:0.067605, g_loss:5.600494, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:23, d_loss:0.066710, g_loss:4.726762, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.111047, g_loss:4.803278, d accuracy:0.973958, d AUC:0.997070, g accuracy:0.947917, rdf 0.000000\n",
      "Epoch:25, d_loss:0.319726, g_loss:4.490638, d accuracy:0.984375, d AUC:0.999023, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.126615, g_loss:5.719356, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.104962, g_loss:5.809461, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.047619, g_loss:5.345635, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.133352, g_loss:4.194400, d accuracy:0.869792, d AUC:0.960612, g accuracy:0.739583, rdf 0.000000\n",
      "Epoch:30, d_loss:0.339958, g_loss:3.750713, d accuracy:0.963542, d AUC:0.999023, g accuracy:0.927083, rdf 0.000000\n",
      "Epoch:31, d_loss:0.379761, g_loss:6.353925, d accuracy:0.921875, d AUC:0.971354, g accuracy:0.906250, rdf 0.000000\n",
      "Epoch:32, d_loss:0.183302, g_loss:6.204707, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.115515, g_loss:6.603321, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.110245, g_loss:6.675592, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.099231, g_loss:7.174231, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.045822, g_loss:6.790202, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.043052, g_loss:6.208976, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.211188, g_loss:4.762197, d accuracy:0.979167, d AUC:1.000000, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:39, d_loss:0.501192, g_loss:6.922139, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:40, d_loss:0.052303, g_loss:7.635487, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:41, d_loss:0.138991, g_loss:5.594194, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:42, d_loss:0.098602, g_loss:7.279280, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.090583, g_loss:6.727435, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.131752, g_loss:5.450616, d accuracy:0.984375, d AUC:0.996419, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:45, d_loss:0.236758, g_loss:4.356385, d accuracy:0.895833, d AUC:0.990234, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:46, d_loss:0.285000, g_loss:3.439632, d accuracy:0.979167, d AUC:0.998698, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:47, d_loss:0.217833, g_loss:2.886425, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.170173, g_loss:3.012190, d accuracy:0.979167, d AUC:0.993815, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:49, d_loss:0.241011, g_loss:3.015193, d accuracy:0.942708, d AUC:0.993164, g accuracy:0.968750, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.8545994065281899\n",
      "PRDC: recall 0.5663716814159292\n",
      "PRDC: density 0.7456973293768546\n",
      "PRDC: coverage 0.39233038348082594\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.257574, validLoss:0.173490, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.147579, validLoss:0.115210, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.112195, validLoss:0.095994, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.094194, validLoss:0.085635, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.083943, validLoss:0.077923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.077579, validLoss:0.064713, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.055821, validLoss:0.047759, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.043486, validLoss:0.039433, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.037863, validLoss:0.036470, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.035421, validLoss:0.032899, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.034447, validLoss:0.032148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.033783, validLoss:0.030639, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.033280, validLoss:0.031155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.033039, validLoss:0.030821, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.032564, validLoss:0.029659, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.032371, validLoss:0.032667, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.032283, validLoss:0.028378, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.032425, validLoss:0.030385, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:18, trainLoss:0.032132, validLoss:0.031320, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.032185, validLoss:0.030242, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.032137, validLoss:0.032261, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.032086, validLoss:0.029075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.032047, validLoss:0.031153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.032023, validLoss:0.031139, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.032008, validLoss:0.028041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.031990, validLoss:0.030089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:26, trainLoss:0.031864, validLoss:0.032162, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.031983, validLoss:0.030083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.031983, validLoss:0.031126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.031977, validLoss:0.029047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.032052, validLoss:0.031172, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.032051, validLoss:0.030127, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.031961, validLoss:0.029000, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.031940, validLoss:0.031094, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.031841, validLoss:0.031109, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.031950, validLoss:0.031102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.032072, validLoss:0.029052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.031843, validLoss:0.031122, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.031966, validLoss:0.030073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.031972, validLoss:0.030075, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.031971, validLoss:0.029061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.032090, validLoss:0.027959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.032060, validLoss:0.032155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.031987, validLoss:0.031073, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.031991, validLoss:0.031120, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.032083, validLoss:0.031131, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.031991, validLoss:0.029036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.032103, validLoss:0.031162, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.032030, validLoss:0.027986, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.031910, validLoss:0.031141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.032014, validLoss:0.029053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.032128, validLoss:0.029037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.032023, validLoss:0.032180, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.032016, validLoss:0.031134, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.032036, validLoss:0.031129, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.032044, validLoss:0.029000, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.032043, validLoss:0.031230, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.032143, validLoss:0.030103, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.032155, validLoss:0.032195, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.032022, validLoss:0.029052, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.032146, validLoss:0.032184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.032031, validLoss:0.030113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.032159, validLoss:0.031142, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.032177, validLoss:0.031138, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.032172, validLoss:0.031139, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.032153, validLoss:0.031126, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.031948, validLoss:0.028043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.032057, validLoss:0.031137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.032168, validLoss:0.030054, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.032062, validLoss:0.032150, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.031963, validLoss:0.030113, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.032185, validLoss:0.030106, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.032079, validLoss:0.028003, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.032064, validLoss:0.028979, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.032172, validLoss:0.030069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.032198, validLoss:0.029064, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.032084, validLoss:0.031153, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.031980, validLoss:0.031061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.032181, validLoss:0.032186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.032038, validLoss:0.029100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.032220, validLoss:0.029093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.031990, validLoss:0.031138, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.032222, validLoss:0.031116, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.032095, validLoss:0.031194, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.032099, validLoss:0.030161, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.032097, validLoss:0.032202, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.032084, validLoss:0.031118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.032193, validLoss:0.029111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.032202, validLoss:0.029078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.032001, validLoss:0.030152, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.032097, validLoss:0.030133, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.032104, validLoss:0.029037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.031999, validLoss:0.029111, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.032191, validLoss:0.030056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.031978, validLoss:0.031132, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.032217, validLoss:0.029065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.032210, validLoss:0.031155, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.031982, validLoss:0.029114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.031995, validLoss:0.031140, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.032209, validLoss:0.030100, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.032120, validLoss:0.029118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.032200, validLoss:0.030096, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.031991, validLoss:0.031164, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.032209, validLoss:0.031159, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.032122, validLoss:0.030093, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.031989, validLoss:0.030167, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.032108, validLoss:0.029117, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.032099, validLoss:0.031185, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.032096, validLoss:0.031134, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.031999, validLoss:0.031208, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.032110, validLoss:0.032194, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.032242, validLoss:0.029118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.032028, validLoss:0.030234, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.032141, validLoss:0.030168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.032004, validLoss:0.030102, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.032011, validLoss:0.030148, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.031996, validLoss:0.030087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.032109, validLoss:0.031192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.032215, validLoss:0.029043, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:119, trainLoss:0.032252, validLoss:0.031226, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.032140, validLoss:0.031083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.032118, validLoss:0.030119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.032122, validLoss:0.030147, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.032160, validLoss:0.030119, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.032124, validLoss:0.030137, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:125, trainLoss:0.032012, validLoss:0.030130, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.032240, validLoss:0.031184, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.032115, validLoss:0.029118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.032016, validLoss:0.032270, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.032243, validLoss:0.031217, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.032007, validLoss:0.030190, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.032257, validLoss:0.029038, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.032123, validLoss:0.030083, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.032089, validLoss:0.031174, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.032139, validLoss:0.032192, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.032238, validLoss:0.032216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.032108, validLoss:0.028005, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.032138, validLoss:0.031255, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.032253, validLoss:0.029078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.032012, validLoss:0.031223, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.032229, validLoss:0.032165, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.032232, validLoss:0.031216, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.032026, validLoss:0.031159, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.031883, validLoss:0.029069, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.032231, validLoss:0.031219, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.032101, validLoss:0.031149, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.032006, validLoss:0.030115, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.031995, validLoss:0.031135, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.032106, validLoss:0.031176, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.032003, validLoss:0.030168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.032133, validLoss:0.030168, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.032150, validLoss:0.031298, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.032057, validLoss:0.031243, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.032148, validLoss:0.031196, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.032268, validLoss:0.031141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.032102, validLoss:0.030061, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.032109, validLoss:0.031191, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.032251, validLoss:0.030179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.032112, validLoss:0.030117, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.032013, validLoss:0.029087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.032128, validLoss:0.029000, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.031991, validLoss:0.029019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.032007, validLoss:0.031178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.032036, validLoss:0.029244, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.032132, validLoss:0.030162, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.032158, validLoss:0.030118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.032106, validLoss:0.030070, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.028063, validLoss:0.021860, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.017099, validLoss:0.014510, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.009474, validLoss:0.004146, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.002527, validLoss:0.001105, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001811, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001737, validLoss:0.001082, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001715, validLoss:0.001072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001694, validLoss:0.001019, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001741, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001729, validLoss:0.001035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001697, validLoss:0.000960, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001738, validLoss:0.001009, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001692, validLoss:0.000934, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001657, validLoss:0.001095, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001707, validLoss:0.000977, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001706, validLoss:0.001021, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001694, validLoss:0.001010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001682, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001693, validLoss:0.000961, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001676, validLoss:0.001021, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001683, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001667, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001657, validLoss:0.000962, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001701, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001655, validLoss:0.000977, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001652, validLoss:0.000855, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001695, validLoss:0.001039, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001698, validLoss:0.000994, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001677, validLoss:0.001027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001647, validLoss:0.000951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001683, validLoss:0.001074, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001686, validLoss:0.001001, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001656, validLoss:0.000988, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:1.095207, g_loss:2.519715, d accuracy:0.786458, d AUC:0.997396, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:1, d_loss:0.902839, g_loss:3.400067, d accuracy:0.614583, d AUC:0.813151, g accuracy:0.916667, rdf 0.000000\n",
      "Epoch:2, d_loss:0.657963, g_loss:4.919909, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:3, d_loss:0.113636, g_loss:6.462176, d accuracy:0.989583, d AUC:0.997396, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:4, d_loss:0.191341, g_loss:5.374642, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:5, d_loss:0.123539, g_loss:7.555363, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:6, d_loss:0.078035, g_loss:8.921938, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:7, d_loss:0.060508, g_loss:8.387254, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.023090, g_loss:9.852430, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.008585, g_loss:9.350512, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.005888, g_loss:8.154726, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, d_loss:0.121848, g_loss:4.586879, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.064581, g_loss:5.408113, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.078126, g_loss:3.416728, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.039928, g_loss:3.709508, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.031111, g_loss:3.844208, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:16, d_loss:0.013727, g_loss:5.831826, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:17, d_loss:0.018085, g_loss:5.667949, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.022024, g_loss:5.110168, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.009675, g_loss:6.268928, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.011080, g_loss:6.498234, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:21, d_loss:0.056576, g_loss:5.521651, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.249109, g_loss:4.895604, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.052585, g_loss:5.814124, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.052358, g_loss:6.250033, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.054419, g_loss:5.281831, d accuracy:0.984375, d AUC:0.999349, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:26, d_loss:0.099651, g_loss:5.152192, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.050527, g_loss:6.188135, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:28, d_loss:0.054609, g_loss:7.340846, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.011314, g_loss:7.505017, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.007605, g_loss:6.893282, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.058548, g_loss:4.471085, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:32, d_loss:0.189424, g_loss:4.660478, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.104708, g_loss:8.007154, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.096290, g_loss:6.715302, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.022656, g_loss:7.842181, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.021234, g_loss:6.531465, d accuracy:0.994792, d AUC:1.000000, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:37, d_loss:0.059610, g_loss:5.158847, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.025788, g_loss:7.765608, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:39, d_loss:0.016314, g_loss:6.151334, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.022384, g_loss:4.975129, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.023121, g_loss:4.750556, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.017557, g_loss:5.244390, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.013857, g_loss:5.446314, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.012335, g_loss:5.757318, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.010960, g_loss:5.699341, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.010228, g_loss:5.749550, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.010917, g_loss:5.416064, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.010477, g_loss:5.606344, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.010600, g_loss:5.566067, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "adult.npy\n",
      "Pretrain_Epoch:0, trainLoss:0.169553, validLoss:0.126543, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:1, trainLoss:0.115020, validLoss:0.095848, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:2, trainLoss:0.088147, validLoss:0.076092, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:3, trainLoss:0.073195, validLoss:0.066169, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:4, trainLoss:0.065933, validLoss:0.059643, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:5, trainLoss:0.062025, validLoss:0.058661, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:6, trainLoss:0.059397, validLoss:0.056883, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:7, trainLoss:0.057797, validLoss:0.054545, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:8, trainLoss:0.056565, validLoss:0.052740, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:9, trainLoss:0.055932, validLoss:0.052362, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:10, trainLoss:0.055560, validLoss:0.052998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:11, trainLoss:0.055332, validLoss:0.052959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:12, trainLoss:0.055239, validLoss:0.051819, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:13, trainLoss:0.055029, validLoss:0.051711, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:14, trainLoss:0.054933, validLoss:0.051739, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:15, trainLoss:0.054838, validLoss:0.051628, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:16, trainLoss:0.054828, validLoss:0.051605, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:17, trainLoss:0.054795, validLoss:0.052611, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:18, trainLoss:0.054758, validLoss:0.052547, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:19, trainLoss:0.054759, validLoss:0.052577, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:20, trainLoss:0.054742, validLoss:0.051539, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:21, trainLoss:0.054724, validLoss:0.052490, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:22, trainLoss:0.054731, validLoss:0.052543, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:23, trainLoss:0.054839, validLoss:0.053497, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:24, trainLoss:0.054829, validLoss:0.051488, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:25, trainLoss:0.054818, validLoss:0.051409, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:26, trainLoss:0.054801, validLoss:0.052499, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:27, trainLoss:0.054829, validLoss:0.052539, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:28, trainLoss:0.054707, validLoss:0.051402, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:29, trainLoss:0.054339, validLoss:0.051189, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:30, trainLoss:0.054025, validLoss:0.051179, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:31, trainLoss:0.054036, validLoss:0.052114, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:32, trainLoss:0.053852, validLoss:0.051998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:33, trainLoss:0.054001, validLoss:0.052020, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:34, trainLoss:0.053847, validLoss:0.051996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:35, trainLoss:0.053716, validLoss:0.051982, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:36, trainLoss:0.053694, validLoss:0.052020, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:37, trainLoss:0.053551, validLoss:0.053002, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:38, trainLoss:0.053765, validLoss:0.051935, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:39, trainLoss:0.053639, validLoss:0.050887, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:40, trainLoss:0.053740, validLoss:0.050904, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:41, trainLoss:0.053626, validLoss:0.050844, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:42, trainLoss:0.053698, validLoss:0.051936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:43, trainLoss:0.053621, validLoss:0.053974, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:44, trainLoss:0.053721, validLoss:0.050891, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:45, trainLoss:0.053592, validLoss:0.051955, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:46, trainLoss:0.053608, validLoss:0.050887, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:47, trainLoss:0.053709, validLoss:0.050945, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:48, trainLoss:0.053636, validLoss:0.052959, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:49, trainLoss:0.053629, validLoss:0.050915, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:50, trainLoss:0.053609, validLoss:0.050902, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:51, trainLoss:0.053629, validLoss:0.052998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:52, trainLoss:0.053737, validLoss:0.050893, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:53, trainLoss:0.053721, validLoss:0.051955, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:54, trainLoss:0.053628, validLoss:0.051942, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:55, trainLoss:0.053636, validLoss:0.052960, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:56, trainLoss:0.053630, validLoss:0.052012, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:57, trainLoss:0.053615, validLoss:0.050914, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:58, trainLoss:0.053635, validLoss:0.050922, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:59, trainLoss:0.053724, validLoss:0.050894, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:60, trainLoss:0.053737, validLoss:0.050924, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:61, trainLoss:0.053614, validLoss:0.051942, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:62, trainLoss:0.053636, validLoss:0.053006, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:63, trainLoss:0.053639, validLoss:0.052995, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:64, trainLoss:0.053750, validLoss:0.051937, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:65, trainLoss:0.053733, validLoss:0.052975, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:66, trainLoss:0.053647, validLoss:0.051961, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:67, trainLoss:0.053759, validLoss:0.051951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:68, trainLoss:0.053745, validLoss:0.051921, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:69, trainLoss:0.053753, validLoss:0.051919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:70, trainLoss:0.053770, validLoss:0.051976, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:71, trainLoss:0.053657, validLoss:0.051935, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:72, trainLoss:0.053757, validLoss:0.050894, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:73, trainLoss:0.053754, validLoss:0.051868, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:74, trainLoss:0.053647, validLoss:0.052973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:75, trainLoss:0.053773, validLoss:0.050910, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:76, trainLoss:0.053658, validLoss:0.054028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:77, trainLoss:0.053778, validLoss:0.051893, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:78, trainLoss:0.053756, validLoss:0.050901, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:79, trainLoss:0.053611, validLoss:0.053031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:80, trainLoss:0.053792, validLoss:0.051987, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:81, trainLoss:0.053784, validLoss:0.051944, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:82, trainLoss:0.053791, validLoss:0.051926, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:83, trainLoss:0.053680, validLoss:0.052010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:84, trainLoss:0.053676, validLoss:0.050965, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:85, trainLoss:0.053679, validLoss:0.050936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:86, trainLoss:0.053777, validLoss:0.050883, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:87, trainLoss:0.053772, validLoss:0.050958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:88, trainLoss:0.053663, validLoss:0.050923, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:89, trainLoss:0.053689, validLoss:0.050938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:90, trainLoss:0.053667, validLoss:0.053022, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:91, trainLoss:0.053672, validLoss:0.051915, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:92, trainLoss:0.053784, validLoss:0.050970, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:93, trainLoss:0.053658, validLoss:0.052964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:94, trainLoss:0.053765, validLoss:0.051939, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:95, trainLoss:0.053891, validLoss:0.050898, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:96, trainLoss:0.053782, validLoss:0.050919, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:97, trainLoss:0.053886, validLoss:0.050952, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:98, trainLoss:0.053793, validLoss:0.052992, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:99, trainLoss:0.053676, validLoss:0.052998, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:100, trainLoss:0.053805, validLoss:0.051997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:101, trainLoss:0.053662, validLoss:0.052996, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:102, trainLoss:0.053776, validLoss:0.050922, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:103, trainLoss:0.053784, validLoss:0.050927, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:104, trainLoss:0.053819, validLoss:0.054037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:105, trainLoss:0.053670, validLoss:0.052015, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:106, trainLoss:0.053670, validLoss:0.051980, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:107, trainLoss:0.053778, validLoss:0.051978, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:108, trainLoss:0.053778, validLoss:0.052971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:109, trainLoss:0.053790, validLoss:0.050951, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:110, trainLoss:0.053681, validLoss:0.051966, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:111, trainLoss:0.053705, validLoss:0.052034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:112, trainLoss:0.053825, validLoss:0.051049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:113, trainLoss:0.053725, validLoss:0.052014, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:114, trainLoss:0.053692, validLoss:0.051936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:115, trainLoss:0.053806, validLoss:0.052013, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:116, trainLoss:0.053689, validLoss:0.050884, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:117, trainLoss:0.053683, validLoss:0.053037, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:118, trainLoss:0.053786, validLoss:0.052991, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:119, trainLoss:0.053825, validLoss:0.053051, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:120, trainLoss:0.053832, validLoss:0.050847, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:121, trainLoss:0.053800, validLoss:0.051964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:122, trainLoss:0.053703, validLoss:0.050963, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:123, trainLoss:0.053854, validLoss:0.051972, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:124, trainLoss:0.053704, validLoss:0.051991, validReverseLoss:0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain_Epoch:125, trainLoss:0.053811, validLoss:0.050938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:126, trainLoss:0.053712, validLoss:0.050956, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:127, trainLoss:0.053696, validLoss:0.053072, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:128, trainLoss:0.053711, validLoss:0.050985, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:129, trainLoss:0.053826, validLoss:0.050971, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:130, trainLoss:0.053694, validLoss:0.050972, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:131, trainLoss:0.053732, validLoss:0.050883, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:132, trainLoss:0.053710, validLoss:0.051938, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:133, trainLoss:0.053672, validLoss:0.053035, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:134, trainLoss:0.053727, validLoss:0.050900, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:135, trainLoss:0.053712, validLoss:0.050915, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:136, trainLoss:0.053801, validLoss:0.051952, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:137, trainLoss:0.053828, validLoss:0.052058, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:138, trainLoss:0.053733, validLoss:0.051955, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:139, trainLoss:0.053807, validLoss:0.050973, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:140, trainLoss:0.053315, validLoss:0.038031, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:141, trainLoss:0.017394, validLoss:0.012283, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:142, trainLoss:0.011899, validLoss:0.011472, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:143, trainLoss:0.009028, validLoss:0.008257, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:144, trainLoss:0.005997, validLoss:0.004593, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:145, trainLoss:0.003366, validLoss:0.002078, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:146, trainLoss:0.002204, validLoss:0.001514, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:147, trainLoss:0.001851, validLoss:0.001206, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:148, trainLoss:0.001743, validLoss:0.001160, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:149, trainLoss:0.001702, validLoss:0.001178, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:150, trainLoss:0.001702, validLoss:0.001141, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:151, trainLoss:0.001704, validLoss:0.001187, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:152, trainLoss:0.001720, validLoss:0.001066, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:153, trainLoss:0.001683, validLoss:0.001089, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:154, trainLoss:0.001739, validLoss:0.001048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:155, trainLoss:0.001665, validLoss:0.000969, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:156, trainLoss:0.001662, validLoss:0.001136, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:157, trainLoss:0.001699, validLoss:0.001048, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:158, trainLoss:0.001654, validLoss:0.001034, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:159, trainLoss:0.001679, validLoss:0.001046, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:160, trainLoss:0.001686, validLoss:0.000955, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:161, trainLoss:0.001640, validLoss:0.000936, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:162, trainLoss:0.001646, validLoss:0.001059, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:163, trainLoss:0.001687, validLoss:0.001186, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:164, trainLoss:0.001673, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:165, trainLoss:0.001718, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:166, trainLoss:0.001648, validLoss:0.000983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:167, trainLoss:0.001675, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:168, trainLoss:0.001633, validLoss:0.000983, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:169, trainLoss:0.001638, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:170, trainLoss:0.001624, validLoss:0.001027, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:171, trainLoss:0.001684, validLoss:0.001032, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:172, trainLoss:0.001697, validLoss:0.001065, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:173, trainLoss:0.001661, validLoss:0.001055, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:174, trainLoss:0.001655, validLoss:0.001049, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:175, trainLoss:0.001710, validLoss:0.001043, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:176, trainLoss:0.001687, validLoss:0.001044, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:177, trainLoss:0.001668, validLoss:0.000958, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:178, trainLoss:0.001690, validLoss:0.001018, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:179, trainLoss:0.001656, validLoss:0.000946, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:180, trainLoss:0.001628, validLoss:0.001118, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:181, trainLoss:0.001678, validLoss:0.000997, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:182, trainLoss:0.001675, validLoss:0.001033, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:183, trainLoss:0.001664, validLoss:0.001036, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:184, trainLoss:0.001659, validLoss:0.001040, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:185, trainLoss:0.001667, validLoss:0.000981, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:186, trainLoss:0.001645, validLoss:0.001028, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:187, trainLoss:0.001661, validLoss:0.001050, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:188, trainLoss:0.001646, validLoss:0.001057, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:189, trainLoss:0.001637, validLoss:0.000976, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:190, trainLoss:0.001677, validLoss:0.001047, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:191, trainLoss:0.001633, validLoss:0.001016, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:192, trainLoss:0.001635, validLoss:0.000857, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:193, trainLoss:0.001673, validLoss:0.001056, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:194, trainLoss:0.001687, validLoss:0.001041, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:195, trainLoss:0.001662, validLoss:0.001053, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:196, trainLoss:0.001634, validLoss:0.000964, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:197, trainLoss:0.001669, validLoss:0.001087, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:198, trainLoss:0.001664, validLoss:0.001010, validReverseLoss:0.000000\n",
      "Pretrain_Epoch:199, trainLoss:0.001638, validLoss:0.001015, validReverseLoss:0.000000\n",
      "Epoch:0, d_loss:0.948119, g_loss:2.571221, d accuracy:0.994792, d AUC:0.999674, g accuracy:0.989583, rdf 0.000000\n",
      "Epoch:1, d_loss:0.881533, g_loss:1.613009, d accuracy:0.817708, d AUC:0.853841, g accuracy:0.697917, rdf 0.000000\n",
      "Epoch:2, d_loss:0.768741, g_loss:2.550965, d accuracy:0.770833, d AUC:0.860352, g accuracy:0.572917, rdf 0.000000\n",
      "Epoch:3, d_loss:0.661103, g_loss:3.798036, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:4, d_loss:0.255427, g_loss:3.851028, d accuracy:0.979167, d AUC:0.999674, g accuracy:0.958333, rdf 0.000000\n",
      "Epoch:5, d_loss:0.201703, g_loss:3.833144, d accuracy:0.989583, d AUC:1.000000, g accuracy:0.979167, rdf 0.000000\n",
      "Epoch:6, d_loss:0.550224, g_loss:3.044053, d accuracy:0.994792, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:7, d_loss:0.185407, g_loss:4.221200, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:8, d_loss:0.283378, g_loss:1.858272, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:9, d_loss:0.094405, g_loss:2.772457, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:10, d_loss:0.051448, g_loss:3.285367, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:11, d_loss:0.130193, g_loss:3.281123, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:12, d_loss:0.027890, g_loss:7.716370, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:13, d_loss:0.012675, g_loss:7.069435, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:14, d_loss:0.014161, g_loss:5.014674, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:15, d_loss:0.011205, g_loss:5.071570, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, d_loss:0.194072, g_loss:3.613797, d accuracy:0.630208, d AUC:1.000000, g accuracy:0.260417, rdf 0.000000\n",
      "Epoch:17, d_loss:0.149889, g_loss:5.810611, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:18, d_loss:0.018114, g_loss:5.154951, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:19, d_loss:0.052388, g_loss:3.672472, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:20, d_loss:0.019496, g_loss:5.829761, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:21, d_loss:0.013504, g_loss:5.433965, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:22, d_loss:0.071378, g_loss:5.074498, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:23, d_loss:0.018957, g_loss:6.438214, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:24, d_loss:0.012123, g_loss:6.910802, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:25, d_loss:0.030698, g_loss:6.740023, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:26, d_loss:0.008794, g_loss:8.479448, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:27, d_loss:0.006267, g_loss:8.478000, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:28, d_loss:0.005487, g_loss:7.466219, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:29, d_loss:0.005196, g_loss:6.978461, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:30, d_loss:0.004862, g_loss:6.621377, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:31, d_loss:0.004814, g_loss:6.496142, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:32, d_loss:0.004223, g_loss:6.439506, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:33, d_loss:0.004495, g_loss:6.413593, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:34, d_loss:0.004646, g_loss:6.357669, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:35, d_loss:0.004187, g_loss:6.386450, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:36, d_loss:0.004232, g_loss:6.359716, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:37, d_loss:0.004339, g_loss:6.361964, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:38, d_loss:0.015180, g_loss:5.599177, d accuracy:0.984375, d AUC:1.000000, g accuracy:0.968750, rdf 0.000000\n",
      "Epoch:39, d_loss:0.107126, g_loss:6.921731, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:40, d_loss:0.006635, g_loss:10.363530, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:41, d_loss:0.005770, g_loss:8.250635, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:42, d_loss:0.006281, g_loss:7.424111, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:43, d_loss:0.038285, g_loss:6.237634, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:44, d_loss:0.269712, g_loss:6.342667, d accuracy:0.989583, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:45, d_loss:0.265133, g_loss:7.551974, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:46, d_loss:0.039285, g_loss:10.966322, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:47, d_loss:0.024541, g_loss:8.884985, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:48, d_loss:0.023418, g_loss:9.163267, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "Epoch:49, d_loss:0.020671, g_loss:9.462343, d accuracy:1.000000, d AUC:1.000000, g accuracy:1.000000, rdf 0.000000\n",
      "INFO:tensorflow:fair_unfair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:fair-49 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "fair-49\n",
      "INFO:tensorflow:Restoring parameters from fair-399\n",
      "burning in\n",
      "generating\n",
      "synth before: (672, 15) (672,)\n",
      "synth after: (672, 16)\n",
      "LOGGGING 265 265\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.5085106382978724\n",
      "PRDC: recall 0.28679245283018867\n",
      "PRDC: density 0.52\n",
      "PRDC: coverage 0.3471698113207547\n",
      "LOGGGING 413 413\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0]\n",
      "Computing neg\n",
      "(674, 16)\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6973293768545994\n",
      "PRDC: recall 0.0\n",
      "PRDC: density 0.6973293768545994\n",
      "PRDC: coverage 0.012106537530266344\n",
      "LOGGGING 678 678\n",
      "0.0\n",
      "nan\n",
      "Feature Importance =  [-0.033962264150943396, 0.0, -0.01327433628318584, -0.07924528301886792, 0.0, -0.030973451327433628, -0.018867924528301886, 0.0, -0.007374631268436578]\n",
      "#####################!OC model not defined !##################\n",
      "Computing metrics for no additional OneClass embedding\n",
      "Start computing P&R and D&C\n",
      "PRDC: precision 0.6201780415430267\n",
      "PRDC: recall 0.3938053097345133\n",
      "PRDC: density 0.5225519287833829\n",
      "PRDC: coverage 0.28761061946902655\n",
      "fairgan 0.0 0.0 -0.02 0.024 -1.0 0.0\n",
      "fairgan&$0.635\\pm0.11$&$0.246\\pm0.192$&$0.0\\pm0.0$&$-0.02\\pm0.024$&$0.777\\pm0.055$\\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "p_idx = 6\n",
    "p_attr = 'ethnicity'\n",
    "\n",
    "for p in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
    "#for p in [0, 0.2, 0.4]:\n",
    "    column_names = ['male', 'age', 'debt', 'married', 'bankcustomer', 'educationlevel', 'ethnicity', 'yearsemployed',\n",
    "               'priordefault', 'employed', 'creditscore', 'driverslicense', 'citizen', 'zip', 'income', 'approved']\n",
    "    data = pd.read_csv('data/crx.data', header=None,  names=column_names)\n",
    "    data.reset_index(drop=True, inplace=True) \n",
    "    data = data.dropna(how = 'all')\n",
    "\n",
    "    data = data[data.age != '?']\n",
    "    data.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    for feat in ['male', 'married','bankcustomer', 'educationlevel', 'ethnicity','priordefault', 'employed', 'driverslicense', 'citizen', 'zip', 'approved']:\n",
    "        data[feat] = preprocessing.LabelEncoder().fit_transform(data[feat])\n",
    "        \n",
    "    data['age'] = pd.to_numeric(data['age'],errors='coerce')\n",
    "\n",
    "    print(data['ethnicity'])\n",
    "\n",
    "    data.loc[data['ethnicity'] <= 4, 'ethnicity'] = 0\n",
    "    data.loc[data['ethnicity'] > 4, 'ethnicity']= 1\n",
    "\n",
    "\n",
    "    data.loc[data['ethnicity'] ==1 , 'employed'] =  1\n",
    "\n",
    "    biased_data = data.copy()\n",
    "\n",
    "    bias = p\n",
    "    biased_data.loc[biased_data['ethnicity'] == 1, 'approved'] = np.logical_and(biased_data.loc[biased_data['ethnicity'] == 1, 'approved'].values, np.random.binomial(1, bias, len(biased_data.loc[biased_data['ethnicity'] == 1, 'approved']))).astype(int)\n",
    "        \n",
    "    print(biased_data['approved'].value_counts())\n",
    "    thresh = 0.8\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    data[data.columns] = scaler.fit_transform(data)\n",
    "    biased_data[biased_data.columns] = scaler.transform(biased_data)\n",
    "    \n",
    "    import pickle \n",
    "    p_idx = 6\n",
    "    p_attr = 'ethnicity'\n",
    "\n",
    "    view_stats_new(['fairgan'], biased_data, protected = p_attr, remove_protected = False,\n",
    "               orig_data = data ,protected_idx = p_idx, bias_dict ={})\n",
    "\n",
    "    #view_stats_new(['gan', 'wgan', 'adsgan'], biased_data, protected = p_attr, remove_protected = False,\n",
    "    #           orig_data = data ,protected_idx = p_idx, bias_dict ={})\n",
    "    \n",
    "#     view_stats_new(['DECAF'], biased_data, protected = p_attr, remove_protected = False,\n",
    "#            orig_data = data ,protected_idx = p_idx, bias_dict ={})\n",
    "\n",
    "#     view_stats_new(['DECAF-FTU1'], biased_data, protected = p_attr, remove_protected = False,\n",
    "#                orig_data = data ,protected_idx = p_idx, bias_dict ={15:[6]})\n",
    "    \n",
    "#     view_stats_new(['DECAF-FTU2'], biased_data, protected = p_attr, remove_protected = False,\n",
    "#                orig_data = data ,protected_idx = p_idx, bias_dict ={15:[6]}, surrogate = True,)\n",
    "\n",
    "#     view_stats_new(['DECAF-DP'], biased_data, protected = p_attr, remove_protected = False,\n",
    "#                orig_data = data ,protected_idx = p_idx, bias_dict ={15:[6,9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "path = 'logs' # use your path\n",
    "all_files = glob.glob(path + \"/*.log\")\n",
    "\n",
    "li = []\n",
    "\n",
    "\n",
    "methods = ['Benchmark', 'bias', 'precision', 'recall', 'density', 'coverage', 'dp', 'ftu', 'auc']\n",
    "\n",
    "\n",
    "\n",
    "def read_df(filename):\n",
    "    df = pd.read_csv(filename, index_col=False, header=0, names = methods)\n",
    "    df['ftu'] = abs(df['ftu'])\n",
    "    df['dp'] = abs(df['dp'])\n",
    "    df.loc[df.Benchmark == 'fairgan', 'Benchmark'] = 'FairGAN'\n",
    "    df.loc[df.Benchmark == 'DECAF', 'Benchmark'] = 'DECAF-ND'\n",
    "    df = df[df.Benchmark != 'adsgan']\n",
    "    \n",
    "    df = df[df.Benchmark != 'adsgan-pr']\n",
    "    df = df[df.Benchmark != 'gan']\n",
    "    df = df[df.Benchmark != 'gan-pr']\n",
    "    df = df[df.Benchmark != 'wgan']\n",
    "    df = df[df.Benchmark != 'wgan-pr']\n",
    "    df.bias = 1 - df.bias\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_df2(filename):\n",
    "    df = pd.read_csv(filename, index_col=False, header=0, names = methods)\n",
    "    df['ftu'] = abs(df['ftu'])\n",
    "    df['dp'] = df['dp'] - np.min(df['dp'])\n",
    "    df.loc[df.Benchmark == 'fairgan', 'Benchmark'] = 'FairGAN'\n",
    "    df.loc[df.Benchmark == 'DECAF', 'Benchmark'] = 'DECAF-ND'\n",
    "    df = df[df.Benchmark != 'adsgan']\n",
    "    \n",
    "    df = df[df.Benchmark != 'adsgan-pr']\n",
    "    df = df[df.Benchmark != 'gan']\n",
    "    df = df[df.Benchmark != 'gan-pr']\n",
    "    df = df[df.Benchmark != 'wgan']\n",
    "    df = df[df.Benchmark != 'wgan-pr']\n",
    "    df = df[df.Benchmark != 'FairGAN']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_df3(filename):\n",
    "    df = pd.read_csv(filename, index_col=False, header=0, names = methods)\n",
    "    df['ftu'] = abs(df['ftu'])\n",
    "    df['dp'] = abs(df['dp'])\n",
    "    df.loc[df.Benchmark == 'fairgan', 'Benchmark'] = 'FairGAN'\n",
    "    df.loc[df.Benchmark == 'DECAF', 'Benchmark'] = 'DECAF-ND'\n",
    "    df.loc[df.Benchmark == 'DECAF-FTU', 'Benchmark'] = 'DECAF-FTU1'\n",
    "    df = df[df.Benchmark != 'adsgan']\n",
    "    \n",
    "    df = df[df.Benchmark != 'adsgan-pr']\n",
    "    df = df[df.Benchmark != 'gan']\n",
    "    df = df[df.Benchmark != 'gan-pr']\n",
    "    df = df[df.Benchmark != 'wgan']\n",
    "    df = df[df.Benchmark != 'wgan-pr']\n",
    "    df = df[df.Benchmark != 'FairGAN']\n",
    "    df.bias = 1 - df.bias\n",
    "    return df\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "df = read_df('plots_surrogate_confounder_both.csv')\n",
    "dims = (3.3,3.3)\n",
    "plt.figure(figsize = dims)\n",
    "\n",
    "fig = sns.lineplot(data=df, x='bias', y = 'auc', hue = 'Benchmark', err_style = \"bars\")\n",
    "\n",
    "\n",
    "plt.xlabel(r\"Bias $\\beta$\", fontsize=14)\n",
    "plt.ylabel(\"AUROC\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_auroc2.pdf')\n",
    "\n",
    "plt.figure(figsize = dims)\n",
    "sns.lineplot(data=df, x='bias', y = 'dp', hue = 'Benchmark',err_style=\"bars\")\n",
    "plt.xlabel(r\"Bias $\\beta$\", fontsize=14)\n",
    "plt.ylabel(\"DP\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_dp2.pdf')\n",
    "\n",
    "\n",
    "plt.figure(figsize = dims)\n",
    "sns.lineplot(data=df, x='bias', y = 'ftu', hue = 'Benchmark', err_style=\"bars\")\n",
    "plt.xlabel(r\"Bias $\\beta$\", fontsize=14)\n",
    "plt.ylabel(\"FTU\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_ftu2.pdf')\n",
    "\n",
    "plt.figure(figsize = dims)\n",
    "sns.lineplot(data=df, x='bias', y = 'precision', hue = 'Benchmark',err_style=\"bars\")\n",
    "plt.xlabel(r\"Bias $\\beta$\", fontsize=14)\n",
    "plt.ylabel(\"Precision\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_prec2.pdf')\n",
    "\n",
    "\n",
    "plt.figure(figsize = dims)\n",
    "sns.lineplot(data=df, x='bias', y = 'recall', hue = 'Benchmark',err_style=\"bars\" )\n",
    "plt.xlabel(r\"Bias $\\beta$\", fontsize=14)\n",
    "plt.ylabel(\"Recall\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_recall2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycausal",
   "language": "python",
   "name": "pycausal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
