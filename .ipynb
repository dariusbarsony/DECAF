{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "S1t5-cjhja30",
    "outputId": "540e7a09-91a3-47b0-ef80-939dc75e8a5f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import recall_score,precision_score\n",
    "\n",
    "from table_evaluator import TableEvaluator\n",
    "from ctgan import CTGANSynthesizer\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xdSEw1G4lwzJ"
   },
   "outputs": [],
   "source": [
    "#adult_dir = '../gdrive/MyDrive/adult.data'\n",
    "adult_dir = 'data/adult.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RPBUIw5jcKu",
    "outputId": "9756042c-364f-4525-8f57-801f06541e98"
   },
   "outputs": [],
   "source": [
    "def clean_df(dir):\n",
    "    names = [\n",
    "            \"age\",\n",
    "            \"workclass\",\n",
    "            \"fnlwgt\",\n",
    "            \"education\",\n",
    "            \"education-num\",\n",
    "            \"marital-status\",\n",
    "            \"occupation\",\n",
    "            \"relationship\",\n",
    "            \"race\",\n",
    "            \"sex\",\n",
    "            \"capital-gain\",\n",
    "            \"capital-loss\",\n",
    "            \"hours-per-week\",\n",
    "            \"native-country\",\n",
    "            \"label\",\n",
    "        ]\n",
    "    df = pd.read_csv(adult_dir, names=names, index_col=False)\n",
    "    df = df.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "\n",
    "    for col in df:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df = df[df[col] != \"?\"]\n",
    "\n",
    "    replace = [\n",
    "        [\n",
    "            \"Private\",\n",
    "            \"Self-emp-not-inc\",\n",
    "            \"Self-emp-inc\",\n",
    "            \"Federal-gov\",\n",
    "            \"Local-gov\",\n",
    "            \"State-gov\",\n",
    "            \"Without-pay\",\n",
    "            \"Never-worked\",\n",
    "        ],\n",
    "        [\n",
    "            \"Bachelors\",\n",
    "            \"Some-college\",\n",
    "            \"11th\",\n",
    "            \"HS-grad\",\n",
    "            \"Prof-school\",\n",
    "            \"Assoc-acdm\",\n",
    "            \"Assoc-voc\",\n",
    "            \"9th\",\n",
    "            \"7th-8th\",\n",
    "            \"12th\",\n",
    "            \"Masters\",\n",
    "            \"1st-4th\",\n",
    "            \"10th\",\n",
    "            \"Doctorate\",\n",
    "            \"5th-6th\",\n",
    "            \"Preschool\",\n",
    "        ],\n",
    "        [\n",
    "            \"Married-civ-spouse\",\n",
    "            \"Divorced\",\n",
    "            \"Never-married\",\n",
    "            \"Separated\",\n",
    "            \"Widowed\",\n",
    "            \"Married-spouse-absent\",\n",
    "            \"Married-AF-spouse\",\n",
    "        ],\n",
    "        [\n",
    "            \"Tech-support\",\n",
    "            \"Craft-repair\",\n",
    "            \"Other-service\",\n",
    "            \"Sales\",\n",
    "            \"Exec-managerial\",\n",
    "            \"Prof-specialty\",\n",
    "            \"Handlers-cleaners\",\n",
    "            \"Machine-op-inspct\",\n",
    "            \"Adm-clerical\",\n",
    "            \"Farming-fishing\",\n",
    "            \"Transport-moving\",\n",
    "            \"Priv-house-serv\",\n",
    "            \"Protective-serv\",\n",
    "            \"Armed-Forces\",\n",
    "        ],\n",
    "        [\n",
    "            \"Wife\",\n",
    "            \"Own-child\",\n",
    "            \"Husband\",\n",
    "            \"Not-in-family\",\n",
    "            \"Other-relative\",\n",
    "            \"Unmarried\",\n",
    "        ],\n",
    "        [\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
    "        [\"Female\", \"Male\"],\n",
    "        [\n",
    "            \"United-States\",\n",
    "            \"Cambodia\",\n",
    "            \"England\",\n",
    "            \"Puerto-Rico\",\n",
    "            \"Canada\",\n",
    "            \"Germany\",\n",
    "            \"Outlying-US(Guam-USVI-etc)\",\n",
    "            \"India\",\n",
    "            \"Japan\",\n",
    "            \"Greece\",\n",
    "            \"South\",\n",
    "            \"China\",\n",
    "            \"Cuba\",\n",
    "            \"Iran\",\n",
    "            \"Honduras\",\n",
    "            \"Philippines\",\n",
    "            \"Italy\",\n",
    "            \"Poland\",\n",
    "            \"Jamaica\",\n",
    "            \"Vietnam\",\n",
    "            \"Mexico\",\n",
    "            \"Portugal\",\n",
    "            \"Ireland\",\n",
    "            \"France\",\n",
    "            \"Dominican-Republic\",\n",
    "            \"Laos\",\n",
    "            \"Ecuador\",\n",
    "            \"Taiwan\",\n",
    "            \"Haiti\",\n",
    "            \"Columbia\",\n",
    "            \"Hungary\",\n",
    "            \"Guatemala\",\n",
    "            \"Nicaragua\",\n",
    "            \"Scotland\",\n",
    "            \"Thailand\",\n",
    "            \"Yugoslavia\",\n",
    "            \"El-Salvador\",\n",
    "            \"Trinadad&Tobago\",\n",
    "            \"Peru\",\n",
    "            \"Hong\",\n",
    "            \"Holand-Netherlands\",\n",
    "        ],\n",
    "        [\">50K\", \"<=50K\"],\n",
    "    ]\n",
    "\n",
    "    for row in replace:\n",
    "        df = df.replace(row, range(len(row)))\n",
    "\n",
    "    # Create a dataframe to store the synthetic data\n",
    "    df = df[['race','age','sex','native-country','marital-status','education','occupation','hours-per-week','workclass','relationship','label']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "# Node order contains the order in which to generate the data, starting with the root nodes\n",
    "node_order = [['race','age','sex','native-country'],['marital-status'],['education'],['occupation','hours-per-week','workclass','relationship'],['label']]\n",
    "node_order_nl = ['race','age','sex','native-country','marital-status','education','occupation','hours-per-week','workclass','relationship','label']\n",
    "\n",
    "# List of connections; key is receiving node\n",
    "node_connections_normal = {'label':['occupation','race','hours-per-week','age','marital-status','education','sex','workclass','native-country','relatinship'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "'''\n",
    "Connections are removed according to the privacy criterion\n",
    "'''\n",
    "node_connections_FTU = {'label':['occupation','race','hours-per-week','age','marital-status','education','workclass','native-country','relationship'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "node_connections_DP = {'label':['race','age','native-country'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "node_connections_CF = {'label':['occupation','race','hours-per-week','age','education','workclass','native-country',],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "gvyTSr449x0G",
    "outputId": "ddf5fd93-9ce1-4b69-c6a2-55ba59bd0ed6"
   },
   "outputs": [],
   "source": [
    "ctgan = CTGANSynthesizer(epochs=10)\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def generate_data(mode):\n",
    "    \n",
    "    # How much more data the synthetic dataset should contain that the OG data (This is to ensure we can\n",
    "    # take a sample that looks like the original data)\n",
    "    factor = 50\n",
    "    \n",
    "    # Define the privacy measure\n",
    "    if mode == 'FTU':\n",
    "        node_connections = node_connections_FTU\n",
    "    elif mode == 'DP':\n",
    "        node_connections = node_connections_DP\n",
    "    elif mode == 'CF':\n",
    "        node_connections = node_connections_CF\n",
    "    else:\n",
    "        print('Mode is not correct!')\n",
    "        \n",
    "    # DF to fit the first model on\n",
    "    start_df = df[['race','age','sex','native-country']]\n",
    "    temp_discrete = ['race','age','sex','native-country']\n",
    "    \n",
    "    ctgan.fit(start_df, temp_discrete)\n",
    "    synth_df = ctgan.sample(factor * len(start_df.index))\n",
    "    \n",
    "    # Iteratively generate the data\n",
    "    for node in node_order_nl:\n",
    "        # If the node has not been generated yet\n",
    "        if node not in synth_df.columns:\n",
    "            # Grab the old data\n",
    "            empty_df = df[[node]]\n",
    "\n",
    "            # Grab the attributes that need to be looked at when generating data\n",
    "            if node in node_connections.keys():\n",
    "                attributes = node_connections[node]\n",
    "            else:\n",
    "                attributes = []\n",
    "                for n in node_order_nl:\n",
    "                    attributes.append(n)\n",
    "                    if n == node:\n",
    "                        break\n",
    "        \n",
    "            # Grab the attributes from the final df\n",
    "            gen_df = synth_df.loc[:,synth_df.columns.isin(attributes)]\n",
    "\n",
    "            # Add the old attribute to the current dataframe\n",
    "            at = df[attributes]\n",
    "            empty_df = empty_df.join(at)\n",
    "            \n",
    "            temp_discrete = []\n",
    "            for d in discrete_columns:\n",
    "                if d in gen_df.columns:\n",
    "                    temp_discrete.append(d)\n",
    "                    \n",
    "            ctgan.fit(empty_df, temp_discrete)\n",
    "            generated_data = ctgan.sample(len(synth_df.index))\n",
    "            \n",
    "            # Add the generated data to the output\n",
    "            for attribute in attributes + [node]:\n",
    "                if attribute not in synth_df.columns:\n",
    "                    synth_df[attribute] = generated_data[attribute].values\n",
    "        print('Finished node',node)\n",
    "    # Finally, we have to manually add the label\n",
    "    return synth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(mode,synthetic):\n",
    "\n",
    "\n",
    "    # Split the data into train,test\n",
    "    traindf, testdf = train_test_split(df, test_size=0.3)\n",
    "    X_train = traindf.loc[:, traindf.columns != 'label']\n",
    "    y_train = traindf['label']\n",
    "    X_test = testdf.loc[:, testdf.columns != 'label']\n",
    "    y_test = testdf['label']\n",
    "\n",
    "    clf_df = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
    "                                     learning_rate='constant', learning_rate_init=0.001).fit(X_train, y_train)\n",
    "    y_pred = clf_df.predict(X_test)\n",
    "\n",
    "    #print('precision+recall for original data')\n",
    "    #print('Precision:',precision_score(y_test, y_pred, average='binary'))\n",
    "    #print('Recall:',recall_score(y_test, y_pred, average='binary'))\n",
    "\n",
    "    df_pos = df.assign(sex=0)\n",
    "    df_neg = df.assign(sex=1)\n",
    "    \n",
    "    x_pos = df[df['sex'] == 0].drop(['label'], axis = 1)[:7508]\n",
    "    x_neg = df[df['sex'] == 1].drop(['label'], axis = 1)[:7508]\n",
    "    \n",
    "    pos = clf_df.predict(df_pos.drop('label',axis=1))\n",
    "    neg = clf_df.predict(df_neg.drop('label',axis=1))\n",
    "\n",
    "    pred_pos = clf_df.predict(x_pos)\n",
    "    pred_neg = clf_df.predict(x_neg)\n",
    "\n",
    "    FTU = np.abs(np.mean(pos-neg))\n",
    "    DP = np.mean(pred_pos)-np.mean(pred_neg)\n",
    "    #print('FTU and DP for original dataset:')\n",
    "    #print('FTU:',FTU)\n",
    "    #print('DP:',DP)\n",
    "\n",
    "    '''\n",
    "    SYNTHETIC DATASET\n",
    "    '''\n",
    "    # Make sure the data is representative of the original dataset\n",
    "    synthetic_balanced_1 = synthetic[synthetic.label == 1].sample(22654)\n",
    "    synthetic_balanced_0 = synthetic[synthetic.label == 0].sample(7508)\n",
    "    synthetic_balanced = synthetic_balanced_1.append(synthetic_balanced_0)\n",
    "\n",
    "    # Split the data into train,test\n",
    "    X_syn = synthetic_balanced.loc[:, synthetic_balanced.columns != 'label']\n",
    "    y_syn = synthetic_balanced['label']\n",
    "\n",
    "    y_pred_syn = clf_df.predict(X_syn)\n",
    "\n",
    "    #print('precision+recall for synthetic data')\n",
    "    print('Precision:',precision_score(y_syn, y_pred_syn, average='binary'))\n",
    "    print('Recall:',recall_score(y_syn, y_pred_syn, average='binary'))\n",
    "    \n",
    "    synthetic_pos = synthetic.assign(sex=0)\n",
    "    synthetic_neg = synthetic.assign(sex=1)\n",
    "    \n",
    "    x_pos_syn = synthetic_balanced[synthetic_balanced['sex'] == 0].drop(['label'], axis = 1)[:7508]\n",
    "    x_neg_syn = synthetic_balanced[synthetic_balanced['sex'] == 1].drop(['label'], axis = 1)[:7508]\n",
    "    \n",
    "    pos = clf_df.predict(synthetic_pos.drop('label',axis=1))\n",
    "    neg = clf_df.predict(synthetic_neg.drop('label',axis=1))\n",
    "\n",
    "    pred_pos_syn = clf_df.predict(x_pos_syn)\n",
    "    pred_neg_syn = clf_df.predict(x_neg_syn)\n",
    "    \n",
    "    FTU = np.abs(np.mean(pos-neg))\n",
    "    DP = np.mean(pred_pos_syn)-np.mean(pred_neg_syn)\n",
    "    #print('FTU and DP for synthetic balanced dataset:')\n",
    "    print('FTU:',FTU)\n",
    "    print('DP:',DP)\n",
    "\n",
    "    #print('FTU and DP for original:',FTU,'-',DP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished node race\n",
      "Finished node age\n",
      "Finished node sex\n",
      "Finished node native-country\n",
      "Finished node marital-status\n",
      "Finished node education\n",
      "Finished node occupation\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FTU results for adult dataset\n",
    "'''\n",
    "\n",
    "mode = 'FTU'\n",
    "# Generate the synthetic data\n",
    "df = clean_df(adult_dir)\n",
    "synthetic = generate_data(mode)\n",
    "\n",
    "synthetic.label.value_counts()\n",
    "get_metrics(mode,synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CF for adult dataset\n",
    "'''\n",
    "mode = 'CF'\n",
    "# Generate the synthetic data\n",
    "df = clean_df(adult_dir)\n",
    "synthetic = generate_data(mode)\n",
    "print(type(synthetic))\n",
    "get_metrics(mode,synthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### '''\n",
    "DP results for adult dataset\n",
    "'''\n",
    "mode = 'DP'\n",
    "# Generate the synthetic data\n",
    "df = clean_df(adult_dir)\n",
    "synthetic = generate_data(mode)\n",
    "get_metrics(mode,synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FACT GAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
