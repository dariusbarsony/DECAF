{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "S1t5-cjhja30",
    "outputId": "540e7a09-91a3-47b0-ef80-939dc75e8a5f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be1f3fc4b840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "#Main imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset (adult.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veyREY-tlrmH"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdSEw1G4lwzJ"
   },
   "outputs": [],
   "source": [
    "#adult_dir = '../gdrive/MyDrive/adult.data'\n",
    "adult_dir = 'data/adult.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RPBUIw5jcKu",
    "outputId": "9756042c-364f-4525-8f57-801f06541e98"
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "        \"label\",\n",
    "    ]\n",
    "df = pd.read_csv(adult_dir, names=names, index_col=False)\n",
    "df = df.applymap(lambda x: x.strip() if type(x) is str else x)\n",
    "\n",
    "for col in df:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df = df[df[col] != \"?\"]\n",
    "\n",
    "replace = [\n",
    "    [\n",
    "        \"Private\",\n",
    "        \"Self-emp-not-inc\",\n",
    "        \"Self-emp-inc\",\n",
    "        \"Federal-gov\",\n",
    "        \"Local-gov\",\n",
    "        \"State-gov\",\n",
    "        \"Without-pay\",\n",
    "        \"Never-worked\",\n",
    "    ],\n",
    "    [\n",
    "        \"Bachelors\",\n",
    "        \"Some-college\",\n",
    "        \"11th\",\n",
    "        \"HS-grad\",\n",
    "        \"Prof-school\",\n",
    "        \"Assoc-acdm\",\n",
    "        \"Assoc-voc\",\n",
    "        \"9th\",\n",
    "        \"7th-8th\",\n",
    "        \"12th\",\n",
    "        \"Masters\",\n",
    "        \"1st-4th\",\n",
    "        \"10th\",\n",
    "        \"Doctorate\",\n",
    "        \"5th-6th\",\n",
    "        \"Preschool\",\n",
    "    ],\n",
    "    [\n",
    "        \"Married-civ-spouse\",\n",
    "        \"Divorced\",\n",
    "        \"Never-married\",\n",
    "        \"Separated\",\n",
    "        \"Widowed\",\n",
    "        \"Married-spouse-absent\",\n",
    "        \"Married-AF-spouse\",\n",
    "    ],\n",
    "    [\n",
    "        \"Tech-support\",\n",
    "        \"Craft-repair\",\n",
    "        \"Other-service\",\n",
    "        \"Sales\",\n",
    "        \"Exec-managerial\",\n",
    "        \"Prof-specialty\",\n",
    "        \"Handlers-cleaners\",\n",
    "        \"Machine-op-inspct\",\n",
    "        \"Adm-clerical\",\n",
    "        \"Farming-fishing\",\n",
    "        \"Transport-moving\",\n",
    "        \"Priv-house-serv\",\n",
    "        \"Protective-serv\",\n",
    "        \"Armed-Forces\",\n",
    "    ],\n",
    "    [\n",
    "        \"Wife\",\n",
    "        \"Own-child\",\n",
    "        \"Husband\",\n",
    "        \"Not-in-family\",\n",
    "        \"Other-relative\",\n",
    "        \"Unmarried\",\n",
    "    ],\n",
    "    [\"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"],\n",
    "    [\"Female\", \"Male\"],\n",
    "    [\n",
    "        \"United-States\",\n",
    "        \"Cambodia\",\n",
    "        \"England\",\n",
    "        \"Puerto-Rico\",\n",
    "        \"Canada\",\n",
    "        \"Germany\",\n",
    "        \"Outlying-US(Guam-USVI-etc)\",\n",
    "        \"India\",\n",
    "        \"Japan\",\n",
    "        \"Greece\",\n",
    "        \"South\",\n",
    "        \"China\",\n",
    "        \"Cuba\",\n",
    "        \"Iran\",\n",
    "        \"Honduras\",\n",
    "        \"Philippines\",\n",
    "        \"Italy\",\n",
    "        \"Poland\",\n",
    "        \"Jamaica\",\n",
    "        \"Vietnam\",\n",
    "        \"Mexico\",\n",
    "        \"Portugal\",\n",
    "        \"Ireland\",\n",
    "        \"France\",\n",
    "        \"Dominican-Republic\",\n",
    "        \"Laos\",\n",
    "        \"Ecuador\",\n",
    "        \"Taiwan\",\n",
    "        \"Haiti\",\n",
    "        \"Columbia\",\n",
    "        \"Hungary\",\n",
    "        \"Guatemala\",\n",
    "        \"Nicaragua\",\n",
    "        \"Scotland\",\n",
    "        \"Thailand\",\n",
    "        \"Yugoslavia\",\n",
    "        \"El-Salvador\",\n",
    "        \"Trinadad&Tobago\",\n",
    "        \"Peru\",\n",
    "        \"Hong\",\n",
    "        \"Holand-Netherlands\",\n",
    "    ],\n",
    "    [\">50K\", \"<=50K\"],\n",
    "]\n",
    "\n",
    "for row in replace:\n",
    "    df = df.replace(row, range(len(row)))\n",
    "\n",
    "index = df.index\n",
    "print('TOTAL DATAPOINTS AFTER CLEANING:',len(index))\n",
    "\n",
    "# Split the data into train,test\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "X_train = train.loc[:, train.columns != 'label']\n",
    "y_train = train['label']\n",
    "X_test = test.loc[:, test.columns != 'label']\n",
    "y_test = test['label']\n",
    "\n",
    "# fig, ax = plt.subplots(5, 3, figsize = (30, 20))\n",
    "# fig.tight_layout(pad = 2.0)\n",
    "\n",
    "# ax[0,0].hist(df['age'])\n",
    "# ax[0,0].set_title('age')\n",
    "# ax[0,1].hist(df['workclass'])\n",
    "# ax[0,1].set_title('workclass')\n",
    "# ax[0,2].hist(df['fnlwgt'])\n",
    "# ax[0,2].set_title('fnlwgt')\n",
    "\n",
    "# ax[1,0].hist(df['education'])\n",
    "# ax[1,0].set_title('education')\n",
    "# ax[1,1].hist(df['education-num'])\n",
    "# ax[1,1].set_title('education-num')\n",
    "# ax[1,2].hist(df['marital-status'])\n",
    "# ax[1,2].set_title('marital-status')\n",
    "\n",
    "# ax[2,0].hist(df['occupation'])\n",
    "# ax[2,0].set_title('occupation')\n",
    "# ax[2,1].hist(df['relationship'])\n",
    "# ax[2,1].set_title('relationship')\n",
    "# ax[2,2].hist(df['race'])\n",
    "# ax[2,2].set_title('race')\n",
    "\n",
    "# ax[3,0].hist(df['sex'])\n",
    "# ax[3,0].set_title('sex')\n",
    "# ax[3,1].hist(df['capital-gain'])\n",
    "# ax[3,1].set_title('capital-gain')\n",
    "# ax[3,2].hist(df['capital-loss'])\n",
    "# ax[3,2].set_title('capital-loss')\n",
    "\n",
    "# ax[4,0].hist(df['hours-per-week'])\n",
    "# ax[4,0].set_title('hours-per-week')\n",
    "# ax[4,1].hist(df['native-country'])\n",
    "# ax[4,1].set_title('native-country')\n",
    "# ax[4,2].hist(df['label'])\n",
    "# ax[4,2].set_title('label')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECAF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DECAF.decaf import DECAF, DataModule\n",
    "from DECAF.utils import gen_data_nonlinear, load_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baseline(size: int = 100) -> Tuple[torch.Tensor, DataModule, list, dict]:\n",
    "    # causal structure is in dag_seed\n",
    "    dag_seed = [\n",
    "        [1, 2],\n",
    "        [1, 3],\n",
    "        [1, 4],\n",
    "        [2, 5],\n",
    "        [2, 0],\n",
    "        [3, 0],\n",
    "        [3, 6],\n",
    "        [3, 7],\n",
    "        [6, 9],\n",
    "        [0, 8],\n",
    "        [0, 9],\n",
    "    ]\n",
    "    # edge removal dictionary\n",
    "    bias_dict = {6: [3]}  # This removes the edge into 6 from 3.\n",
    "\n",
    "    # DATA SETUP according to dag_seed\n",
    "    G = nx.DiGraph(dag_seed)\n",
    "    data = gen_data_nonlinear(G, SIZE=size)\n",
    "    dm = DataModule(data.values)\n",
    "\n",
    "    return torch.Tensor(np.asarray(data)), dm, dag_seed, bias_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_params() -> None:\n",
    "    _, dummy_dm, seed, _ = generate_baseline()\n",
    "\n",
    "    model = DECAF(\n",
    "        dummy_dm.dims[0],\n",
    "        dag_seed=seed,\n",
    "    )\n",
    "\n",
    "    assert model.generator is not None\n",
    "    assert model.discriminator is not None\n",
    "    assert model.x_dim == dummy_dm.dims[0]\n",
    "    assert model.z_dim == dummy_dm.dims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_train() -> None:\n",
    "    _, dummy_dm, seed, _ = generate_baseline()\n",
    "\n",
    "    model = DECAF(\n",
    "        dummy_dm.dims[0],\n",
    "        dag_seed=seed,\n",
    "    )\n",
    "    trainer = pl.Trainer(max_epochs=2, logger=False)\n",
    "\n",
    "    trainer.fit(model, dummy_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_generate() -> None:\n",
    "    raw_data, dummy_dm, seed, bias_dict = generate_baseline(size=10)\n",
    "\n",
    "    model = DECAF(\n",
    "        dummy_dm.dims[0],\n",
    "        dag_seed=seed,\n",
    "    )\n",
    "    trainer = pl.Trainer(max_epochs=2, logger=False)\n",
    "\n",
    "    trainer.fit(model, dummy_dm)\n",
    "\n",
    "    synth_data = (\n",
    "        model.gen_synthetic(\n",
    "            raw_data, gen_order=model.get_gen_order(), biased_edges=bias_dict\n",
    "        )\n",
    "            .detach()\n",
    "            .numpy()\n",
    "    )\n",
    "    assert synth_data.shape[0] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"X,y\", [load_adult()])\n",
    "@pytest.mark.slow\n",
    "def test_run_experiments(X: pd.DataFrame, y: pd.DataFrame) -> None:\n",
    "    print(X.shape)\n",
    "    \"\"\"Normalize X\"\"\"\n",
    "    X_normalized = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "    # baseline_clf = XGBClassifier(eval_metric='logloss', use_label_encoder=False).fit(X, y)\n",
    "    # baseline_clf = XGBClassifier().fit(X_normalized, y)\n",
    "    baseline_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
    "                                 learning_rate='constant', learning_rate_init=0.001)\n",
    "    baseline_clf.fit(X_normalized, y)\n",
    "\n",
    "    y_pred = baseline_clf.predict(X_normalized)\n",
    "\n",
    "    print(\n",
    "        \"baseline scores\",\n",
    "        precision_score(y, y_pred),\n",
    "        recall_score(y, y_pred),\n",
    "        roc_auc_score(y, y_pred),\n",
    "    )\n",
    "\n",
    "    dm = DataModule(X_normalized)\n",
    "\n",
    "    # causal structure is in dag_seed\n",
    "    dag_seed = [\n",
    "        [0, 6],\n",
    "        [0, 12],\n",
    "        [0, 1],\n",
    "        [0, 5],\n",
    "        [0, 3],\n",
    "        [3, 6],\n",
    "        [3, 12],\n",
    "        [3, 1],\n",
    "        [3, 7],\n",
    "        [5, 6],\n",
    "        [5, 12],\n",
    "        [5, 1],\n",
    "        [5, 7],\n",
    "        [5, 3],\n",
    "        [8, 6],\n",
    "        [8, 12],\n",
    "        [8, 3],\n",
    "        [8, 5],\n",
    "        [9, 6],\n",
    "        [9, 5],\n",
    "        [9, 12],\n",
    "        [9, 1],\n",
    "        [9, 3],\n",
    "        [9, 7],\n",
    "        [13, 5],\n",
    "        [13, 12],\n",
    "        [13, 3],\n",
    "        [13, 1],\n",
    "        [13, 7],\n",
    "    ]\n",
    "    # edge removal dictionary\n",
    "    bias_dict = {}\n",
    "\n",
    "    # bias_dict = {6: [9],\n",
    "    #              5: [9],\n",
    "    #              12: [9],\n",
    "    #              1: [9],\n",
    "    #              3: [9],\n",
    "    #              7: [9],\n",
    "    #              }\n",
    "\n",
    "    model = DECAF(\n",
    "        dm.dims[0],\n",
    "        dag_seed=dag_seed,\n",
    "        use_mask=True,\n",
    "        grad_dag_loss=False,\n",
    "        lambda_privacy=0,\n",
    "        lambda_gp=10,\n",
    "        weight_decay=1e-2,\n",
    "        l1_g=0,\n",
    "        p_gen=-1,\n",
    "        batch_size=100,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=10, logger=False)\n",
    "\n",
    "    trainer.fit(model, dm)\n",
    "\n",
    "    X_synth = (\n",
    "        model.gen_synthetic(\n",
    "            dm.dataset.x,\n",
    "            gen_order=model.get_gen_order(), biased_edges=bias_dict\n",
    "        )\n",
    "            .detach()\n",
    "            .numpy()\n",
    "    )\n",
    "\n",
    "    print(X_normalized[10:])\n",
    "    print(X_synth[10:])\n",
    "\n",
    "    y_synth = baseline_clf.predict(X_synth)\n",
    "\n",
    "    print(y_synth)\n",
    "    print('y_synth unique?', np.unique(y_synth) > 1)\n",
    "\n",
    "    # synth_clf = XGBClassifier().fit(X_synth, y_synth)\n",
    "    synth_clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
    "                              learning_rate='constant', learning_rate_init=0.001)\n",
    "    synth_clf.fit(X_synth, y_synth)\n",
    "    y_pred = synth_clf.predict(X_synth)\n",
    "\n",
    "    # try:\n",
    "    print(\n",
    "        \"synth scores\",\n",
    "        precision_score(y_synth, y),\n",
    "        recall_score(y_synth, y),\n",
    "        roc_auc_score(y_synth, y),\n",
    "    )\n",
    "    # except ValueError:\n",
    "    #     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark results for comparison - CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "QOa1glz3wCe-",
    "outputId": "696b2f1b-b3e2-48d9-9f58-cf11be291cb9"
   },
   "outputs": [],
   "source": [
    "from table_evaluator import TableEvaluator\n",
    "from ctgan import CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAMirvKwmm3H",
    "outputId": "44473c3e-aa10-4c04-cfcf-f41473c00a7e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "#ctgan = CTGANSynthesizer(epochs=10,verbose=True)\n",
    "#ctgan.fit(dfc, discrete_columns)\n",
    "\n",
    "# Generate the exact same amount\n",
    "#df1 = ctgan.sample(len(dfc.index))\n",
    "\n",
    "# fig, ax = plt.subplots(5, 3, figsize = (30, 20))\n",
    "# fig.tight_layout(pad = 2.0)\n",
    "\n",
    "# ax[0,0].hist(df1['age'])\n",
    "# ax[0,0].set_title('age')\n",
    "# ax[0,1].hist(df1['workclass'])\n",
    "# ax[0,1].set_title('workclass')\n",
    "# ax[0,2].hist(df1['fnlwgt'])\n",
    "# ax[0,2].set_title('fnlwgt')\n",
    "\n",
    "# ax[1,0].hist(df1['education'])\n",
    "# ax[1,0].set_title('education')\n",
    "# ax[1,1].hist(df1['education-num'])\n",
    "# ax[1,1].set_title('education-num')\n",
    "# ax[1,2].hist(df1['marital-status'])\n",
    "# ax[1,2].set_title('marital-status')\n",
    "\n",
    "# ax[2,0].hist(df1['occupation'])\n",
    "# ax[2,0].set_title('occupation')\n",
    "# ax[2,1].hist(df1['relationship'])\n",
    "# ax[2,1].set_title('relationship')\n",
    "# ax[2,2].hist(df1['race'])\n",
    "# ax[2,2].set_title('race')\n",
    "\n",
    "# ax[3,0].hist(df1['sex'])\n",
    "# ax[3,0].set_title('sex')\n",
    "# ax[3,1].hist(df1['capital-gain'])\n",
    "# ax[3,1].set_title('capital-gain')\n",
    "# ax[3,2].hist(df1['capital-loss'])\n",
    "# ax[3,2].set_title('capital-loss')\n",
    "\n",
    "# ax[4,0].hist(df1['hours-per-week'])\n",
    "# ax[4,0].set_title('hours-per-week')\n",
    "# ax[4,1].hist(df1['native-country'])\n",
    "# ax[4,1].set_title('native-country')\n",
    "# ax[4,2].hist(df1['label'])\n",
    "# ax[4,2].set_title('label')\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7j987Rrbs9Lb"
   },
   "outputs": [],
   "source": [
    "# indexc = dfc.index\n",
    "# print('TOTAL DATAPOINTS AFTER CLEANING:',len(indexc))\n",
    "# index1 = df1.index\n",
    "# print('TOTAL DATAPOINTS AFTER CLEANING:',len(index1))\n",
    "# table_evaluator = TableEvaluator(dfc,df1)\n",
    "# table_evaluator.visual_evaluation() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "    'label'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a dataframe to store the synthetic data\n",
    "df = df[['race','age','sex','native-country','marital-status','education','occupation','hours-per-week','workclass','relationship','label']]\n",
    "\n",
    "# Node order contains the order in which to generate the data, starting with the root nodes\n",
    "node_order = [['race','age','sex','native-country'],['marital-status'],['education'],['occupation','hours-per-week','workclass','relationship'],['label']]\n",
    "node_order_nl = ['race','age','sex','native-country','marital-status','education','occupation','hours-per-week','workclass','relationship','label']\n",
    "\n",
    "# List of connections; key is receiving node\n",
    "node_connections_normal = {'label':['occupation','race','hours-per-week','age','marital-status','education','sex','workclass','native-country','relatinship'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "'''\n",
    "Connections are removed according to the privacy criterion\n",
    "'''\n",
    "node_connections_FTU = {'label':['occupation','race','hours-per-week','age','marital-status','education','workclass','native-country','relationship'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "node_connections_DP = {'label':['race','age','native-country'],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }\n",
    "\n",
    "node_connections_CF = {'label':['occupation','race','hours-per-week','age','education','workclass','native-country',],\n",
    "                    'occupation':['race','age','sex','marital-status','education'],\n",
    "                    'hours-per-week':['race','age','marital-status','native-country','education','sex'],\n",
    "                    'workclass':['age','marital-status','sex','education','native-country'],\n",
    "                    'relationship':['marital-status','education','age','sex','native-country'],\n",
    "                    'education':['race','age','marital-status','sex','native-country'],\n",
    "                    'marital-status':['race','age','sex','native-country']\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "gvyTSr449x0G",
    "outputId": "ddf5fd93-9ce1-4b69-c6a2-55ba59bd0ed6"
   },
   "outputs": [],
   "source": [
    "ctgan = CTGANSynthesizer(epochs=10)\n",
    "def generate_data(mode):\n",
    "    \n",
    "    # Define the privacy measure\n",
    "    if mode == 'FTU':\n",
    "        node_connections = node_connections_FTU\n",
    "    elif mode == 'DP':\n",
    "        node_connections = node_connections_DP\n",
    "    elif mode == 'CF':\n",
    "        node_connections = node_connections_CF\n",
    "    else:\n",
    "        print('Mode is not correct!')\n",
    "        \n",
    "    # DF to fit the first model on\n",
    "    start_df = df[['race','age','sex','native-country']]\n",
    "    \n",
    "    # Generate the initial nodes\n",
    "    temp_discrete = ['race','age','sex','native-country']\n",
    "    ctgan.fit(start_df, temp_discrete)\n",
    "    synth_df = ctgan.sample(len(start_df.index))\n",
    "    print('Done generating the root nodes.')\n",
    "    \n",
    "    \n",
    "    # Iteratively generate the data\n",
    "    for node in node_order_nl:\n",
    "        \n",
    "        # If the node has not been generated yet\n",
    "        if node not in synth_df.columns:\n",
    "            \n",
    "            # Grab the old data\n",
    "            empty_df = df[[node]]\n",
    "\n",
    "            # Grab the attributes that need to be looked at when generating data\n",
    "            attributes = node_connections[node]\n",
    "            \n",
    "            # Grab the attributes from the final df\n",
    "            gen_df = synth_df.loc[:,synth_df.columns.isin(attributes)]\n",
    "        \n",
    "            # Add the old attribute to the current dataframe\n",
    "            at = df[attributes]\n",
    "            empty_df = empty_df.join(at)\n",
    "            \n",
    "            temp_discrete = []\n",
    "            for d in discrete_columns:\n",
    "                if d in gen_df.columns:\n",
    "                    temp_discrete.append(d)\n",
    "                    \n",
    "            print('Started training node',node)\n",
    "            ctgan.fit(empty_df, temp_discrete)\n",
    "            generated_data = ctgan.sample(len(synth_df.index))\n",
    "            \n",
    "            # Check if synth_df needs the current attribute (shouldn't, but just to be sure)\n",
    "            for attribute in attributes:\n",
    "                if attribute not in synth_df.columns:\n",
    "                    synth_df[attribute] = generated_data[attribute].values\n",
    "            print('Finished training node',node)\n",
    "    \n",
    "    synth_df = synth_df.join(generated_data[['label']])\n",
    "    return synth_df\n",
    "\n",
    "synthetic = generate_data('FTU')\n",
    "print(synthetic.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FACT GAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
